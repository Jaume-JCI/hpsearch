{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp examples.dummy_experiment_manager\n",
    "from nbdev.showdoc import *\n",
    "from block_types.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Experiment Manager\n",
    "\n",
    "> Dummy experiment manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FakeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FakeModel (object):\n",
    "    \n",
    "    overfitting_epochs = 20\n",
    "    \n",
    "    def __init__ (self, offset=0.5, rate=0.01, epochs=10, noise=0.0, verbose=True):\n",
    "        # hyper-parameters\n",
    "        self.offset = offset\n",
    "        self.rate = rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # fake internal weight\n",
    "        self.weight = 0\n",
    "        \n",
    "        # fake accuracy\n",
    "        self.accuracy = 0\n",
    "        \n",
    "        # noise\n",
    "        self.noise = noise\n",
    "        \n",
    "        # other parameters\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.history = {}\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def fit (self):\n",
    "        number_epochs = int(self.epochs)\n",
    "        if self.verbose:\n",
    "            print (f'fitting model with {number_epochs} epochs')\n",
    "        \n",
    "        if self.current_epoch==0:\n",
    "            self.accuracy = self.offset\n",
    "        \n",
    "        for epoch in range(number_epochs):\n",
    "            self.weight += self.rate\n",
    "            if self.current_epoch < self.overfitting_epochs:\n",
    "                self.accuracy += self.rate\n",
    "            else:\n",
    "                self.accuracy -= self.rate\n",
    "            if self.verbose:\n",
    "                print (f'epoch {epoch}: accuracy: {self.accuracy}')\n",
    "            \n",
    "            # we keep track of the evolution of different metrics to later be able to visualize it\n",
    "            self.store_intermediate_metrics ()\n",
    "            \n",
    "            # increase current epoch by 1\n",
    "            self.current_epoch += 1\n",
    "    \n",
    "    def store_intermediate_metrics (self):\n",
    "        validation_accuracy, test_accuracy = self.score()\n",
    "        if 'validation_accuracy' not in self.history:\n",
    "            self.history['validation_accuracy'] = []\n",
    "        self.history['validation_accuracy'].append(validation_accuracy)\n",
    "        \n",
    "        if 'test_accuracy' not in self.history:\n",
    "            self.history['test_accuracy'] = []\n",
    "        self.history['test_accuracy'].append(test_accuracy)\n",
    "        \n",
    "        if 'accuracy' not in self.history:\n",
    "            self.history['accuracy'] = []\n",
    "        self.history['accuracy'].append(self.accuracy)\n",
    "        \n",
    "    def save_model_and_history (self, path_results):\n",
    "        pickle.dump (self.weight, open(f'{path_results}/model_weights.pk','wb'))\n",
    "        pickle.dump (self.history, open(f'{path_results}/model_history.pk','wb'))\n",
    "        \n",
    "    def load_model_and_history (self, path_results):\n",
    "        if os.path.exists(f'{path_results}/model_weights.pk'):\n",
    "            print (f'reading model from {path_results}/model_weights.pk')\n",
    "            self.weight = pickle.load (open(f'{path_results}/model_weights.pk','rb'))\n",
    "            self.history = pickle.load (open(f'{path_results}/model_history.pk','rb'))\n",
    "            self.current_epoch = len(self.history['accuracy'])\n",
    "            if self.current_epoch > 0:\n",
    "                self.accuracy = self.history['accuracy'][-1]\n",
    "            else:\n",
    "                self.accuracy = self.offset\n",
    "        else:\n",
    "            print (f'model not found in {path_results}')\n",
    "        \n",
    "    def score (self):\n",
    "        # validation accuracy\n",
    "        validation_accuracy = self.accuracy + np.random.randn() * self.noise\n",
    "        \n",
    "        # test accuracy\n",
    "        if self.current_epoch < 10:\n",
    "            test_accuracy = self.accuracy + 0.1\n",
    "        else:\n",
    "            test_accuracy = self.accuracy - 0.1\n",
    "        test_accuracy = test_accuracy + np.random.randn() * self.noise\n",
    "        \n",
    "        # make accuracy be in interval [0,1] \n",
    "        validation_accuracy = max(min(validation_accuracy, 1.0), 0.0)\n",
    "        test_accuracy = max(min(test_accuracy, 1.0), 0.0)\n",
    "        \n",
    "        return validation_accuracy, test_accuracy\n",
    "    \n",
    "    # fake load_data which does nothing\n",
    "    def load_data (self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyExperimentManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from hpsearch.experiment_manager import ExperimentManager\n",
    "import hpsearch\n",
    "import os\n",
    "from hpsearch.visualization import plot_utils \n",
    "\n",
    "class DummyExperimentManager (ExperimentManager):\n",
    "\n",
    "    def __init__ (self, \n",
    "                  path_experiments=None, \n",
    "                  root='',\n",
    "                  metric='validation_accuracy',\n",
    "                  op='max',\n",
    "                  **kwargs):\n",
    "        \n",
    "        if path_experiments is None: path_experiments = f'{os.path.dirname(hpsearch.__file__)}/../results'\n",
    "        \n",
    "        super().__init__ (path_experiments=path_experiments, \n",
    "                          root=root,\n",
    "                          metric=metric,\n",
    "                          op=op,\n",
    "                          **kwargs)\n",
    "\n",
    "    def run_experiment (self, parameters={}, path_results='./results'):\n",
    "        # extract hyper-parameters used by our model. All the parameters have default values if they are not passed.\n",
    "        offset = parameters.get('offset', 0.5)   # default value: 0.5\n",
    "        rate = parameters.get('rate', 0.01)   # default value: 0.01\n",
    "        epochs = parameters.get('epochs', 10) # default value: 10\n",
    "        noise = parameters.get('noise', 0.0)\n",
    "        \n",
    "        # other parameters that do not form part of our experiment definition\n",
    "        # changing the values of these other parameters, does not make the ID of the experiment change\n",
    "        verbose = parameters.get('verbose', True)\n",
    "        \n",
    "        # build model with given hyper-parameters\n",
    "        model = FakeModel (offset=offset, rate=rate, epochs=epochs, noise = noise, verbose=verbose)\n",
    "        \n",
    "        # load training, validation and test data (fake step)\n",
    "        model.load_data()\n",
    "        \n",
    "        # fit model with training data \n",
    "        model.fit ()\n",
    "        \n",
    "        # save model weights and evolution of accuracy metric across epochs\n",
    "        model.save_model_and_history(path_results)\n",
    "        \n",
    "        # evaluate model with validation and test data\n",
    "        validation_accuracy, test_accuracy = model.score()\n",
    "        \n",
    "        # store model\n",
    "        self.model = model\n",
    "        \n",
    "        # the function returns a dictionary with keys corresponding to the names of each metric. \n",
    "        # We return result on validation and test set in this example\n",
    "        dict_results = dict (validation_accuracy = validation_accuracy,\n",
    "                             test_accuracy = test_accuracy)\n",
    "        \n",
    "        return dict_results\n",
    "    \n",
    "    # implementing the following method is not necessary but recommended\n",
    "    def get_default_parameters (self, parameters):\n",
    "        \"\"\"Indicate the default value for each of the hyper-parameters used.\"\"\"\n",
    "        defaults = dict(offset=0.5,\n",
    "                        rate=0.01,\n",
    "                        epochs=10)\n",
    "        \n",
    "        if parameters.get('rate', defaults['rate']) < 0.001:\n",
    "            defaults.update (epochs=100)\n",
    "        \n",
    "        return defaults\n",
    "    \n",
    "    def experiment_visualization (self, experiments=None, run_number=0, root_path=None, root_folder=None, \n",
    "                                  name_file='model_history.pk', metric='test_accuracy', backend='matplotlib', \n",
    "                                  **kwargs):\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        traces = []\n",
    "        for experiment_id in experiments:\n",
    "            path_results = self.get_path_results (experiment_id, run_number=run_number, root_path=root_path)\n",
    "            if os.path.exists('%s/%s' %(path_results, name_file)):\n",
    "                history = pickle.load(open('%s/%s' %(path_results, name_file),'rb'))\n",
    "                label = '{}'.format(experiment_id)\n",
    "                traces = plot_utils.add_trace ((1-np.array(history[metric]))*20, style='A.-', label=label, \n",
    "                                               backend=backend, traces=traces)\n",
    "        plot_utils.plot(title=metric, xlabel='epoch', ylabel=metric, traces=traces, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_multiple_experiments (nruns=1, noise=0.0, verbose=True, rate=0.03, values_to_explore=None,\n",
    "                              EM=DummyExperimentManager, em=None, **kwargs):\n",
    "    if em is None:\n",
    "        em = EM (**kwargs)\n",
    "    parameters_single_value = dict(rate=rate, noise=noise)   # parameters where we use a fixed value\n",
    "    if values_to_explore is None:\n",
    "        parameters_multiple_values=dict(offset=[0.1, 0.3, 0.6], epochs=[5, 15, 30]) # parameters where we try multiple values\n",
    "    else:\n",
    "        parameters_multiple_values=values_to_explore\n",
    "    other_parameters = dict(verbose=verbose) # parameters that control other aspects that are not part of our experiment definition (a new experiment is not created if we assign different values for these parametsers)\n",
    "    em.grid_search (log_message='fixed rate, multiple epochs values',\n",
    "            parameters_single_value=parameters_single_value,\n",
    "            parameters_multiple_values=parameters_multiple_values,\n",
    "            other_parameters=other_parameters,\n",
    "            nruns=nruns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_data (name_folder):\n",
    "    em = DummyExperimentManager (path_experiments=f'test_{name_folder}', verbose=0)\n",
    "    em.remove_previous_experiments ()\n",
    "    run_multiple_experiments (em=em, nruns=5, noise=0.1, verbose=False)\n",
    "    return em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def remove_previous_experiments (EM=DummyExperimentManager):\n",
    "    em = EM ()\n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.examples.test_dummy_experiment_manager\n",
    "def test_dummy_experiment_manager ():\n",
    "    em = generate_data ('dummy_experiment_manager')\n",
    "\n",
    "    path_results = em.get_path_experiments()\n",
    "    df = pd.read_csv (f'{path_results}/experiments_data.csv', index_col=0)\n",
    "    display (df)\n",
    "\n",
    "    # check that stored parameters are correct\n",
    "    assert (df.epochs.values == np.array([ 5.,  5.,  5., 15., 15., 15., 30., 30., 30.])).all()\n",
    "    assert (df.offset.values == np.array([0.1, 0.3, 0.6, 0.1, 0.3, 0.6, 0.1, 0.3, 0.6])).all()\n",
    "    assert (df.rate.values == 0.03).all()\n",
    "\n",
    "    # check that the accuracy values are correct\n",
    "    epochs_before_overfitting = 20\n",
    "    epochs_test = 10\n",
    "    for experiment_id in df.index:\n",
    "        if df.loc[experiment_id, 'epochs'] < epochs_before_overfitting:\n",
    "            accuracy = df.loc[experiment_id, 'offset'] + df.loc[experiment_id, 'rate'] * df.loc[experiment_id, 'epochs']\n",
    "        else:\n",
    "            epochs_after_overfitting = df.loc[experiment_id, 'epochs']-epochs_before_overfitting\n",
    "            accuracy = df.loc[experiment_id, 'offset'] + df.loc[experiment_id, 'rate'] * (epochs_before_overfitting  - epochs_after_overfitting)\n",
    "        if df.loc[experiment_id, 'epochs'] < epochs_test:\n",
    "            test_accuracy = accuracy + 0.1\n",
    "        else:\n",
    "            test_accuracy = accuracy - 0.1\n",
    "        validation_accuracy = max(min(accuracy, 1.0), 0.0)\n",
    "        test_accuracy = max(min(test_accuracy, 1.0), 0.0)\n",
    "\n",
    "        assert np.abs(df.loc[experiment_id, '0_validation_accuracy'] - validation_accuracy) <1.e-10, f\"experiment {experiment_id}: {df.loc[experiment_id, '0_validation_accuracy']} == {validation_accuracy}\" \n",
    "        assert np.abs(df.loc[experiment_id, '0_test_accuracy'] - test_accuracy) <1.e-10\n",
    "\n",
    "        md ('check that model history is written correcly')\n",
    "        path_experiment = em.get_path_results (3, 0)\n",
    "    model = FakeModel()\n",
    "    model.load_model_and_history(path_experiment)\n",
    "    assert np.max(np.abs(model.history['accuracy']-np.arange(0.13, 0.55, 0.03))) < 1e-10\n",
    "\n",
    "    em.experiment_visualization ([3,4,5], backend='matplotlib')\n",
    "\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_dummy_experiment_manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n",
      "write_manager failed with exception <class '__main__.DummyExperimentManager'> is a built-in class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>noise</th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "      <th>3_validation_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>time_3</th>\n",
       "      <th>3_finished</th>\n",
       "      <th>4_validation_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "      <th>time_4</th>\n",
       "      <th>4_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.479362</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>23:34:24.198639</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>True</td>\n",
       "      <td>0.119856</td>\n",
       "      <td>0.378851</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049509</td>\n",
       "      <td>0.492394</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.516995</td>\n",
       "      <td>0.662710</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>23:34:24.360379</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>True</td>\n",
       "      <td>0.629369</td>\n",
       "      <td>0.577808</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>True</td>\n",
       "      <td>0.638762</td>\n",
       "      <td>0.629643</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.877515</td>\n",
       "      <td>0.796200</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>23:34:24.528384</td>\n",
       "      <td>True</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552479</td>\n",
       "      <td>0.797070</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>True</td>\n",
       "      <td>0.495809</td>\n",
       "      <td>0.950973</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.432134</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>23:34:24.703160</td>\n",
       "      <td>True</td>\n",
       "      <td>0.581996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>True</td>\n",
       "      <td>0.481629</td>\n",
       "      <td>0.529480</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>True</td>\n",
       "      <td>0.384646</td>\n",
       "      <td>0.539312</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.719918</td>\n",
       "      <td>0.515527</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>23:34:24.890510</td>\n",
       "      <td>True</td>\n",
       "      <td>0.773483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611251</td>\n",
       "      <td>0.514665</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>True</td>\n",
       "      <td>0.612740</td>\n",
       "      <td>0.621241</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.946606</td>\n",
       "      <td>0.787672</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>23:34:25.084281</td>\n",
       "      <td>True</td>\n",
       "      <td>0.967570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.306008</td>\n",
       "      <td>0.290677</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>23:34:25.288224</td>\n",
       "      <td>True</td>\n",
       "      <td>0.306261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579755</td>\n",
       "      <td>0.323987</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>True</td>\n",
       "      <td>0.407276</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.697518</td>\n",
       "      <td>0.497054</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>23:34:25.504385</td>\n",
       "      <td>True</td>\n",
       "      <td>0.557703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>True</td>\n",
       "      <td>0.635177</td>\n",
       "      <td>0.498495</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>True</td>\n",
       "      <td>0.524572</td>\n",
       "      <td>0.584592</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.855438</td>\n",
       "      <td>0.747790</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>23:34:25.733829</td>\n",
       "      <td>True</td>\n",
       "      <td>0.761694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>True</td>\n",
       "      <td>0.929841</td>\n",
       "      <td>0.810269</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900978</td>\n",
       "      <td>0.891672</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  noise  offset  rate  0_validation_accuracy  0_test_accuracy  \\\n",
       "0     5.0    0.1     0.1  0.03               0.258346         0.479362   \n",
       "1     5.0    0.1     0.3  0.03               0.516995         0.662710   \n",
       "2     5.0    0.1     0.6  0.03               0.877515         0.796200   \n",
       "3    15.0    0.1     0.1  0.03               0.629959         0.432134   \n",
       "4    15.0    0.1     0.3  0.03               0.719918         0.515527   \n",
       "5    15.0    0.1     0.6  0.03               0.946606         0.787672   \n",
       "6    30.0    0.1     0.1  0.03               0.306008         0.290677   \n",
       "7    30.0    0.1     0.3  0.03               0.697518         0.497054   \n",
       "8    30.0    0.1     0.6  0.03               0.855438         0.747790   \n",
       "\n",
       "     time_0             date  0_finished  1_validation_accuracy  ...  \\\n",
       "0  0.000251  23:34:24.198639        True               0.100439  ...   \n",
       "1  0.000229  23:34:24.360379        True               0.545112  ...   \n",
       "2  0.000246  23:34:24.528384        True               0.802632  ...   \n",
       "3  0.000278  23:34:24.703160        True               0.581996  ...   \n",
       "4  0.000279  23:34:24.890510        True               0.773483  ...   \n",
       "5  0.000295  23:34:25.084281        True               0.967570  ...   \n",
       "6  0.000313  23:34:25.288224        True               0.306261  ...   \n",
       "7  0.000312  23:34:25.504385        True               0.557703  ...   \n",
       "8  0.000336  23:34:25.733829        True               0.761694  ...   \n",
       "\n",
       "     time_2  2_finished  3_validation_accuracy  3_test_accuracy    time_3  \\\n",
       "0  0.000227        True               0.119856         0.378851  0.000248   \n",
       "1  0.000233        True               0.629369         0.577808  0.000254   \n",
       "2  0.000226        True               0.552479         0.797070  0.000233   \n",
       "3  0.000274        True               0.481629         0.529480  0.000282   \n",
       "4  0.000299        True               0.611251         0.514665  0.000285   \n",
       "5  0.000268        True               1.000000         0.900374  0.000269   \n",
       "6  0.000323        True               0.579755         0.323987  0.000327   \n",
       "7  0.000320        True               0.635177         0.498495  0.000351   \n",
       "8  0.000337        True               0.929841         0.810269  0.000323   \n",
       "\n",
       "   3_finished  4_validation_accuracy  4_test_accuracy    time_4  4_finished  \n",
       "0        True               0.049509         0.492394  0.000237        True  \n",
       "1        True               0.638762         0.629643  0.000224        True  \n",
       "2        True               0.495809         0.950973  0.000237        True  \n",
       "3        True               0.384646         0.539312  0.000279        True  \n",
       "4        True               0.612740         0.621241  0.000265        True  \n",
       "5        True               1.000000         0.845161  0.000283        True  \n",
       "6        True               0.407276         0.261914  0.000323        True  \n",
       "7        True               0.524572         0.584592  0.000300        True  \n",
       "8        True               0.900978         0.891672  0.000308        True  \n",
       "\n",
       "[9 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "experiment 0: 0.2583461342632857 == 0.25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112641/583737169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_dummy_experiment_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dummy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jaume/workspace/remote/block-types/block_types/utils/nbdev_utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_func, data_func, do, include, debug, exclude, tag, show, store)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'running {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mtest_func\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_112641/936693335.py\u001b[0m in \u001b[0;36mtest_dummy_experiment_manager\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0_validation_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;36m1.e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"experiment {experiment_id}: {df.loc[experiment_id, '0_validation_accuracy']} == {validation_accuracy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0_test_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;36m1.e-10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: experiment 0: 0.2583461342632857 == 0.25"
     ]
    }
   ],
   "source": [
    "tst.run (test_dummy_experiment_manager, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (athena_old)",
   "language": "python",
   "name": "athena_old"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
