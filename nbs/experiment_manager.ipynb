{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp experiment_manager\n",
    "from nbdev.showdoc import *\n",
    "from block_types.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Manager\n",
    "\n",
    "> Main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# coding: utf-8\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.utils import Bunch\n",
    "import platform\n",
    "import pprint\n",
    "import subprocess\n",
    "import json\n",
    "from multiprocessing import Process\n",
    "import logging\n",
    "import traceback\n",
    "import shutil\n",
    "from fastcore.utils import store_attr\n",
    "\n",
    "from block_types.utils.utils import set_logger, set_verbosity\n",
    "\n",
    "# hpsearch core API\n",
    "from hpsearch.config.manager_factory import ManagerFactory\n",
    "from hpsearch.utils import experiment_utils\n",
    "from hpsearch.utils.experiment_utils import remove_defaults\n",
    "from hpsearch.utils.organize_experiments import remove_defaults_from_experiment_data\n",
    "import hpsearch.config.hp_defaults as dflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import pytest\n",
    "import os\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from block_types.utils.nbdev_utils import md\n",
    "\n",
    "from hpsearch.examples.complex_dummy_experiment_manager import init_em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExperimentManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExperimentManager (object):\n",
    "\n",
    "    def __init__ (self, \n",
    "                  allow_base_class=dflt.allow_base_class,\n",
    "                  path_experiments=dflt.path_experiments,\n",
    "                  defaults=dflt.defaults,\n",
    "                  root=dflt.root,\n",
    "                  metric=dflt.metric,\n",
    "                  op=dflt.op,\n",
    "                  alternative_root_path=None,\n",
    "                  path_data=None,\n",
    "                  name_model_history=dflt.name_model_history,\n",
    "                  model_file_name=dflt.model_file_name,\n",
    "                  name_epoch=dflt.name_epoch,\n",
    "                  result_file=dflt.result_file, \n",
    "                  target_model_file=None,\n",
    "                  destination_model_file=None,\n",
    "                  root_folder=None,\n",
    "                  manager_path=dflt.manager_path,\n",
    "                  logger=None,\n",
    "                  verbose: int = dflt.verbose,\n",
    "                  name_logger:str = dflt.name_logger\n",
    "                 ):\n",
    "        \n",
    "        #store_attr ()\n",
    "        if True:\n",
    "            self.allow_base_class = allow_base_class\n",
    "            self.path_experiments = path_experiments\n",
    "            self.defaults = defaults\n",
    "            self.key_score = metric\n",
    "            self.root = root\n",
    "            self.metric = metric\n",
    "            self.op = op\n",
    "            self.alternative_root_path = alternative_root_path\n",
    "            self.path_data = path_data\n",
    "            self.name_model_history = name_model_history\n",
    "            self.model_file_name = model_file_name\n",
    "            self.name_epoch = name_epoch\n",
    "            self.result_file = result_file\n",
    "            self.target_model_file = target_model_file\n",
    "            self.destination_model_file = destination_model_file\n",
    "            self.name_logger = name_logger\n",
    "            self.logger = logger\n",
    "            self.verbose = verbose\n",
    "            self.root_folder = root_folder\n",
    "            self.manager_path = manager_path\n",
    "        \n",
    "        class_name = self.__class__.__name__\n",
    "        self.registered_name = (f'{class_name}-default' if self.root_folder is None\n",
    "                                else f'{class_name}-{self.root_folder}')\n",
    "        \n",
    "        if self.logger is None:\n",
    "            self.logger = set_logger (self.name_logger, path_results=self.path_experiments, verbose=self.verbose)\n",
    "        \n",
    "        self.key_score = metric\n",
    "        self.root_folder = self.root\n",
    "        self.parameters_non_pickable = {}\n",
    "        self.default_operations = dict(root=root,\n",
    "                                       metric=metric,\n",
    "                                       op=op)\n",
    "        self.manager_factory = ManagerFactory(allow_base_class=allow_base_class, \n",
    "                                              manager_path=self.manager_path)\n",
    "        self.manager_factory.register_manager (self)\n",
    "        self.non_pickable_fields = ['manager_factory', 'parameters_non_pickable',\n",
    "                                    'logger']\n",
    "\n",
    "    def set_verbose (self, verbose):\n",
    "        self.verbose = verbose\n",
    "        set_verbosity (logger=self.logger, verbose=verbose)\n",
    "    \n",
    "    def get_default_parameters (self, parameters):\n",
    "        if not self.allow_base_class:\n",
    "            raise ImportError ('call get_default_parameters from base class is not allowed')\n",
    "        return self.defaults\n",
    "    \n",
    "    def get_default_operations (self):\n",
    "        return self.default_operations\n",
    "\n",
    "    def get_path_experiments (self, path_experiments=None, folder=None):\n",
    "        \"\"\"Gives the root path to the folder where results of experiments are stored.\"\"\"\n",
    "        path_experiments = (path_experiments if path_experiments is not None \n",
    "                            else self.path_experiments)\n",
    "        if folder != None: path_experiments = f'{path_experiments}/{folder}'\n",
    "        return path_experiments\n",
    "\n",
    "    def get_path_experiment (self, experiment_id, root_path=None, root_folder=None):\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        path_experiment = f'{root_path}/experiments/{experiment_id:05d}'\n",
    "        return path_experiment\n",
    "\n",
    "    def get_path_results (self, experiment_id=None, run_number=0, root_path=None, root_folder=None, path_experiment=None):\n",
    "        assert experiment_id is not None or path_experiment is not None\n",
    "        if path_experiment is None:\n",
    "            path_experiment = path_experiment = self.get_path_experiment (experiment_id, root_path=root_path, root_folder=root_folder)\n",
    "        path_results = f'{path_experiment}/{run_number}'\n",
    "        return path_results\n",
    "    \n",
    "    def get_path_alternative (self, path_results, root_path=None, alternative_root_path=None):\n",
    "        alternative_root_path = alternative_root_path if alternative_root_path is not None else self.alternative_root_path \n",
    "        if alternative_root_path is None:\n",
    "            return path_results\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments (folder=self.root_folder)\n",
    "        path_alternative = path_results.replace (root_path, alternative_root_path)\n",
    "\n",
    "        return path_alternative\n",
    "\n",
    "    def get_path_data (self, run_number, root_path=None, parameters={}):\n",
    "        if self.path_data is None:\n",
    "            if root_path is None:\n",
    "                root_path = self.get_path_experiments()\n",
    "            return f'{root_path}/data'\n",
    "        else:\n",
    "            return self.path_data\n",
    "    \n",
    "    def get_experiment_data (self, path_experiments=None, folder_experiments=None, experiments=None):\n",
    "        path_experiments = self.get_path_experiments(path_experiments=path_experiments, \n",
    "                                                    folder=folder_experiments)\n",
    "        path_csv = '%s/experiments_data.csv' %path_experiments\n",
    "        path_pickle = path_csv.replace('csv', 'pk')\n",
    "        if os.path.exists (path_pickle):\n",
    "            experiment_data = pd.read_pickle (path_pickle)\n",
    "        else:\n",
    "            experiment_data = pd.read_csv (path_csv, index_col=0)\n",
    "        if experiments is not None:\n",
    "            experiment_data = experiment_data.loc[experiments,:]\n",
    "            \n",
    "        return experiment_data\n",
    "    \n",
    "    def get_key_score (self, other_parameters):\n",
    "        key_score = other_parameters.get('key_score')\n",
    "        suffix_results = other_parameters.get('suffix_results', '')\n",
    "        if key_score is None and (len(suffix_results) > 0):\n",
    "            if suffix_results[0] == '_':\n",
    "                key_score = suffix_results[1:]\n",
    "            else:\n",
    "                key_score = suffix_results\n",
    "        key_score = self.key_score if key_score is None else key_score\n",
    "        \n",
    "        return key_score\n",
    "    \n",
    "    def get_name_epoch (self, other_parameters):\n",
    "        return other_parameters.get ('name_epoch', self.name_epoch)\n",
    "    \n",
    "    def remove_previous_experiments (self, path_experiments = None, folder = None):\n",
    "        path_experiments = self.get_path_experiments (path_experiments=path_experiments, \n",
    "                                                      folder=folder)\n",
    "        if os.path.exists (path_experiments):\n",
    "            shutil.rmtree (path_experiments)\n",
    "\n",
    "    def experiment_visualization (self, **kwargs):\n",
    "        raise ValueError ('this type of experiment visualization is not recognized')\n",
    "\n",
    "    def run_experiment_pipeline (self, run_number=0, path_results='./results', parameters = {}):\n",
    "        \"\"\" Runs complete learning pipeline: loading / generating data, building and learning model, applying it to data,\n",
    "        and evaluating it.\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        # record all parameters except for non-pickable ones\n",
    "        record_parameters (path_results, parameters)\n",
    "\n",
    "        # integrate non-pickable parameters into global dictionary\n",
    "        parameters.update (self.parameters_non_pickable)\n",
    "        self.parameters_non_pickable = {}\n",
    "\n",
    "        # #####################################\n",
    "        # Evaluation\n",
    "        # #####################################\n",
    "        time_before = time.time()\n",
    "        score_dict = self._run_experiment (parameters=parameters, path_results=path_results, run_number=run_number)\n",
    "        self.logger.info ('time spent on this experiment: {}'.format(time.time()-time_before))\n",
    "\n",
    "        # #####################################\n",
    "        # Final scores\n",
    "        # #####################################\n",
    "        score_name = parameters.get('suffix_results','')\n",
    "        if len(score_name) > 0:\n",
    "            if score_name[0] == '_':\n",
    "                score_name = score_name[1:]\n",
    "            if score_dict.get(score_name) is not None:\n",
    "                self.logger.info (f'score: {score_dict.get(score_name)}')\n",
    "\n",
    "        spent_time = time.time() - time_before\n",
    "\n",
    "        return score_dict, spent_time\n",
    "\n",
    "    # *************************************************************************\n",
    "    #   run_experiment methods\n",
    "    # *************************************************************************\n",
    "    def _run_experiment (self, parameters={}, path_results='./results', run_number=None):\n",
    "\n",
    "        parameters['run_number'] = run_number\n",
    "\n",
    "        # wrap parameters\n",
    "        parameters = Bunch(**parameters)\n",
    "\n",
    "        if parameters.get('use_process', False):\n",
    "            return self.run_experiment_in_separate_process (parameters, path_results)\n",
    "        else:\n",
    "            return self.run_experiment (parameters=parameters, path_results=path_results)\n",
    "\n",
    "    def run_experiment_in_separate_process (self, parameters={}, path_results='./results'):\n",
    "\n",
    "        parameters['return_results']=False\n",
    "        p = Process(target=self.run_experiment_saving_results, args=(parameters, path_results))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        if p.exitcode != 0:\n",
    "            self.logger.warning ('process exited with non-zero code: there might be an error '\n",
    "                                 'in run_pipeline function')\n",
    "\n",
    "        path_dict_results = f'{path_results}/dict_results.pk'\n",
    "        try:\n",
    "            dict_results = pickle.load (open (path_dict_results, 'rb'))\n",
    "        except FileNotFoundError:\n",
    "            raise RuntimeError (f'{path_dict_results} not found: probably there is an error in run_pipeline'\n",
    "                                'function. Please run in debug mode, without multi-processing')\n",
    "\n",
    "        return dict_results\n",
    "\n",
    "    def run_experiment_saving_results (self, parameters={}, path_results='./results'):\n",
    "        dict_results = self.run_experiment (parameters=parameters, path_results=path_results)\n",
    "        pickle.dump (dict_results, open ('%s/dict_results.pk' %path_results, 'wb'))\n",
    "\n",
    "    def run_experiment (self, parameters={}, path_results='./results'):\n",
    "        raise NotImplementedError ('This method needs to be defined in subclass')\n",
    "\n",
    "\n",
    "    # *************************************************************************\n",
    "    # *************************************************************************\n",
    "    def create_experiment_and_run (self, parameters = {}, other_parameters = {}, root_path=None, \n",
    "                                   run_number=0, log_message=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # ****************************************************\n",
    "        #  preliminary set-up: logger and root_path\n",
    "        # ****************************************************\n",
    "        if log_message is not None:\n",
    "            self.logger.info ('**************************************************')\n",
    "            self.logger.info (log_message)\n",
    "            self.logger.info ('**************************************************')\n",
    "            other_parameters['log_message'] = log_message\n",
    "\n",
    "        # insert path to experiment script file that called the experiment manager\n",
    "        other_parameters = other_parameters.copy()\n",
    "        insert_experiment_script_path (other_parameters, self.logger)\n",
    "\n",
    "        # get root_path and create directories\n",
    "        if root_path is None:\n",
    "            root_folder = self.get_parameter (other_parameters, 'root_folder')\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        os.makedirs (root_path, exist_ok = True)\n",
    "\n",
    "        # ****************************************************\n",
    "        # register (subclassed) manager so that it can be used by decoupled modules\n",
    "        # ****************************************************\n",
    "        self.register_and_store_subclassed_manager ()\n",
    "\n",
    "        # ****************************************************\n",
    "        #   get experiment number given parameters\n",
    "        # ****************************************************\n",
    "        parameters = remove_defaults (parameters)\n",
    "\n",
    "        path_csv = '%s/experiments_data.csv' %root_path\n",
    "        path_pickle = path_csv.replace('csv', 'pk')\n",
    "        experiment_number, experiment_data = load_or_create_experiment_values (\n",
    "            path_csv, parameters, precision=other_parameters.get('precision', 1e-15)\n",
    "        )\n",
    "\n",
    "        #save_other_parameters (experiment_number, other_parameters, root_path)\n",
    "\n",
    "        # if old experiment, we can require that given parameters match with experiment number\n",
    "        if (other_parameters.get('experiment_number') is not None \n",
    "            and experiment_number != other_parameters.get('experiment_number')):\n",
    "            raise ValueError (f'expected number: {other_parameters.get(\"experiment_number\")}, '\n",
    "                              f'found: {experiment_number}')\n",
    "        other_parameters['experiment_number'] = experiment_number\n",
    "\n",
    "        # ****************************************************\n",
    "        # get key_score and suffix_results\n",
    "        # ****************************************************\n",
    "        key_score = self.get_key_score (other_parameters)\n",
    "        if key_score is not None:\n",
    "            suffix_results = f'_{key_score}'\n",
    "            other_parameters['suffix_results'] = suffix_results\n",
    "\n",
    "        # ****************************************************\n",
    "        #   get run_id, if not given\n",
    "        # ****************************************************\n",
    "        if run_number is None:\n",
    "            run_number = 0\n",
    "            name_score = '%d%s' %(run_number, suffix_results)\n",
    "            while not isnull(experiment_data, experiment_number, name_score):\n",
    "                self.logger.info ('found previous run for experiment number {}, run {}, with score {} = {}'.format(experiment_number, run_number, key_score, experiment_data.loc[experiment_number, name_score]))\n",
    "                run_number += 1\n",
    "                name_score = '%d%s' %(run_number, suffix_results)\n",
    "            self.logger.info ('starting experiment {} with run number {}'.format(experiment_number, run_number))\n",
    "\n",
    "        else:\n",
    "            name_score = '%d%s' %(run_number, suffix_results)\n",
    "            if not isnull(experiment_data, experiment_number, name_score):\n",
    "                previous_result = experiment_data.loc[experiment_number, name_score]\n",
    "                self.logger.info ('found completed: experiment number: %d, run number: %d - score: %f' %(experiment_number, run_number, previous_result))\n",
    "                self.logger.info (parameters)\n",
    "                if other_parameters.get('repeat_experiment', False):\n",
    "                    self.logger.info ('redoing experiment')\n",
    "\n",
    "        # ****************************************************\n",
    "        #   remove unfinished experiments\n",
    "        # ****************************************************\n",
    "        if other_parameters.get('remove_not_finished', False):\n",
    "            name_finished = '%d_finished' %run_number\n",
    "            if not isnull(experiment_data, experiment_number, name_finished):\n",
    "                finished = experiment_data.loc[experiment_number, name_finished]\n",
    "                self.logger.info (f'experiment {experiment_number}, run number {run_number}, finished {finished}')\n",
    "                if not finished:\n",
    "                    experiment_data.loc[experiment_number, name_score] = None\n",
    "                    experiment_data.to_csv (path_csv)\n",
    "                    experiment_data.to_pickle (path_pickle)\n",
    "                    self.logger.info (f'removed experiment {experiment_number}, '\n",
    "                                 f'run number {run_number}, finished {finished}')\n",
    "            if other_parameters.get('only_remove_not_finished', False):\n",
    "                return None, {}\n",
    "\n",
    "        unfinished_flag = False\n",
    "        name_epoch = self.get_name_epoch(other_parameters)\n",
    "        current_path_results = self.get_path_results (experiment_number, run_number=run_number, \n",
    "                                                      root_path=root_path)\n",
    "\n",
    "        # ****************************************************\n",
    "        #   check conditions for skipping experiment\n",
    "        # ****************************************************\n",
    "        if (not isnull(experiment_data, experiment_number, name_score) \n",
    "            and not other_parameters.get('repeat_experiment', False)):\n",
    "            if (other_parameters.get('check_finished', False) \n",
    "                and not self.finished_all_epochs (parameters, current_path_results, name_epoch)):\n",
    "                unfinished_flag = True\n",
    "            else:\n",
    "                self.logger.info ('skipping...')\n",
    "                return previous_result, {key_score: previous_result}\n",
    "        elif (isnull(experiment_data, experiment_number, name_score) \n",
    "              and other_parameters.get('recompute_metrics', False) \n",
    "              and not other_parameters.get('force_recompute_metrics', False)):\n",
    "            self.logger.info (f'experiment not found, skipping {run_number} due to only recompute_metrics')\n",
    "            return None, {}\n",
    "        \n",
    "        # ****************************************************\n",
    "        # log info\n",
    "        # ****************************************************\n",
    "        self.logger.info ('running experiment %d' %experiment_number)\n",
    "        self.logger.info ('run number: %d' %run_number)\n",
    "        self.logger.info ('\\nparameters:\\n%s' %mypprint(parameters))\n",
    "\n",
    "        # ****************************************************\n",
    "        #  get paths\n",
    "        # ****************************************************\n",
    "        # path_root_experiment folder\n",
    "        path_root_experiment = self.get_path_experiment (experiment_number, root_path=root_path)\n",
    "        os.makedirs (path_root_experiment, exist_ok=True)\n",
    "\n",
    "        # path_results folder (where results are)\n",
    "        path_results = self.get_path_results (run_number=run_number, path_experiment=path_root_experiment)\n",
    "        os.makedirs (path_results, exist_ok=True)\n",
    "\n",
    "        # path to save big files\n",
    "        path_results_big_size = self.get_path_alternative (path_results)\n",
    "        os.makedirs (path_results_big_size, exist_ok = True)\n",
    "        other_parameters['path_results_big'] = path_results_big_size\n",
    "\n",
    "        # ****************************************************\n",
    "        # get git and record parameters\n",
    "        # ****************************************************\n",
    "        # get git revision number\n",
    "        other_parameters['git_hash'] = get_git_revision_hash(root_path)\n",
    "\n",
    "        # write parameters in root experiment folder\n",
    "        record_parameters (path_root_experiment, parameters, other_parameters)\n",
    "\n",
    "        # store hyper_parameters in dictionary that maps experiment_number with hyper_parameter values\n",
    "        store_parameters (root_path, experiment_number, parameters)\n",
    "\n",
    "        # ****************************************************************\n",
    "        # loggers\n",
    "        # ****************************************************************\n",
    "        logger_experiment = set_logger (\"experiment\", path_results, verbose=self.verbose)\n",
    "        logger_experiment.info (f'script: {other_parameters[\"script_path\"]}, line number: {other_parameters[\"lineno\"]}')\n",
    "        if os.path.exists(other_parameters['script_path']):\n",
    "            shutil.copy (other_parameters['script_path'], path_results)\n",
    "            shutil.copy (other_parameters['script_path'], path_root_experiment)\n",
    "\n",
    "        # summary logger\n",
    "        logger_summary = set_logger (\"summary\", root_path, mode='w', stdout=False, just_message=True, \n",
    "                                     filename='summary.txt', verbose_out=self.verbose)\n",
    "        logger_summary.info ('\\n\\n{}\\nexperiment: {}, run: {}\\nscript: {}, line number: {}\\nparameters:\\n{}{}'.format('*'*100, experiment_number, run_number, other_parameters['script_path'], other_parameters['lineno'], mypprint(parameters), '*'*100))\n",
    "        if other_parameters.get('rerun_script') is not None:\n",
    "            logger_summary.info ('\\nre-run:\\n{}'.format(other_parameters['rerun_script']))\n",
    "        # same file in path_results\n",
    "        logger_summary2 = set_logger (\"summary\", path_results, mode='w', stdout=False, \n",
    "                                      just_message=True, filename='summary.txt', verbose_out=self.verbose)\n",
    "        logger_summary2.info ('\\n\\n{}\\nexperiment: {}, run: {}\\nscript: {}, line number: {}\\nparameters:\\n{}{}'.format('*'*100, experiment_number, run_number, other_parameters['script_path'], other_parameters['lineno'], mypprint(parameters), '*'*100))\n",
    "\n",
    "        # ****************************************************************\n",
    "        # Do final adjustments to parameters\n",
    "        # ****************************************************************\n",
    "        parameters = parameters.copy()\n",
    "        original_parameters = parameters.copy()\n",
    "        parameters.update(other_parameters)\n",
    "\n",
    "        # add default parameters - their values are overwritten by input values, if given\n",
    "        defaults = self.get_default_parameters(parameters)\n",
    "        parameters_with_defaults = defaults.copy()\n",
    "        parameters_with_defaults.update(parameters)\n",
    "        parameters = parameters_with_defaults\n",
    "\n",
    "        # ***********************************************************\n",
    "        # resume from previous experiment \n",
    "        # ***********************************************************\n",
    "        if (isnull(experiment_data, experiment_number, name_score) \n",
    "            and other_parameters.get('check_finished_if_interrupted', False)\n",
    "            and not self.finished_all_epochs (parameters, current_path_results, name_epoch)):\n",
    "            unfinished_flag = True\n",
    "        \n",
    "        resuming_from_prev_epoch_flag = False\n",
    "        if parameters.get('prev_epoch', False):\n",
    "            self.logger.info('trying prev_epoch')\n",
    "            experiment_data2 = experiment_data.copy()\n",
    "            if (not unfinished_flag \n",
    "                and (other_parameters.get('repeat_experiment', False) \n",
    "                     or isnull(experiment_data, experiment_number, name_score))):\n",
    "                    experiment_data2 = experiment_data2.drop(experiment_number,axis=0)\n",
    "            prev_experiment_number = self.find_closest_epoch (experiment_data2, original_parameters, \n",
    "                                                              name_epoch=name_epoch)\n",
    "            if prev_experiment_number is not None:\n",
    "                self.logger.info(f'using prev_epoch: {prev_experiment_number}')\n",
    "                prev_path_results = self.get_path_results (prev_experiment_number, \n",
    "                                                           run_number=run_number, \n",
    "                                                           root_path=root_path)\n",
    "                found = self.make_resume_from_checkpoint (parameters, prev_path_results)\n",
    "                if found:\n",
    "                    self.logger.info (f'found previous exp: {prev_experiment_number}')\n",
    "                    if prev_experiment_number == experiment_number:\n",
    "                        if 'use_previous_best' not in other_parameters:\n",
    "                            other_parameters['use_previous_best'] = parameters.get('use_previous_best', \n",
    "                                                                                   dflt.use_previous_best)\n",
    "                        if not other_parameters['use_previous_best'] and unfinished_flag:\n",
    "                            prev_epoch = self.get_last_epoch (parameters, \n",
    "                                                              current_path_results, \n",
    "                                                              name_epoch)\n",
    "                            prev_epoch = max (int(prev_epoch), 0)\n",
    "                            parameters[name_epoch] = parameters[name_epoch] - prev_epoch\n",
    "                        self.logger.info ('using previous best')\n",
    "                    else:\n",
    "                        prev_epoch = experiment_data.loc[prev_experiment_number,name_epoch]\n",
    "                        prev_epoch = (int(prev_epoch) if prev_epoch is not None \n",
    "                                      else defaults.get(name_epoch))\n",
    "                        parameters[name_epoch] = parameters[name_epoch] - prev_epoch\n",
    "\n",
    "                resuming_from_prev_epoch_flag = found\n",
    "                \n",
    "\n",
    "        if not resuming_from_prev_epoch_flag and parameters.get('from_exp', None) is not None:\n",
    "            prev_experiment_number = parameters.get('from_exp', None)\n",
    "            self.logger.info('using previous experiment %d' %prev_experiment_number)\n",
    "            prev_path_results = self.get_path_results (prev_experiment_number, run_number=run_number, \n",
    "                                                       root_path=root_path)\n",
    "            self.make_resume_from_checkpoint (parameters, prev_path_results, use_best=True)\n",
    "\n",
    "        # ****************************************************************\n",
    "        #   Analyze if experiment was interrupted\n",
    "        # ****************************************************************\n",
    "        if parameters.get('skip_interrupted', False):\n",
    "            was_interrumpted = self.exists_current_checkpoint (parameters, path_results)\n",
    "            was_interrumpted = (was_interrumpted or \n",
    "                                self.obtain_last_result (parameters, path_results) is not None)\n",
    "            if was_interrumpted:\n",
    "                self.logger.info ('found intermediate results, skipping...')\n",
    "                return None, {}\n",
    "\n",
    "        # ****************************************************************\n",
    "        # retrieve last results in interrupted experiments\n",
    "        # ****************************************************************\n",
    "        run_pipeline = True\n",
    "        if parameters.get('use_last_result', False):\n",
    "            experiment_result = self.obtain_last_result (parameters, path_results)\n",
    "            if experiment_result is None and parameters.get('run_if_not_interrumpted', False):\n",
    "                run_pipeline = True\n",
    "            elif experiment_result is None:\n",
    "                return None, {}\n",
    "            else:\n",
    "                run_pipeline = False\n",
    "\n",
    "        # ****************************************************************\n",
    "        # run experiment\n",
    "        # ****************************************************************\n",
    "        if run_pipeline:\n",
    "            experiment_result, time_spent = self.run_experiment_pipeline (run_number,\n",
    "                                        path_results,\n",
    "                                        parameters=parameters)\n",
    "            finished = True\n",
    "        else:\n",
    "            finished = False\n",
    "\n",
    "        # ****************************************************************\n",
    "        #  Retrieve and store results\n",
    "        # ****************************************************************\n",
    "        if type(experiment_result)==dict:\n",
    "            dict_results = experiment_result\n",
    "            for key in dict_results.keys():\n",
    "                if key != '':\n",
    "                    experiment_data.loc[experiment_number, '%d_%s' %(run_number, key)]=dict_results[key]\n",
    "                else:\n",
    "                    experiment_data.loc[experiment_number, '%d' %run_number]=dict_results[key]\n",
    "                self.logger.info('{} - {}: {}'.format(run_number, key, dict_results[key]))\n",
    "        else:\n",
    "            experiment_data.loc[experiment_number, name_score]=experiment_result\n",
    "            self.logger.info('{} - {}: {}'.format(run_number, name_score, experiment_result))\n",
    "            dict_results = {name_score:experiment_result}\n",
    "\n",
    "        if isnull(experiment_data, experiment_number, 'time_'+str(run_number)) and finished:\n",
    "            experiment_data.loc[experiment_number,'time_'+str(run_number)]=time_spent\n",
    "        experiment_data.loc[experiment_number, 'date']=datetime.datetime.time(datetime.datetime.now())\n",
    "        experiment_data.loc[experiment_number, '%d_finished' %run_number]=finished\n",
    "\n",
    "        experiment_data.to_csv(path_csv)\n",
    "        experiment_data.to_pickle(path_pickle)\n",
    "\n",
    "        try:\n",
    "            save_other_parameters (experiment_number, other_parameters, root_path)\n",
    "        except:\n",
    "            print (f'error saving other parameters')\n",
    "\n",
    "        logger_summary2.info ('\\nresults:\\n{}'.format(dict_results))\n",
    "        self.logger.info ('finished experiment %d' %experiment_number)\n",
    "\n",
    "        # return final score\n",
    "        result = dict_results.get(key_score)\n",
    "        return result, dict_results\n",
    "\n",
    "    def grid_search (self, parameters_multiple_values={}, parameters_single_value={}, other_parameters = {},\n",
    "                     root_path=None, run_numbers=[0], random_search=False,\n",
    "                     load_previous=False, log_message='', nruns = None, keep='multiple'):\n",
    "\n",
    "        other_parameters = other_parameters.copy()\n",
    "\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "        if nruns is not None:\n",
    "            run_numbers = range (nruns)\n",
    "\n",
    "        if root_path is None:\n",
    "            root_folder = self.get_parameter (other_parameters, 'root_folder')\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        path_results_base = root_path\n",
    "\n",
    "        os.makedirs (path_results_base,exist_ok=True)\n",
    "\n",
    "        if keep=='multiple':\n",
    "            parameters_single_value = {k:parameters_single_value[k] for k in parameters_single_value.keys() if k not in parameters_multiple_values}\n",
    "        elif keep=='single':\n",
    "            parameters_multiple_values = {k:parameters_multiple_values[k] for k in parameters_multiple_values.keys() if k not in parameters_single_value}\n",
    "        else:\n",
    "            raise ValueError ('parameter keep {} not recognized: it must be either multiple or single'.format(keep))\n",
    "\n",
    "        parameters_multiple_values_all = parameters_multiple_values\n",
    "        parameters_multiple_values_all = list(ParameterGrid(parameters_multiple_values_all))\n",
    "\n",
    "        if log_message != '':\n",
    "            other_parameters['log_message'] = log_message\n",
    "        insert_experiment_script_path (other_parameters, self.logger)\n",
    "\n",
    "        if random_search:\n",
    "            path_random_hp = '%s/random_hp.pk' %path_results_base\n",
    "            if load_previous and os.path.exists(path_random_hp):\n",
    "                parameters_multiple_values_all = pickle.load(open(path_random_hp,'rb'))\n",
    "            else:\n",
    "                parameters_multiple_values_all = list(np.random.permutation(parameters_multiple_values_all))\n",
    "                pickle.dump (parameters_multiple_values_all, open(path_random_hp,'wb'))\n",
    "        for (i_hp, parameters_multiple_values) in enumerate(parameters_multiple_values_all):\n",
    "            parameters = parameters_multiple_values.copy()\n",
    "            parameters.update(parameters_single_value)\n",
    "\n",
    "            for (i_run, run_number) in enumerate(run_numbers):\n",
    "                self.logger.info('processing hyper-parameter %d out of %d' %(i_hp, len(parameters_multiple_values_all)))\n",
    "                self.logger.info('doing run %d out of %d' %(i_run, len(run_numbers)))\n",
    "                self.logger.info('%s' %log_message)\n",
    "\n",
    "                self.create_experiment_and_run (parameters=parameters, other_parameters = other_parameters,\n",
    "                                           run_number=run_number, root_path=path_results_base)\n",
    "\n",
    "        # This solves an intermitent issue found in TensorFlow (reported as bug by community)\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    def run_multiple_repetitions (self, parameters={}, other_parameters = {},\n",
    "                     root_path=None, log_message='', nruns = None, run_numbers=[0]):\n",
    "\n",
    "        other_parameters = other_parameters.copy()\n",
    "\n",
    "        if nruns is not None:\n",
    "            run_numbers = range (nruns)\n",
    "        \n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=other_parameters.get('root_folder'))\n",
    "        os.makedirs (root_path, exist_ok = True)\n",
    "            \n",
    "        results = np.zeros((len(run_numbers),))\n",
    "        for (i_run, run_number) in enumerate(run_numbers):\n",
    "                self.logger.info('doing run %d out of %d' %(i_run, len(run_numbers)))\n",
    "                self.logger.info('%s' %log_message)\n",
    "\n",
    "                results[i_run], dict_results  = self.create_experiment_and_run (\n",
    "                    parameters=parameters, other_parameters = other_parameters,\n",
    "                    run_number=run_number, root_path=root_path)\n",
    "                if dict_results.get('is_pruned', False):\n",
    "                    break\n",
    "\n",
    "        mu, std = results.mean(), results.std()\n",
    "        self.logger.info ('mean {}: {}, std: {}'.format(other_parameters.get('key_score',''), mu, std))\n",
    "\n",
    "        dict_results[other_parameters.get('key_score','cost')] = mu\n",
    "\n",
    "        return mu, std, dict_results\n",
    "\n",
    "\n",
    "    def hp_optimization (self, parameter_sampler=None, root_path=None, log_message=None, \n",
    "                         parameters={}, other_parameters={}, nruns=None):\n",
    "\n",
    "        import optuna\n",
    "        from optuna.pruners import SuccessiveHalvingPruner, MedianPruner\n",
    "        from optuna.samplers import RandomSampler, TPESampler\n",
    "        from optuna.integration.skopt import SkoptSampler\n",
    "        \n",
    "        optuna.logging.disable_propagation()\n",
    "\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder  = other_parameters.get('root_folder'))\n",
    "\n",
    "        other_parameters = other_parameters.copy()\n",
    "\n",
    "        os.makedirs(root_path, exist_ok=True)\n",
    "        if log_message != '':\n",
    "            other_parameters['log_message'] = log_message\n",
    "        insert_experiment_script_path (other_parameters, self.logger)\n",
    "\n",
    "        # n_warmup_steps: Disable pruner until the trial reaches the given number of step.\n",
    "        sampler_method = other_parameters.get('sampler_method', 'random')\n",
    "        pruner_method = other_parameters.get('pruner_method', 'halving')\n",
    "        n_evaluations = other_parameters.get('n_evaluations', 20)\n",
    "        seed = other_parameters.get('seed', 0)\n",
    "        if sampler_method == 'random':\n",
    "            sampler = RandomSampler(seed=seed)\n",
    "        elif sampler_method == 'tpe':\n",
    "            sampler = TPESampler(n_startup_trials=other_parameters.get('n_startup_trials', 5), \n",
    "                                 seed=seed)\n",
    "        elif sampler_method == 'skopt':\n",
    "            # cf https://scikit-optimize.github.io/#skopt.Optimizer\n",
    "            # GP: gaussian process\n",
    "            # Gradient boosted regression: GBRT\n",
    "            sampler = SkoptSampler(skopt_kwargs={'base_estimator': \"GP\", 'acq_func': 'gp_hedge'})\n",
    "        else:\n",
    "            raise ValueError('Unknown sampler: {}'.format(sampler_method))\n",
    "\n",
    "        if pruner_method == 'halving':\n",
    "            pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=4, \n",
    "                                             min_early_stopping_rate=0)\n",
    "        elif pruner_method == 'median':\n",
    "            pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=n_evaluations // 3)\n",
    "        elif pruner_method == 'none':\n",
    "            # Do not prune\n",
    "            pruner = MedianPruner(n_startup_trials=other_parameters.get('n_trials', 10), \n",
    "                                  n_warmup_steps=n_evaluations)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown pruner: {pruner_method}')\n",
    "\n",
    "        self.logger.info (f'Sampler: {sampler_method} - Pruner: {pruner_method}')\n",
    "\n",
    "        #study = optuna.create_study(sampler=sampler, pruner=pruner)\n",
    "        study_name = other_parameters.get('study_name', 'hp_study')  # Unique identifier of the study.\n",
    "        direction = 'maximize' if self.op=='max' else 'minimize'\n",
    "        study = optuna.create_study(direction=direction,\n",
    "                                    study_name=study_name, \n",
    "                                    storage=f'sqlite:///{root_path}/{study_name}.db',\n",
    "                                    sampler=sampler, pruner=pruner, load_if_exists=True)\n",
    "\n",
    "        key_score = self.get_key_score (other_parameters)\n",
    "        \n",
    "        def objective(trial):\n",
    "\n",
    "            hp_parameters = parameters.copy()\n",
    "            self.parameters_non_pickable = dict(trial=trial)\n",
    "\n",
    "            if parameter_sampler is not None:\n",
    "                hp_parameters.update(parameter_sampler(trial))\n",
    "\n",
    "            if nruns is None:\n",
    "                _, dict_results = self.create_experiment_and_run (\n",
    "                    parameters=hp_parameters, other_parameters=other_parameters, \n",
    "                    root_path=root_path, run_number=other_parameters.get('run_number')\n",
    "                )\n",
    "            else:\n",
    "                mu_best, std_best, dict_results = self.run_multiple_repetitions (\n",
    "                    parameters=hp_parameters, other_parameters=other_parameters, \n",
    "                    root_path=root_path, nruns=nruns\n",
    "                )\n",
    "\n",
    "            if dict_results.get('is_pruned', False):\n",
    "                raise optuna.structs.TrialPruned()\n",
    "            \n",
    "            assert key_score in dict_results, f'metric {key_score} not found in results'\n",
    "\n",
    "            return dict_results[key_score]\n",
    "\n",
    "        study.optimize(objective, n_trials=other_parameters.get('n_trials', 10), \n",
    "                       n_jobs=other_parameters.get('n_jobs', 1))\n",
    "\n",
    "        self.logger.info ('Number of finished trials: {}'.format(len(study.trials)))\n",
    "        self.logger.info ('Best trial:')\n",
    "        trial = study.best_trial\n",
    "        self.logger.info ('Value: {}'.format(trial.value))\n",
    "        self.logger.info ('best params: {}'.format (study.best_params))\n",
    "        best_value = trial.value\n",
    "\n",
    "        nruns_best = other_parameters.get('nruns_best', 0)\n",
    "        if nruns_best > 0:\n",
    "            self.logger.info ('running best configuration %d times' %nruns_best)\n",
    "            parameters.update (study.best_params)\n",
    "            mu_best, std_best, _ = self.run_multiple_repetitions (parameters=parameters, other_parameters = other_parameters,\n",
    "                                            root_path=root_path, nruns=nruns_best)\n",
    "            best_value = mu_best\n",
    "\n",
    "        return best_value\n",
    "\n",
    "    def rerun_experiment (self, experiments=[], run_numbers=[0], nruns=None, root_path=None, \n",
    "                          root_folder = None, other_parameters={}, parameters={}, \n",
    "                          parameter_sampler=None, parameters_multiple_values=None,\n",
    "                          log_message='', only_if_exists=False, check_experiment_matches=True):\n",
    "\n",
    "        other_parameters = other_parameters.copy()\n",
    "\n",
    "        if root_folder is not None:\n",
    "            other_parameters['root_folder'] = root_folder\n",
    "\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=other_parameters.get('root_folder'))\n",
    "\n",
    "        if nruns is not None:\n",
    "            run_numbers = range (nruns)\n",
    "\n",
    "        parameters_original = parameters\n",
    "        other_parameters_original = other_parameters\n",
    "        for experiment_id in experiments:\n",
    "            check_experiment_matches = (check_experiment_matches and \n",
    "                                        parameters_multiple_values is None\n",
    "                                        and parameter_sampler is None)\n",
    "            parameters, other_parameters = load_parameters (em=self,\n",
    "                experiment=experiment_id, root_path=root_path, root_folder=root_folder,\n",
    "                other_parameters=other_parameters_original, parameters=parameters_original,\n",
    "                check_experiment_matches=check_experiment_matches\n",
    "            )\n",
    "\n",
    "            # we need to set the following flag to False, since otherwise when we request to store the intermediate results\n",
    "            # and the experiment did not start, we do not run the experiment\n",
    "            if (other_parameters.get('use_last_result', False) \n",
    "                and not other_parameters_original.get('use_last_result', False)):\n",
    "                self.logger.debug ('changing other_parameters[\"use_last_result\"] to False')\n",
    "                other_parameters['use_last_result'] = False\n",
    "            self.logger.info (f'running experiment {experiment_id} with parameters:\\n{parameters}\\n'\n",
    "                         f'other_parameters:\\n{other_parameters}')\n",
    "\n",
    "            if parameter_sampler is not None:\n",
    "                self.logger.info ('running hp_optimization')\n",
    "                insert_experiment_script_path (other_parameters, self.logger)\n",
    "                self.hp_optimization (parameter_sampler=parameter_sampler, root_path=root_path, \n",
    "                                      log_message=log_message, parameters=parameters, \n",
    "                                      other_parameters=other_parameters)\n",
    "            elif parameters_multiple_values is not None:\n",
    "                self.grid_search (\n",
    "                    parameters_multiple_values=parameters_multiple_values, \n",
    "                    parameters_single_value=parameters, other_parameters=other_parameters, \n",
    "                    root_path=root_path, run_numbers=run_numbers, log_message=log_message\n",
    "                )\n",
    "            else:\n",
    "                if only_if_exists:\n",
    "                    run_numbers = [run_number for run_number in run_numbers if os.path.exists('%s/%d' %(path_root_experiment, run_number))]\n",
    "\n",
    "                script_parameters = {}\n",
    "                insert_experiment_script_path (script_parameters, self.logger)\n",
    "                other_parameters['rerun_script'] = script_parameters\n",
    "                self.run_multiple_repetitions (\n",
    "                    parameters=parameters, other_parameters=other_parameters, root_path=root_path,\n",
    "                    log_message=log_message, run_numbers=run_numbers\n",
    "                )\n",
    "\n",
    "    def rerun_experiment_pipeline (self, experiments, run_numbers=None, root_path=None, \n",
    "                                   root_folder=None, new_parameters={}, save_results=False):\n",
    "\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        for experiment_id in experiments:\n",
    "            path_root_experiment = self.get_path_experiment (experiment_id, root_path=root_path)\n",
    "\n",
    "            parameters, other_parameters=pickle.load (\n",
    "                open(f'{path_root_experiment}/parameters.pk', 'rb')\n",
    "            )\n",
    "            parameters = parameters.copy()\n",
    "            parameters.update(other_parameters)\n",
    "            parameters.update(new_parameters)\n",
    "            for run_number in run_numbers:\n",
    "                path_experiment = '%s/%d/' %(path_root_experiment, run_number)\n",
    "                path_data = self.get_path_data (run_number, root_path, parameters)\n",
    "                score, _ = self.run_experiment_pipeline (run_number, path_experiment, \n",
    "                                                         parameters=parameters)\n",
    "\n",
    "                if save_results:\n",
    "                    experiment_number = experiment_id\n",
    "                    path_csv = '%s/experiments_data.csv' %root_path\n",
    "                    path_pickle = path_csv.replace('csv', 'pk')\n",
    "                    if os.path.exists(path_pickle):\n",
    "                        experiment_data = pd.read_pickle (path_pickle)\n",
    "                    else:\n",
    "                        experiment_data = pd.read_csv (path_csv, index_col=0)\n",
    "                    if type(score)==dict:\n",
    "                        for key in score.keys():\n",
    "                            if key != '':\n",
    "                                experiment_data.loc[experiment_number, '%d_%s' %(run_number, key)]=score[key]\n",
    "                            else:\n",
    "                                experiment_data.loc[experiment_number, '%d' %run_number]=score[key]\n",
    "                    else:\n",
    "                        experiment_data.loc[experiment_number, name_score]=score\n",
    "                    experiment_data.to_csv(path_csv)\n",
    "                    experiment_data.to_pickle(path_pickle)\n",
    "\n",
    "    def rerun_experiment_par (self, experiments, run_numbers=None, root_path=None, \n",
    "                              root_folder=None, parameters={}):\n",
    "\n",
    "        if root_path is None:\n",
    "            root_path = self.get_path_experiments(folder=root_folder)\n",
    "        for experiment_id in experiments:\n",
    "            path_root_experiment = self.get_path_experiment (experiment_id, root_path=root_path)\n",
    "\n",
    "            for run_number in run_numbers:\n",
    "                path_experiment = '%s/%d/' %(path_root_experiment, run_number)\n",
    "                self.run_experiment_pipeline (run_number, path_experiment, parameters = parameters)\n",
    "\n",
    "    def record_intermediate_results (self, experiments=range(100), run_numbers=range(100), root_path=None, root_folder=None, new_parameters={}, remove=False):\n",
    "\n",
    "        if remove:\n",
    "            new_parameters.update (remove_not_finished=True, only_remove_not_finished=True)\n",
    "        else:\n",
    "            new_parameters.update (use_last_result=True)\n",
    "\n",
    "        self.rerun_experiment_and_save(experiments=experiments, run_numbers=run_numbers,\n",
    "            root_path=root_path, root_folder=root_folder,\n",
    "            new_parameters=new_parameters)\n",
    "        \n",
    "    def find_closest_epoch (self, experiment_data, parameters, name_epoch=dflt.name_epoch):\n",
    "        '''Finds experiment with same parameters except for number of epochs, and takes the epochs that are closer but lower than the one in parameters.'''\n",
    "\n",
    "        experiment_numbers, _, _ = experiment_utils.find_rows_with_parameters_dict (experiment_data, parameters, ignore_keys=[name_epoch,'prev_epoch'])\n",
    "\n",
    "        defaults = self.get_default_parameters(parameters)\n",
    "        current_epoch = parameters.get(name_epoch, defaults.get(name_epoch))\n",
    "        if current_epoch is None:\n",
    "            current_epoch = -1\n",
    "        if len(experiment_numbers) > 1:\n",
    "            epochs = experiment_data.loc[experiment_numbers,name_epoch].copy()\n",
    "            epochs[epochs.isnull()]=defaults.get(name_epoch)\n",
    "            epochs = epochs.loc[epochs<=current_epoch]\n",
    "            if epochs.shape[0] == 0:\n",
    "                return None\n",
    "            else:\n",
    "                return epochs.astype(int).idxmax()\n",
    "        elif len(experiment_numbers) == 1:\n",
    "            return experiment_numbers[0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def get_last_epoch (self, parameters, path_results, \n",
    "                             name_epoch=dflt.name_epoch, name_last_epoch=dflt.name_last_epoch):\n",
    "        \n",
    "        name_model_history = parameters.get('name_model_history', self.name_model_history)\n",
    "        path_model_history = f'{path_results}/{name_model_history}'\n",
    "\n",
    "        prev_epoch = -1\n",
    "        if os.path.exists(path_model_history):\n",
    "            summary = pickle.load(open(path_model_history, 'rb'))\n",
    "            prev_epoch = summary.get(name_last_epoch)\n",
    "            if prev_epoch is None:\n",
    "                key_score = self.get_key_score (parameters)\n",
    "                if key_score in summary and (isinstance(summary[key_score], list) \n",
    "                                             or isinstance(summary[key_score], np.array)):\n",
    "                    prev_epoch = (~np.isnan(summary[key_score])).sum()\n",
    "\n",
    "        return prev_epoch\n",
    "        \n",
    "    def finished_all_epochs (self, parameters, path_results, \n",
    "                             name_epoch=dflt.name_epoch, name_last_epoch=dflt.name_last_epoch):\n",
    "        defaults = self.get_default_parameters (parameters)\n",
    "        current_epoch = parameters.get(name_epoch, defaults.get(name_epoch))\n",
    "        prev_epoch = self.get_last_epoch (parameters, path_results, name_epoch=name_epoch, \n",
    "                                          name_last_epoch=name_last_epoch)\n",
    "        \n",
    "        if prev_epoch >= current_epoch:\n",
    "            finished = True\n",
    "        else:\n",
    "            finished = False\n",
    "\n",
    "        return finished\n",
    "    \n",
    "    def make_resume_from_checkpoint (self, parameters, prev_path_results, use_best=False):\n",
    "\n",
    "        if parameters.get('previous_model_file_name') is not None:\n",
    "            previous_model_file_name = parameters['previous_model_file_name']\n",
    "        else:\n",
    "            model_extension = parameters.get('model_extension', 'h5')\n",
    "            model_name = parameters.get('model_name', 'checkpoint_')\n",
    "            epoch_offset = parameters.get('epoch_offset', 0)\n",
    "            name_best_model = parameters.get('name_best_model', 'best_model')\n",
    "\n",
    "        found = False\n",
    "        name_model_history = parameters.get('name_model_history', 'model_history.pk')\n",
    "        name_last_epoch = parameters.get('name_last_epoch', dflt.name_last_epoch)\n",
    "        path_model_history = f'{prev_path_results}/{name_model_history}'\n",
    "        if os.path.exists(path_model_history):\n",
    "            parameters['resume_summary'] = path_model_history\n",
    "            found = True\n",
    "            parameters['prev_path_results'] = prev_path_results\n",
    "            if parameters.get('previous_model_file_name') is not None:\n",
    "                parameters['resume'] = f'{prev_path_results}/{previous_model_file_name}'\n",
    "            elif use_best:\n",
    "                parameters['resume'] = f'{prev_path_results}/{name_best_model}.{model_extension}'\n",
    "            else:\n",
    "                summary = pickle.load(open(path_model_history, 'rb'))\n",
    "                prev_epoch = summary.get(name_last_epoch)\n",
    "                key_score = self.get_key_score (parameters)\n",
    "                if prev_epoch is None:\n",
    "                    if key_score in summary and (isinstance(summary[key_score], list) \n",
    "                                                 or isinstance(summary[key_score], np.array)):\n",
    "                        prev_epoch = (~np.isnan(summary[key_score])).sum()\n",
    "                    else:\n",
    "                        prev_epoch = 0\n",
    "\n",
    "                if prev_epoch >= 0:\n",
    "                    parameters['resume'] = f'{prev_path_results}/{model_name}{prev_epoch+epoch_offset}.{model_extension}'\n",
    "            if not os.path.exists(parameters['resume']):\n",
    "                path_resume2 = f'{prev_path_results}/{self.model_file_name}'\n",
    "                if os.path.exists (path_resume2):\n",
    "                    parameters['resume'] = path_resume2\n",
    "                else:\n",
    "                    parameters['resume'] = ''\n",
    "                    parameters['prev_path_results'] = ''\n",
    "                    found = False\n",
    "\n",
    "        return found\n",
    "    \n",
    "    def exists_current_checkpoint (self, parameters, path_results):\n",
    "        model_file_name = self.get_parameter (parameters, 'model_file_name')\n",
    "        return os.path.exists (f'{path_results}/{model_file_name}')\n",
    "    \n",
    "    def get_parameter (self, parameters, key, default=None):\n",
    "        parameter = parameters.get(key)\n",
    "        return parameter if parameter is not None else getattr(self, key, default)\n",
    "    \n",
    "    def obtain_last_result (self, parameters, path_results):\n",
    "\n",
    "        if parameters.get('use_last_result_from_dict', False):\n",
    "            return self.obtain_last_result_from_dict (parameters, path_results)\n",
    "        name_result_file = self.get_parameter (parameters, 'name_model_history')\n",
    "        path_results_file = f'{path_results}/{name_result_file}'\n",
    "        dict_results = None\n",
    "        if os.path.exists (path_results_file):\n",
    "            history = pickle.load(open(path_results_file, 'rb'))\n",
    "            metrics = parameters.get('key_scores')\n",
    "            if metrics is None:\n",
    "                metrics = history.keys()\n",
    "            ops = parameters.get('ops')\n",
    "            if ops is None:\n",
    "                ops = ['max'] * len(metrics)\n",
    "            if type(ops) is str:\n",
    "                ops = [ops] * len(metrics)\n",
    "            if type(ops) is dict:\n",
    "                ops_dict = ops\n",
    "                ops = ['max'] * len(metrics)\n",
    "                i = 0\n",
    "                for k in metrics:\n",
    "                    if k in ops_dict.keys():\n",
    "                        ops[i] = ops_dict[k]\n",
    "                    i += 1\n",
    "            dict_results = {}\n",
    "            max_last_position = -1\n",
    "            for metric, op in zip(metrics, ops):\n",
    "                if metric in history.keys():\n",
    "                    history_array = history[metric]\n",
    "                    score = min(history_array) if op == 'min' else max(history_array)\n",
    "                    last_position = np.where(np.array(history_array).ravel()==0)[0]\n",
    "                    if len(last_position) > 0:\n",
    "                        last_position = last_position[0] - 1\n",
    "                    else:\n",
    "                        last_position = len(history_array)\n",
    "                    dict_results[metric] = score\n",
    "                else:\n",
    "                    last_position = -1\n",
    "                max_last_position = max(last_position, max_last_position)\n",
    "\n",
    "            dict_results['last'] = max_last_position\n",
    "            if max_last_position < parameters.get('min_iterations', dflt.min_iterations):\n",
    "                dict_results = None\n",
    "                print (f'not storing result from {path_results} with iterations {max_last_position}')\n",
    "            else:\n",
    "                print (f'storing result from {path_results} with iterations {max_last_position}')\n",
    "\n",
    "        return dict_results\n",
    "    \n",
    "    #export\n",
    "    def obtain_last_result_from_dict (self, parameters, path_results):\n",
    "        name_result_file = self.get_parameter(parameters, 'result_file')\n",
    "        path_results_file = f'{path_results}/{name_result_file}'\n",
    "        dict_results = None\n",
    "        if os.path.exists (path_results_file):\n",
    "            dict_results = pickle.load(open(path_results_file, 'rb'))\n",
    "            if 'last' not in dict_results.keys() and 'epoch' in dict_results.keys():\n",
    "                dict_results['last'] = dict_results['epoch']\n",
    "            if 'last' not in dict_results:\n",
    "                parameters['use_last_result_from_dict'] = False\n",
    "                dict_results_from_history = self.obtain_last_result (parameters, path_results)\n",
    "                parameters['use_last_result_from_dict'] = True\n",
    "                if dict_results_from_history is not None:\n",
    "                    dict_results['last'] = dict_results_from_history['last']\n",
    "            if 'last' not in dict_results:\n",
    "                raise RuntimeError ('dict_results has no entry named \"last\", and '\n",
    "                                    'the value of last could not be retrieved from '\n",
    "                                    'a model history file')\n",
    "            max_last_position = dict_results['last']\n",
    "            if max_last_position < parameters.get('min_iterations', dflt.min_iterations):\n",
    "                dict_results = None\n",
    "                print (f'not storing result from {path_results} with iterations {max_last_position}')\n",
    "            else:\n",
    "                print (f'storing result from {path_results} with iterations {max_last_position}')\n",
    "\n",
    "        return dict_results\n",
    "    \n",
    "    def register_and_store_subclassed_manager (self):\n",
    "        #self.logger.debug ('registering')\n",
    "        self.manager_factory.register_manager (self)\n",
    "        self.manager_factory.write_manager (self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create_experiment_and_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_experiment_and_run` is the main function of the `ExperimentManager`. All other functions make use of it adding additional functionalities.\n",
    "\n",
    "In order to call `create_experiment_and_run`, we pass a dictionary of parameters characterizing the experiment we want to run, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_basic_usage ():\n",
    "    em = init_em ('basic')\n",
    "    \n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    # The output is a tuple of two objects:\n",
    "    #1. The main result metric. In our case, we didn't indicate the name of this metric, \n",
    "    #and therefore we get None.\n",
    "    #1. A dictionary containing all the performance metrics for this experiment.\n",
    "    \n",
    "    assert result==0.6\n",
    "    assert dict_results == {'validation_accuracy': 0.6, 'test_accuracy': 0.5}\n",
    "\n",
    "    # Eight files  are stored in *path_experiments*, and the `experiments` folder is created:\n",
    "    \n",
    "    files_stored = ['current_experiment_number.pkl',\n",
    "             'experiments',\n",
    "             'experiments_data.csv',\n",
    "             'experiments_data.pk',\n",
    "             'git_hash.json',\n",
    "             'other_parameters.csv',\n",
    "             'parameters.pk',\n",
    "             'parameters.txt',\n",
    "             'summary.txt']\n",
    "    \n",
    "    display(files_stored)\n",
    "\n",
    "    path_experiments = em.get_path_experiments()\n",
    "\n",
    "    assert (sorted(os.listdir (path_experiments))==\n",
    "            files_stored)\n",
    "\n",
    "    # TODO TEST: test content of the above files\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_pickle (f'{path_experiments}/experiments_data.pk')\n",
    "\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    \n",
    "    print (f'folder created in `{path_experiments}/experiments`:'); print(list_exp)\n",
    "    \n",
    "    assert list_exp == ['00000']\n",
    "    \n",
    "    print ('This folder has one sub-folder per run, since '\n",
    "            'multiple runs can be done with the same parameters.')\n",
    "    \n",
    "    list_run = os.listdir (f'{path_experiments}/experiments/00000')\n",
    "    \n",
    "    print (f'contents of current run at `{path_experiments}/experiments/00000`:'); print(list_run)\n",
    "    \n",
    "    # the same data frame can be obtained by doing:\n",
    "    df_bis = em.get_experiment_data ()\n",
    "    \n",
    "    pd.testing.assert_frame_equal(df,df_bis)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/587345255.py, line number: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_basic_usage\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['current_experiment_number.pkl',\n",
       " 'experiments',\n",
       " 'experiments_data.csv',\n",
       " 'experiments_data.pk',\n",
       " 'git_hash.json',\n",
       " 'other_parameters.csv',\n",
       " 'parameters.pk',\n",
       " 'parameters.txt',\n",
       " 'summary.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>23:03:16.385757</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001688   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:16.385757       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder created in `test_basic/experiments`:\n",
      "['00000']\n",
      "This folder has one sub-folder per run, since multiple runs can be done with the same parameters.\n",
      "contents of current run at `test_basic/experiments/00000`:\n",
      "['other_parameters.json', 'parameters.pk', 'parameters.txt', '0', 'parameters.json']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_basic_usage, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Running second experiment with same parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_same_values ():\n",
    "    em = init_em ('same_values')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "        \n",
    "    em.raise_error_if_run = True\n",
    "    # second experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    # As we can see, no new experiment is added to the DataFrame, since the values of the parameters used \n",
    "    # are already present in the first experiment.\n",
    "    \n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    \n",
    "    print (f'folders created in `{path_experiments}/experiments`:'); print(list_exp)\n",
    "    \n",
    "    assert list_exp == ['00000']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/314616621.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_same_values\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>23:03:16.487347</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001651   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:16.487347       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folders created in `test_same_values/experiments`:\n",
      "['00000']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_same_values, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Running second experiment with *almost* same parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_almost_same_values ():\n",
    "    em = init_em ('almost_same_values')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "        \n",
    "    em.raise_error_if_run = True\n",
    "    # second experiment: the difference between the values of rate parameter is 1.e-16: \n",
    "    # too small to be considered different\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05+1e-16})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    assert list_exp == ['00000']\n",
    "    \n",
    "    # consider 1.e-17 difference big enough\n",
    "    em.raise_error_if_run = False\n",
    "    # second experiment: the difference between the values of rate parameter is 1.e-16: \n",
    "    # too small to be considered different\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05+1e-16},\n",
    "                                                        other_parameters={'precision': 1e-17})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape[0]==2 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    display (df)\n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    assert list_exp == ['00000', '00001']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2249530880.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_almost_same_values\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2249530880.py, line number: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.1500000000000001\n",
      "epoch 1: accuracy: 0.2000000000000002\n",
      "epoch 2: accuracy: 0.25000000000000033\n",
      "epoch 3: accuracy: 0.30000000000000043\n",
      "epoch 4: accuracy: 0.35000000000000053\n",
      "epoch 5: accuracy: 0.40000000000000063\n",
      "epoch 6: accuracy: 0.45000000000000073\n",
      "epoch 7: accuracy: 0.5000000000000009\n",
      "epoch 8: accuracy: 0.5500000000000009\n",
      "epoch 9: accuracy: 0.600000000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>23:03:16.595396</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>23:03:16.633961</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001508   \n",
       "1     0.1  0.05                    0.6              0.5  0.001606   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:16.595396       True  \n",
       "1  23:03:16.633961       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_almost_same_values, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adding new runs on previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_new_runs ():\n",
    "    em = init_em ('new_runs')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "        \n",
    "    # second experiment: in order to run another experiment with same parametres, we increase\n",
    "    # the run number. The default run number used in the first experiment is 0, so we indicate\n",
    "    # run_number=1\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05}, \n",
    "                                                         run_number=1)\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished', '1_validation_accuracy',\n",
    "                                            '1_test_accuracy', 'time_1','1_finished']).all()\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    # another adding a new run number is to indicate run_number=None. This will make the experiment\n",
    "    # manager find the next run number automatically. Since we have used run numbers 0 and 1, \n",
    "    # the next run number will be 2\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05}, \n",
    "                                                         run_number=None)\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    \n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished', '1_validation_accuracy',\n",
    "                                            '1_test_accuracy', 'time_1','1_finished',\n",
    "                                            '2_validation_accuracy', '2_test_accuracy', 'time_2', \n",
    "                                            '2_finished']).all()\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    # As we can see, no new experiment is added to the DataFrame, since the values of the parameters used \n",
    "    # are already present in the first experiment.\n",
    "    \n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    \n",
    "    print (f'folders created in `{path_experiments}/experiments`:'); print(list_exp)\n",
    "    \n",
    "    assert list_exp == ['00000']\n",
    "    \n",
    "    list_runs = os.listdir (f'{path_experiments}/experiments/00000')\n",
    "    if False:\n",
    "        assert sorted(list_runs) == ['0',\n",
    "                                     '1',\n",
    "                                     '2',\n",
    "                                     'other_parameters.json',\n",
    "                                     'parameters.json',\n",
    "                                     'parameters.pk',\n",
    "                                     'parameters.txt']\n",
    "    else:\n",
    "        print (sorted(list_runs))\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3459580111.py, line number: 7\n",
      "script: /tmp/ipykernel_17968/3459580111.py, line number: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_new_runs\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>time_1</th>\n",
       "      <th>1_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>23:03:16.766153</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001906   \n",
       "\n",
       "              date 0_finished  1_validation_accuracy  1_test_accuracy  \\\n",
       "0  23:03:16.766153       True                    0.6              0.5   \n",
       "\n",
       "     time_1 1_finished  \n",
       "0  0.001509       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3459580111.py, line number: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>time_1</th>\n",
       "      <th>1_finished</th>\n",
       "      <th>2_validation_accuracy</th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>23:03:16.812915</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001906   \n",
       "\n",
       "              date 0_finished  1_validation_accuracy  1_test_accuracy  \\\n",
       "0  23:03:16.812915       True                    0.6              0.5   \n",
       "\n",
       "     time_1 1_finished  2_validation_accuracy  2_test_accuracy    time_2  \\\n",
       "0  0.001509       True                    0.6              0.5  0.001535   \n",
       "\n",
       "  2_finished  \n",
       "0       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folders created in `test_new_runs/experiments`:\n",
      "['00000']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_new_runs, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adding second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_second_experiment ():\n",
    "    em = init_em ('second')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    md ('If we run a second experiment with new parameters, a new row is '\n",
    "        'added to the dataframe, and a new folder is created:')\n",
    "    \n",
    "    # second experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.7, 'rate': 0.2})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    assert df.shape[0]==2 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    list_exp = os.listdir (f'{path_experiments}/experiments')\n",
    "    \n",
    "    md (f'folders created in `{path_experiments}/experiments`:'); print(list_exp)\n",
    "    \n",
    "    assert list_exp == ['00000','00001']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_second_experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3126725428.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If we run a second experiment with new parameters, a new row is added to the dataframe, and a new folder is created:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3126725428.py, line number: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.8999999999999999\n",
      "epoch 1: accuracy: 1.0999999999999999\n",
      "epoch 2: accuracy: 1.2999999999999998\n",
      "epoch 3: accuracy: 1.4999999999999998\n",
      "epoch 4: accuracy: 1.6999999999999997\n",
      "epoch 5: accuracy: 1.8999999999999997\n",
      "epoch 6: accuracy: 2.0999999999999996\n",
      "epoch 7: accuracy: 2.3\n",
      "epoch 8: accuracy: 2.5\n",
      "epoch 9: accuracy: 2.7\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>23:03:16.936540</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>23:03:16.969515</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.002351   \n",
       "1     0.7  0.20                    1.0              1.0  0.001715   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:16.936540       True  \n",
       "1  23:03:16.969515       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "folders created in `test_second/experiments`:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000', '00001']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_second_experiment, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding another parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b\n",
       "0  1  1.0\n",
       "1  2  NaN\n",
       "2  3  3.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':[1,2,3],'b':[1,None,3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().loc[1,'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_new_parameter ():\n",
    "    em = init_em ('another_parameter')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    # second experiment:\n",
    "    # same parameters as before plus new parameter 'epochs' not indicated in first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    # a new experiment is added, and a new parameter `epochs` is added as additional column at the end\n",
    "    assert df.shape[0]==2 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished','epochs']).all()\n",
    "    \n",
    "    assert (df.index==[0,1]).all()\n",
    "    \n",
    "    # the new parameter has None value for all previous experiments that did not indicated its value\n",
    "    # In our case, the first experiment has None value for parameter `epochs`\n",
    "    # This means that the default value of epochs is used for that parameter.\n",
    "    # In our case, if we look at the implementation of DummyExperimentManager, we can see that \n",
    "    # the default value for epochs is 10.\n",
    "    assert df.isna().loc[0,'epochs']\n",
    "    \n",
    "    assert df.loc[1,'epochs'] == 5.0\n",
    "\n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2342689092.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_new_parameter\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2342689092.py, line number: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>23:03:17.170410</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>23:03:17.202045</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                   0.60             0.50  0.001476   \n",
       "1     0.1  0.05                   0.35             0.45  0.001106   \n",
       "\n",
       "              date 0_finished  epochs  \n",
       "0  23:03:17.170410       True     NaN  \n",
       "1  23:03:17.202045       True     5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_new_parameter, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding another parameter with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_new_parameter_default ():\n",
    "    em = init_em ('another_parameter_default')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    # second experiment:\n",
    "    # same parameters as before plus new parameter 'epochs' not indicated in first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 10})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    # in this case, no new experiment is added, since the new parameter has the same value as the default value\n",
    "    # implicitly used in the first experiment.\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    \n",
    "    assert (df.index==[0]).all()\n",
    "    \n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2374034115.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_new_parameter_default\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>23:03:17.296610</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001513   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:17.296610       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_new_parameter_default, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicating parameters that don't affect the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_other_parameters ():\n",
    "    em = init_em ('other_parameters')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment: \n",
    "    # we use the other_parameters argument to indicate a parameter that does not affect the outcome \n",
    "    # of the experiment\n",
    "    # in this example, we change the level of verbosity. This parameter should not affect how the \n",
    "    # experiment runs, and therefore we tell our experiment manager to not create a new experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05},\n",
    "                                                         other_parameters={'verbose': False})\n",
    "    \n",
    "    # second experiment:\n",
    "    # same parameters as before except for the verbosity parameter. Our experiment manager considers\n",
    "    # this experiment the same as before, and therefore it does not run it, but outputs the same results \n",
    "    # obtained before\n",
    "    em.raise_error_if_run = True\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    # in this case, no new experiment is added, since the new parameter has the same value as the default value\n",
    "    # implicitly used in the first experiment.\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    \n",
    "    assert (df.index==[0]).all()\n",
    "    \n",
    "    md ('experiment dataframe:'); display(df)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1875725149.py, line number: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_other_parameters\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "experiment dataframe:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>23:03:17.435932</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.000668   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:17.435932       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_other_parameters, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove_not_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this functionality, we need to indicate the name of the parameter that specifies the number of epochs. This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (name_epoch='epochs')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(name_epoch='epochs', ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_remove_not_finished ():\n",
    "    em = init_em ('remove_not_finished')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment: we simulate that a halt before finishing\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05},\n",
    "                                                         other_parameters={'halt':True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    \n",
    "    # second experiment: remove unfinished\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':1.0, 'rate': 0.2})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    \n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':1.0, 'rate': 0.3},\n",
    "                                                         other_parameters={'remove_not_finished':True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "\n",
    "    # in this case, no new experiment is added, since the new parameter has the same value as the default value\n",
    "    # implicitly used in the first experiment.\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2801524373.py, line number: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_remove_not_finished\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate\n",
       "0     0.1  0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2801524373.py, line number: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 1.2\n",
      "epoch 1: accuracy: 1.4\n",
      "epoch 2: accuracy: 1.5999999999999999\n",
      "epoch 3: accuracy: 1.7999999999999998\n",
      "epoch 4: accuracy: 1.9999999999999998\n",
      "epoch 5: accuracy: 2.1999999999999997\n",
      "epoch 6: accuracy: 2.4\n",
      "epoch 7: accuracy: 2.6\n",
      "epoch 8: accuracy: 2.8000000000000003\n",
      "epoch 9: accuracy: 3.0000000000000004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>23:03:17.573406</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    NaN              NaN       NaN   \n",
       "1     1.0  0.20                    1.0              1.0  0.001539   \n",
       "\n",
       "              date 0_finished  \n",
       "0              NaN        NaN  \n",
       "1  23:03:17.573406       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2801524373.py, line number: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 1.3\n",
      "epoch 1: accuracy: 1.6\n",
      "epoch 2: accuracy: 1.9000000000000001\n",
      "epoch 3: accuracy: 2.2\n",
      "epoch 4: accuracy: 2.5\n",
      "epoch 5: accuracy: 2.8\n",
      "epoch 6: accuracy: 3.0999999999999996\n",
      "epoch 7: accuracy: 3.3999999999999995\n",
      "epoch 8: accuracy: 3.6999999999999993\n",
      "epoch 9: accuracy: 3.999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>23:03:17.573406</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>23:03:17.613941</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    NaN              NaN       NaN   \n",
       "1     1.0  0.20                    1.0              1.0  0.001539   \n",
       "2     1.0  0.30                    1.0              1.0  0.001799   \n",
       "\n",
       "              date 0_finished  \n",
       "0              NaN        NaN  \n",
       "1  23:03:17.573406       True  \n",
       "2  23:03:17.613941       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_remove_not_finished, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repeat_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_repeat_experiment ():\n",
    "    em = init_em ('repeat_experiment')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    date = df.date.values[0]\n",
    "    \n",
    "    # second experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05},\n",
    "                                                         other_parameters={'repeat_experiment': True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    assert df.date.values[0] != date\n",
    "    \n",
    "\n",
    "    # in this case, no new experiment is added, since the new parameter has the same value as the default value\n",
    "    # implicitly used in the first experiment.\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    \n",
    "    assert (df.index==[0]).all()\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1962307353.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_repeat_experiment\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>23:03:17.712281</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001501   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:17.712281       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1962307353.py, line number: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>23:03:17.747980</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.001501   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:17.747980       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_repeat_experiment, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this functionality, we need to indicate the name of the parameter that specifies the number of epochs. This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (name_epoch='epochs')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(name_epoch='epochs', ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_check_finished ():\n",
    "    em = init_em ('check_finished')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment: we simulate that we only run for half the number of epochs\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 10},\n",
    "                                                         other_parameters={'actual_epochs': 5})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    date = df.date.values[0]\n",
    "    score = df['0_validation_accuracy'].values[0]\n",
    "    \n",
    "    # second experiment: same values in parameters dictionary, without other_parameters \n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 10})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    \n",
    "    assert (date==df.date.values[0]) and (score==df['0_validation_accuracy'].values[0])\n",
    "    \n",
    "    # third experiment: same values in parameters dictionary, with other_parameters indicating check_finished\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 10},\n",
    "                                                         other_parameters={'check_finished':True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape[0]==1 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    assert (df.index==[0]).all()\n",
    "    assert (date!=df.date.values[0]) and (score!=df['0_validation_accuracy'].values[0])\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2482338563.py, line number: 7\n",
      "script: /tmp/ipykernel_17968/2482338563.py, line number: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_check_finished\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_check_finished, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recompute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_recompute_metrics ():\n",
    "    em = init_em ('recompute_metrics')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "    \n",
    "    # first experiment\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    # second experiment: new values \n",
    "    em.raise_error_if_run = True\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.02},\n",
    "                                                         other_parameters={'recompute_metrics': True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape[0]==2 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()    \n",
    "    assert np.isnan(df['0_validation_accuracy'].values[1])\n",
    "    \n",
    "    # third experiment: new values \n",
    "    em.raise_error_if_run = False\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.02, 'epochs': 10},\n",
    "                                                         other_parameters={'recompute_metrics':True,\n",
    "                                                                           'force_recompute_metrics': True})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape[0]==2 and (df.columns==['offset','rate','0_validation_accuracy','0_test_accuracy',\n",
    "                                           'time_0', 'date', '0_finished']).all()\n",
    "    assert (df.index==[0,1]).all()\n",
    "    assert df['0_validation_accuracy'].values[1]==0.3\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2340212191.py, line number: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_recompute_metrics\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2340212191.py, line number: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.12000000000000001\n",
      "epoch 1: accuracy: 0.14\n",
      "epoch 2: accuracy: 0.16\n",
      "epoch 3: accuracy: 0.18\n",
      "epoch 4: accuracy: 0.19999999999999998\n",
      "epoch 5: accuracy: 0.21999999999999997\n",
      "epoch 6: accuracy: 0.23999999999999996\n",
      "epoch 7: accuracy: 0.25999999999999995\n",
      "epoch 8: accuracy: 0.27999999999999997\n",
      "epoch 9: accuracy: 0.3\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_recompute_metrics, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prev_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this functionality, we need to indicate: \n",
    "1. The name of the parameter that specifies the number of epochs. \n",
    "1. The name of the file where the model is stored.\n",
    "This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (name_epoch='epochs', model_file_name='model_weights.pk')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(name_epoch='epochs', model_file_name='model_weights.pk')\n",
    "```\n",
    "\n",
    "Furthermore, in order to work, we need our experiment manager to make use of the parameter `resume` or the parameter `prev_path_results`. In particular, we need it to load the model file whose path is indicated in `parameters['resume']`, or whose path is indicated in `f'{parameters[\"prev_path_results\"]}/{self.model_file_name}'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_prev_epoch ():\n",
    "    em = init_em ('prev_epoch')\n",
    "\n",
    "    # get reference result\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 17})\n",
    "    reference_accuracy = em.model.accuracy\n",
    "    reference_weight = em.model.weight\n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    em.remove_previous_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 10})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 20})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 15})\n",
    "\n",
    "    # more epochs\n",
    "    # in order to work, we need our experiment manager to make use of the \n",
    "    # parameter 'resume' or the parameter 'prev_path_results'. \n",
    "    # In particular, we need it to load the model file\n",
    "    # whose path is indicated in parameters['resume'], or whose path is \n",
    "    # indicated in f'{parameters[\"prev_path_results\"]}/{self.model_file_name}'\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 17},\n",
    "                                      other_parameters={'prev_epoch': True})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    assert em.model.epochs==2 and em.model.current_epoch==17\n",
    "\n",
    "    assert reference_accuracy==em.model.accuracy and reference_weight==em.model.weight\n",
    "\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 17},\n",
    "                                      other_parameters={'repeat_experiment': True})\n",
    "\n",
    "    assert em.model.epochs==17 and em.model.current_epoch==17\n",
    "\n",
    "    assert reference_accuracy==em.model.accuracy and reference_weight==em.model.weight\n",
    "\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_prev_epoch\n",
      "fitting model with 17 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n",
      "epoch 10: accuracy: 0.65\n",
      "epoch 11: accuracy: 0.7000000000000001\n",
      "epoch 12: accuracy: 0.7500000000000001\n",
      "epoch 13: accuracy: 0.8000000000000002\n",
      "epoch 14: accuracy: 0.8500000000000002\n",
      "epoch 15: accuracy: 0.9000000000000002\n",
      "epoch 16: accuracy: 0.9500000000000003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00219</td>\n",
       "      <td>23:03:18.132084</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy   time_0  \\\n",
       "0     0.1  0.05    17.0                   0.95             0.85  0.00219   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:18.132084       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 15\n",
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 20 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n",
      "epoch 10: accuracy: 0.65\n",
      "epoch 11: accuracy: 0.7000000000000001\n",
      "epoch 12: accuracy: 0.7500000000000001\n",
      "epoch 13: accuracy: 0.8000000000000002\n",
      "epoch 14: accuracy: 0.8500000000000002\n",
      "epoch 15: accuracy: 0.9000000000000002\n",
      "epoch 16: accuracy: 0.9500000000000003\n",
      "epoch 17: accuracy: 1.0000000000000002\n",
      "epoch 18: accuracy: 1.0500000000000003\n",
      "epoch 19: accuracy: 1.1000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 15 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n",
      "epoch 10: accuracy: 0.65\n",
      "epoch 11: accuracy: 0.7000000000000001\n",
      "epoch 12: accuracy: 0.7500000000000001\n",
      "epoch 13: accuracy: 0.8000000000000002\n",
      "epoch 14: accuracy: 0.8500000000000002\n",
      "reading model from test_prev_epoch/experiments/00002/0/model_weights.pk\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.9000000000000002\n",
      "epoch 1: accuracy: 0.9500000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1621658181.py, line number: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 17 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n",
      "epoch 10: accuracy: 0.65\n",
      "epoch 11: accuracy: 0.7000000000000001\n",
      "epoch 12: accuracy: 0.7500000000000001\n",
      "epoch 13: accuracy: 0.8000000000000002\n",
      "epoch 14: accuracy: 0.8500000000000002\n",
      "epoch 15: accuracy: 0.9000000000000002\n",
      "epoch 16: accuracy: 0.9500000000000003\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_prev_epoch, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_prev_epoch2 ():\n",
    "    em = init_em ('prev_epoch2')\n",
    "    \n",
    "    em.remove_previous_experiments()\n",
    "    score, results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "                                          other_parameters={'actual_epochs': 2})\n",
    "    \n",
    "    \n",
    "    assert score==0.16 and results['validation_accuracy']==0.16\n",
    "    assert em.model.current_epoch==2 and em.model.epochs==2\n",
    "    \n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 5})\n",
    "\n",
    "        \n",
    "    # We use last result and have the required number of epochs to default number (50)\n",
    "    # But we request to run the experiment until the end\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'prev_epoch': True, 'check_finished': True, 'use_previous_best': False}\n",
    "    )\n",
    "\n",
    "    assert score==0.25 and results['validation_accuracy']==0.25\n",
    "    assert em.model.current_epoch==5 and em.model.epochs==3\n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['0_validation_accuracy']==[0.25, 0.30]).all()\n",
    "    \n",
    "\n",
    "    em.remove_previous_experiments()\n",
    "\n",
    "    # **********************************\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "                                          other_parameters={'actual_epochs': 2, 'halt': True})\n",
    "    \n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 5})\n",
    "        \n",
    "    # We use last result and have the required number of epochs to default number (50)\n",
    "    # But we request to run the experiment until the end\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'prev_epoch': True, 'check_finished_if_interrupted': True, \n",
    "                          'use_previous_best': False}\n",
    "    )\n",
    "    assert score==0.25 and results['validation_accuracy']==0.25\n",
    "    assert em.model.current_epoch==5 and em.model.epochs==3\n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['0_validation_accuracy']==[0.25, 0.30]).all()\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_prev_epoch2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/813877249.py, line number: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/813877249.py, line number: 13\n",
      "script: /tmp/ipykernel_17968/813877249.py, line number: 18\n",
      "script: /tmp/ipykernel_17968/813877249.py, line number: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "epoch 2: accuracy: 0.22000000000000003\n",
      "epoch 3: accuracy: 0.26\n",
      "epoch 4: accuracy: 0.3\n",
      "reading model from test_prev_epoch2/experiments/00000/0/model_weights.pk\n",
      "fitting model with 3 epochs\n",
      "epoch 0: accuracy: 0.19\n",
      "epoch 1: accuracy: 0.22\n",
      "epoch 2: accuracy: 0.25\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/813877249.py, line number: 36\n",
      "script: /tmp/ipykernel_17968/813877249.py, line number: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "epoch 2: accuracy: 0.22000000000000003\n",
      "epoch 3: accuracy: 0.26\n",
      "epoch 4: accuracy: 0.3\n",
      "reading model from test_prev_epoch2/experiments/00000/0/model_weights.pk\n",
      "fitting model with 3 epochs\n",
      "epoch 0: accuracy: 0.19\n",
      "epoch 1: accuracy: 0.22\n",
      "epoch 2: accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_prev_epoch2, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work, we need our experiment manager to make use of the parameter `prev_path_results`. In particular, we need it to load the model file whose path is indicated in `f'{parameters[\"prev_path_results\"]}/{self.model_file_name}'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_from_exp ():\n",
    "    em = init_em ('from_exp')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "\n",
    "    # get reference result\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5})\n",
    "    reference_accuracy = em.model.accuracy\n",
    "    reference_weight = em.model.weight\n",
    "    em.remove_previous_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 2})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 2})\n",
    "    \n",
    "    # the following resumes from experiment 0, and trains the model for 5 more epochs \n",
    "    # using now different `offset` and `rate` hyper-parameters\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5},\n",
    "                                      other_parameters={'from_exp': 0})\n",
    "\n",
    "    assert em.model.epochs==5 and em.model.current_epoch==7\n",
    "    correct_accuracy = (0.1 + 0.03*2 # accuracy of model from experiment 0\n",
    "                        + 0.05*5)     # accuracy gained by training for 5 more epochs using \n",
    "                                    #  new hyper-parameters: rate=0.05 \n",
    "    assert (em.model.accuracy-correct_accuracy) < 1e-10\n",
    "    assert reference_accuracy!=em.model.accuracy\n",
    "\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3213666507.py, line number: 7\n",
      "script: /tmp/ipykernel_17968/3213666507.py, line number: 13\n",
      "script: /tmp/ipykernel_17968/3213666507.py, line number: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_from_exp\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3213666507.py, line number: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading model from test_from_exp/experiments/00000/0/model_weights.pk\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.21000000000000002\n",
      "epoch 1: accuracy: 0.26\n",
      "epoch 2: accuracy: 0.31\n",
      "epoch 3: accuracy: 0.36\n",
      "epoch 4: accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_from_exp, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### skip_interrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this functionality, we need to indicate the name of the file where the model is stored.\n",
    "This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (model_file_name='model_weights.pk')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(model_file_name='model_weights.pk')\n",
    "```\n",
    "\n",
    "Alternatively, we can indicate the name of the file where the model history exists. This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (name_model_history='history.pk')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(model_file_name='history.pk')\n",
    "```\n",
    "If not indicated, the experiment manager tries to find the model history in a file named `model_history.pk`. In order to consider the history good enough, the experiment manager checks if the length of the arrays stored in the model_history dictionary is at least `parameters.get('min_iterations', dflt.min_iterations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_skip_interrupted ():\n",
    "    em = init_em ('skip_interrupted')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "                                          other_parameters={'halt': True})\n",
    "    \n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 5})\n",
    "    \n",
    "    em.raise_error_if_run = True\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'skip_interrupted': True}\n",
    "    )\n",
    "    assert score is None and len(results)==0\n",
    "    \n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'skip_interrupted': True,\n",
    "                          'model_file_name': 'wrong_file.pk',\n",
    "                          'min_iterations':1}\n",
    "    )\n",
    "    assert score is None and len(results)==0\n",
    "    \n",
    "    with pytest.raises (RuntimeError):\n",
    "        score, results = em.create_experiment_and_run (\n",
    "            parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "            other_parameters={'skip_interrupted': True,\n",
    "                              'model_file_name': 'wrong_file.pk'}\n",
    "        )\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2789182944.py, line number: 8\n",
      "script: /tmp/ipykernel_17968/2789182944.py, line number: 11\n",
      "script: /tmp/ipykernel_17968/2789182944.py, line number: 14\n",
      "script: /tmp/ipykernel_17968/2789182944.py, line number: 20\n",
      "script: /tmp/ipykernel_17968/2789182944.py, line number: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_skip_interrupted\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "epoch 2: accuracy: 0.22000000000000003\n",
      "epoch 3: accuracy: 0.26\n",
      "epoch 4: accuracy: 0.3\n",
      "storing result from test_skip_interrupted/experiments/00000/0 with iterations 5\n",
      "not storing result from test_skip_interrupted/experiments/00000/0 with iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>23:03:18.913938</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.03     5.0                    NaN              NaN       NaN   \n",
       "1     0.1  0.04     5.0                    0.3              0.4  0.000943   \n",
       "\n",
       "              date 0_finished  \n",
       "0              NaN        NaN  \n",
       "1  23:03:18.913938       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_skip_interrupted, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### use_last_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this functionality, we need to indicate the name of the file where the model history exists. This can be done either passing this when constructing the object:\n",
    "```python\n",
    "em = MyExperimentManager (name_model_history='history.pk')\n",
    "```\n",
    "or indicating it in the `other_parameters` dictionary:\n",
    "```python\n",
    "other_parameters = dict(model_file_name='history.pk')\n",
    "```\n",
    "If not indicated, the experiment manager tries to find the model history in a file named `model_history.pk`. In order to consider the history good enough, the experiment manager checks if the length of the arrays stored in the model_history dictionary is at least `parameters.get('min_iterations', dflt.min_iterations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_use_last_result ():\n",
    "    em = init_em ('use_last_result')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "                                          other_parameters={'halt': True})\n",
    "    \n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 5})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df.isna()['0_validation_accuracy'] == [True, False]).all()\n",
    "    \n",
    "    # We use last result but require that number of epochs is at least 50.\n",
    "    # Since this is not true, the last result is not used.\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'use_last_result': True}\n",
    "    )\n",
    "    assert score is None and results=={}\n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    assert (df.isna()['0_validation_accuracy'] == [True, False]).all()\n",
    "    \n",
    "    # We use last result and lower the required number of epochs to 2\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'use_last_result': True, 'min_iterations': 2}\n",
    "    )\n",
    "    print (score, results)\n",
    "    assert score==0.25 and results=={'validation_accuracy': 0.25, 'test_accuracy': 0.35, 'accuracy': 0.25, 'last': 5}\n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    assert (df.isna()['0_validation_accuracy'] == [False, False]).all()\n",
    "    assert (df['0_validation_accuracy'] == [0.25, 0.30]).all()\n",
    "    \n",
    "    # We use last result and increase the required number of epochs to default number (50)\n",
    "    # But we request to run the experiment until the end\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'use_last_result': True, 'run_if_not_interrumpted': True}\n",
    "    )\n",
    "    print (score, results)\n",
    "    #assert score==None and results=={'validation_accuracy': 0.25, 'test_accuracy': 0.35, 'accuracy': 0.25, 'last': 5}\n",
    "    df = em.get_experiment_data ()\n",
    "    display(df)\n",
    "    #assert (df.isna()['0_validation_accuracy'] == [False, False]).all()\n",
    "    #assert (df['0_validation_accuracy'] == [0.25, 0.30]).all()\n",
    "\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2930722641.py, line number: 8\n",
      "script: /tmp/ipykernel_17968/2930722641.py, line number: 11\n",
      "script: /tmp/ipykernel_17968/2930722641.py, line number: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_use_last_result\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "epoch 2: accuracy: 0.22000000000000003\n",
      "epoch 3: accuracy: 0.26\n",
      "epoch 4: accuracy: 0.3\n",
      "not storing result from test_use_last_result/experiments/00000/0 with iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>23:03:19.123819</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.03     5.0                    NaN              NaN       NaN   \n",
       "1     0.1  0.04     5.0                    0.3              0.4  0.000973   \n",
       "\n",
       "              date 0_finished  \n",
       "0              NaN        NaN  \n",
       "1  23:03:19.123819       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/2930722641.py, line number: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing result from test_use_last_result/experiments/00000/0 with iterations 5\n",
      "0.25 {'validation_accuracy': 0.25, 'test_accuracy': 0.35, 'accuracy': 0.25, 'last': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>0_accuracy</th>\n",
       "      <th>0_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:03:19.187088</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>23:03:19.123819</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.03     5.0                   0.25             0.35       NaN   \n",
       "1     0.1  0.04     5.0                   0.30             0.40  0.000973   \n",
       "\n",
       "              date 0_finished  0_accuracy  0_last  \n",
       "0  23:03:19.187088      False        0.25     5.0  \n",
       "1  23:03:19.123819       True         NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 {'validation_accuracy': 0.25}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>0_accuracy</th>\n",
       "      <th>0_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:03:19.187088</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>23:03:19.123819</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.03     5.0                   0.25             0.35       NaN   \n",
       "1     0.1  0.04     5.0                   0.30             0.40  0.000973   \n",
       "\n",
       "              date 0_finished  0_accuracy  0_last  \n",
       "0  23:03:19.187088      False        0.25     5.0  \n",
       "1  23:03:19.123819       True         NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_use_last_result, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### second case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_use_last_result_run_interrupted ():\n",
    "    em = init_em ('use_last_result_run_interrupted')\n",
    "    path_experiments = em.get_path_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "                                          other_parameters={'actual_epochs': 2, 'halt': True})\n",
    "    \n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.04, 'epochs': 5})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    #display (df)\n",
    "    assert (df.isna()['0_validation_accuracy'] == [True, False]).all()\n",
    "        \n",
    "    # We use last result and have the required number of epochs to default number (50)\n",
    "    # But we request to run the experiment until the end\n",
    "    score, results = em.create_experiment_and_run (\n",
    "        parameters={'offset':0.1, 'rate': 0.03, 'epochs': 5},\n",
    "        other_parameters={'use_last_result': True, 'run_if_not_interrumpted': True}\n",
    "    )\n",
    "    print (score, results)\n",
    "    #assert score==None and results=={'validation_accuracy': 0.25, 'test_accuracy': 0.35, 'accuracy': 0.25, 'last': 5}\n",
    "    df = em.get_experiment_data ()\n",
    "    #display(df)\n",
    "    assert em.model.current_epoch==5 and em.model.epochs==5\n",
    "    assert (df.isna()['0_validation_accuracy'] == [False, False]).all()\n",
    "    assert (df['0_validation_accuracy'] == [0.25, 0.30]).all()\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/3294322140.py, line number: 8\n",
      "script: /tmp/ipykernel_17968/3294322140.py, line number: 11\n",
      "script: /tmp/ipykernel_17968/3294322140.py, line number: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_use_last_result_run_interrupted\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "epoch 2: accuracy: 0.22000000000000003\n",
      "epoch 3: accuracy: 0.26\n",
      "epoch 4: accuracy: 0.3\n",
      "not storing result from test_use_last_result_run_interrupted/experiments/00000/0 with iterations 2\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "0.25 {'validation_accuracy': 0.25, 'test_accuracy': 0.35}\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_use_last_result_run_interrupted, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_grid_search ():\n",
    "    em = init_em ('grid_search')\n",
    "    np.random.seed (42)\n",
    "    \n",
    "    # *********************************\n",
    "    # *********************************\n",
    "    em.grid_search (parameters_multiple_values={'rate': [0.03,0.01], 'epochs': [5, 7]},\n",
    "                    parameters_single_value={'offset':0.1},\n",
    "                    other_parameters={'verbose':False})\n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['epochs']==[5.0, 5.0, 7.0, 7.0]).all()\n",
    "    assert (df['rate'].values[[0,2]]==[0.03, 0.03]).all()\n",
    "    assert (df.isna()['rate']==[False, True, False, True]).all()\n",
    "    assert (df['offset']==0.1).all()\n",
    "    assert (np.abs(df['0_validation_accuracy']-[0.25, 0.15, 0.31, 0.17])<1.0e-15).all()\n",
    "    \n",
    "    #assert (df.isna()['0_validation_accuracy'] == [True, False]).all()\n",
    "    \n",
    "    # *********************************\n",
    "    # *********************************\n",
    "    em.raise_error_if_run = True\n",
    "    em.grid_search (parameters_multiple_values={'rate': [0.01,0.03], 'epochs': [7, 5]},\n",
    "                    parameters_single_value={'offset':0.1})\n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['epochs']==[5.0, 5.0, 7.0, 7.0]).all()\n",
    "    assert (df['rate'].values[[0,2]]==[0.03, 0.03]).all()\n",
    "    assert (df.isna()['rate']==[False, True, False, True]).all()\n",
    "    assert (df['offset']==0.1).all()\n",
    "    assert (np.abs(df['0_validation_accuracy']-[0.25, 0.15, 0.31, 0.17])<1.0e-15).all()\n",
    "    \n",
    "    # *********************************\n",
    "    # *********************************\n",
    "    em.remove_previous_experiments()\n",
    "    em.raise_error_if_run = False\n",
    "    em.grid_search (parameters_multiple_values={'rate': [0.01,0.03], 'epochs': [7, 5]},\n",
    "                    parameters_single_value={'offset':0.1, 'noise':0.0001}, nruns=2)\n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['epochs']==[7.0, 7.0, 5.0, 5.0]).all()\n",
    "    assert (df['rate'].values[[1,3]]==[0.03, 0.03]).all()\n",
    "    assert (df.isna()['rate']==[True, False, True, False]).all()\n",
    "    assert (df['offset']==0.1).all()\n",
    "    assert (np.abs(df['0_validation_accuracy']-[0.17, 0.31, 0.15, 0.25])<0.1).all()\n",
    "    assert (np.abs(df['1_validation_accuracy']-[0.17, 0.31, 0.15, 0.25])<0.1).all()\n",
    "    assert (df['0_validation_accuracy']!=df['1_validation_accuracy']).all()\n",
    "    \n",
    "    # *********************************\n",
    "    # *********************************\n",
    "    em.remove_previous_experiments()\n",
    "    em.grid_search (parameters_multiple_values={'rate': [0.01,0.03], 'epochs': [7, 5]},\n",
    "                    parameters_single_value={'offset':0.1}, random_search=True,\n",
    "                    other_parameters={'verbose':False})\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert (df['epochs']==[7.0, 7.0, 5.0, 5.0]).all()\n",
    "    assert (df['rate'].values[[0,3]]==[0.03, 0.03]).all()\n",
    "    assert (df.isna()['rate']==[False, True, True, False]).all()\n",
    "    assert (df['offset']==0.1).all()\n",
    "    assert (np.abs(df['0_validation_accuracy']-[0.31, 0.17, 0.15, 0.25])<1e-15).all()\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/546716936.py, line: 8\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 8\n",
      "time spent on this experiment: 0.0002505779266357422\n",
      "score: 0.25\n",
      "0 - validation_accuracy: 0.25\n",
      "0 - test_accuracy: 0.35\n",
      "finished experiment 0\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 0 out of 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_grid_search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 8\n",
      "time spent on this experiment: 0.00022721290588378906\n",
      "score: 0.15000000000000002\n",
      "0 - validation_accuracy: 0.15000000000000002\n",
      "0 - test_accuracy: 0.25\n",
      "finished experiment 1\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 8\n",
      "time spent on this experiment: 0.0002541542053222656\n",
      "score: 0.31000000000000005\n",
      "0 - validation_accuracy: 0.31000000000000005\n",
      "0 - test_accuracy: 0.41000000000000003\n",
      "finished experiment 2\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 3\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 8\n",
      "time spent on this experiment: 0.00023746490478515625\n",
      "score: 0.17000000000000004\n",
      "0 - validation_accuracy: 0.17000000000000004\n",
      "0 - test_accuracy: 0.27\n",
      "finished experiment 3\n",
      "experiment script: /tmp/ipykernel_17968/546716936.py, line: 23\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "found completed: experiment number: 3, run number: 0 - score: 0.170000\n",
      "{'epochs': 7, 'offset': 0.1}\n",
      "skipping...\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "found completed: experiment number: 2, run number: 0 - score: 0.310000\n",
      "{'epochs': 7, 'rate': 0.03, 'offset': 0.1}\n",
      "skipping...\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "found completed: experiment number: 1, run number: 0 - score: 0.150000\n",
      "{'epochs': 5, 'offset': 0.1}\n",
      "skipping...\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "found completed: experiment number: 0, run number: 0 - score: 0.250000\n",
      "{'epochs': 5, 'rate': 0.03, 'offset': 0.1}\n",
      "skipping...\n",
      "experiment script: /tmp/ipykernel_17968/546716936.py, line: 36\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.0012292861938476562\n",
      "score: 0.1700361395605509\n",
      "0 - validation_accuracy: 0.1700361395605509\n",
      "0 - test_accuracy: 0.2701538036566466\n",
      "finished experiment 0\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 0\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.001239776611328125\n",
      "score: 0.17009154021177025\n",
      "1 - validation_accuracy: 0.17009154021177025\n",
      "1 - test_accuracy: 0.27003287511096596\n",
      "finished experiment 0\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.001501321792602539\n",
      "score: 0.30996572854834736\n",
      "0 - validation_accuracy: 0.30996572854834736\n",
      "0 - test_accuracy: 0.40991977227307785\n",
      "finished experiment 1\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 1\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.001220703125\n",
      "score: 0.31011428228145155\n",
      "1 - validation_accuracy: 0.31011428228145155\n",
      "1 - test_accuracy: 0.4100751933032687\n",
      "finished experiment 1\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.001016378402709961\n",
      "score: 0.14984493365689341\n",
      "0 - validation_accuracy: 0.14984493365689341\n",
      "0 - test_accuracy: 0.2500068562974806\n",
      "finished experiment 2\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 1 out of 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 7 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "fitting model with 7 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "fitting model with 7 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "epoch 5: accuracy: 0.28\n",
      "epoch 6: accuracy: 0.31000000000000005\n",
      "fitting model with 7 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "epoch 5: accuracy: 0.28\n",
      "epoch 6: accuracy: 0.31000000000000005\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running experiment 2\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.0010807514190673828\n",
      "score: 0.1498392516765439\n",
      "1 - validation_accuracy: 0.1498392516765439\n",
      "1 - test_accuracy: 0.2500184633858532\n",
      "finished experiment 2\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 3\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.0010292530059814453\n",
      "score: 0.25002930724732986\n",
      "0 - validation_accuracy: 0.25002930724732986\n",
      "0 - test_accuracy: 0.34992856485819734\n",
      "finished experiment 3\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 3\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\tnoise=0.0001,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 36\n",
      "time spent on this experiment: 0.0009410381317138672\n",
      "score: 0.25008220601599945\n",
      "1 - validation_accuracy: 0.25008220601599945\n",
      "1 - test_accuracy: 0.3501896792982654\n",
      "finished experiment 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "epoch 2: accuracy: 0.19\n",
      "epoch 3: accuracy: 0.22\n",
      "epoch 4: accuracy: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/546716936.py, line: 50\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 50\n",
      "time spent on this experiment: 0.00023627281188964844\n",
      "score: 0.31000000000000005\n",
      "0 - validation_accuracy: 0.31000000000000005\n",
      "0 - test_accuracy: 0.41000000000000003\n",
      "finished experiment 0\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=7,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 50\n",
      "time spent on this experiment: 0.00023031234741210938\n",
      "score: 0.17000000000000004\n",
      "0 - validation_accuracy: 0.17000000000000004\n",
      "0 - test_accuracy: 0.27\n",
      "finished experiment 1\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 50\n",
      "time spent on this experiment: 0.0002288818359375\n",
      "score: 0.15000000000000002\n",
      "0 - validation_accuracy: 0.15000000000000002\n",
      "0 - test_accuracy: 0.25\n",
      "finished experiment 2\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 3\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/546716936.py, line number: 50\n",
      "time spent on this experiment: 0.00024771690368652344\n",
      "score: 0.25\n",
      "0 - validation_accuracy: 0.25\n",
      "0 - test_accuracy: 0.35\n",
      "finished experiment 3\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_grid_search, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_multiple_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_run_multiple_repetitions ():\n",
    "    em = init_em ('run_multiple_repetitions')\n",
    "    np.random.seed (42)\n",
    "    \n",
    "    mu, std, dict_results = em.run_multiple_repetitions (\n",
    "        parameters={'rate': 0.03, 'epochs': 5, 'offset': 0.1}, \n",
    "        other_parameters = {'verbose': False, 'noise': 0.001}, nruns=5\n",
    "    )\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(1,24)\n",
    "    x=[f'{i}_validation_accuracy' for i in range(5)]; assert df.columns.isin(x).sum()==5\n",
    "    assert (0 < np.abs(mu-0.25) < 1e-3) and (0 < std < 1e-3)\n",
    "    \n",
    "    # *********************************\n",
    "    # *********************************\n",
    "    em.remove_previous_experiments()\n",
    "    mu, std, dict_results = em.run_multiple_repetitions (\n",
    "        parameters={'rate': 0.03, 'epochs': 5, 'offset': 0.1}, \n",
    "        other_parameters = {'verbose': False}\n",
    "    )\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(1,8)\n",
    "    assert mu==0.25 and std==0\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "doing run 0 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.000225067138671875\n",
      "score: 0.24953658230718753\n",
      "0 - validation_accuracy: 0.24953658230718753\n",
      "0 - test_accuracy: 0.34953427024642975\n",
      "finished experiment 0\n",
      "doing run 1 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.00023818016052246094\n",
      "score: 0.2500675282046879\n",
      "1 - validation_accuracy: 0.2500675282046879\n",
      "1 - test_accuracy: 0.3485752518137865\n",
      "finished experiment 0\n",
      "doing run 2 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 2\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.00023865699768066406\n",
      "score: 0.2508225449121032\n",
      "2 - validation_accuracy: 0.2508225449121032\n",
      "2 - test_accuracy: 0.34877915635002893\n",
      "finished experiment 0\n",
      "doing run 3 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 3\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0002448558807373047\n",
      "score: 0.24953936122904022\n",
      "3 - validation_accuracy: 0.24953936122904022\n",
      "3 - test_accuracy: 0.3510571222262189\n",
      "finished experiment 0\n",
      "doing run 4 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 4\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.000247955322265625\n",
      "score: 0.25033126343140355\n",
      "4 - validation_accuracy: 0.25033126343140355\n",
      "4 - test_accuracy: 0.3509755451271223\n",
      "finished experiment 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_run_multiple_repetitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean : 0.2500594560168845, std: 0.000489927463497328\n",
      "doing run 0 out of 1\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0002410411834716797\n",
      "score: 0.25\n",
      "0 - validation_accuracy: 0.25\n",
      "0 - test_accuracy: 0.35\n",
      "finished experiment 0\n",
      "mean : 0.25, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_run_multiple_repetitions, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hp_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def parameter_sampler (trial):\n",
    "    rate = trial.suggest_uniform('rate', 0.001, 0.01)\n",
    "    offset = trial.suggest_categorical('offset', [0.01, 0.05, 0.1])    \n",
    "    \n",
    "    parameters = dict(rate=rate, \n",
    "                      offset=offset)\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def test_hp_optimization ():\n",
    "    em = init_em ('hp_optimization')\n",
    "    np.random.seed (42)\n",
    "\n",
    "    parameters = {'epochs': 12}\n",
    "    other_parameters = dict (trial_report='test_hp_optimization_trial',\n",
    "                             study_name='test_hp_optimization_study', \n",
    "                             n_trials=5)\n",
    "                            \n",
    "    em.hp_optimization (parameter_sampler=parameter_sampler, parameters=parameters, \n",
    "                        other_parameters=other_parameters)\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    # TODO: error in pytest\n",
    "    #assert df.shape == (5,8)\n",
    "    #assert (df['offset']==[0.01,0.10,0.05,0.01,0.10]).all()\n",
    "    #assert np.max(np.abs(df['rate']-[0.005939, 0.004813, 0.009673, 0.006112, 0.001182])) < 1e-5\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/4246270235.py, line: 20\n",
      "Sampler: random - Pruner: halving\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_hp_optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-07 23:03:21,947]\u001b[0m A new study created in RDB with name: test_hp_optimization_study\u001b[0m\n",
      "starting experiment 0 with run number 0\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=12,\n",
      "\toffset=0.01,\n",
      "\trate=0.005939321535345923\n",
      "\n",
      "script: /tmp/ipykernel_17968/4246270235.py, line number: 20\n",
      "time spent on this experiment: 0.0017962455749511719\n",
      "score: 0.08127185842415106\n",
      "0 - validation_accuracy: 0.08127185842415106\n",
      "0 - test_accuracy: 0.0\n",
      "finished experiment 0\n",
      "\u001b[32m[I 2022-01-07 23:03:22,292]\u001b[0m Trial 0 finished with value: 0.08127185842415106 and parameters: {'rate': 0.005939321535345923, 'offset': 0.01}. Best is trial 0 with value: 0.08127185842415106.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 12 epochs\n",
      "epoch 0: accuracy: 0.015939321535345923\n",
      "epoch 1: accuracy: 0.021878643070691844\n",
      "epoch 2: accuracy: 0.02781796460603777\n",
      "epoch 3: accuracy: 0.033757286141383694\n",
      "epoch 4: accuracy: 0.03969660767672962\n",
      "epoch 5: accuracy: 0.04563592921207554\n",
      "epoch 6: accuracy: 0.05157525074742147\n",
      "epoch 7: accuracy: 0.05751457228276739\n",
      "epoch 8: accuracy: 0.06345389381811331\n",
      "epoch 9: accuracy: 0.06939321535345923\n",
      "epoch 10: accuracy: 0.07533253688880515\n",
      "epoch 11: accuracy: 0.08127185842415106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starting experiment 1 with run number 0\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=12,\n",
      "\toffset=0.1,\n",
      "\trate=0.004812893194050143\n",
      "\n",
      "script: /tmp/ipykernel_17968/4246270235.py, line number: 20\n",
      "time spent on this experiment: 0.001783609390258789\n",
      "score: 0.1577547183286018\n",
      "0 - validation_accuracy: 0.1577547183286018\n",
      "0 - test_accuracy: 0.057754718328601795\n",
      "finished experiment 1\n",
      "\u001b[32m[I 2022-01-07 23:03:22,565]\u001b[0m Trial 1 finished with value: 0.1577547183286018 and parameters: {'rate': 0.004812893194050143, 'offset': 0.1}. Best is trial 1 with value: 0.1577547183286018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 12 epochs\n",
      "epoch 0: accuracy: 0.10481289319405016\n",
      "epoch 1: accuracy: 0.1096257863881003\n",
      "epoch 2: accuracy: 0.11443867958215045\n",
      "epoch 3: accuracy: 0.1192515727762006\n",
      "epoch 4: accuracy: 0.12406446597025075\n",
      "epoch 5: accuracy: 0.1288773591643009\n",
      "epoch 6: accuracy: 0.13369025235835105\n",
      "epoch 7: accuracy: 0.1385031455524012\n",
      "epoch 8: accuracy: 0.14331603874645135\n",
      "epoch 9: accuracy: 0.1481289319405015\n",
      "epoch 10: accuracy: 0.15294182513455165\n",
      "epoch 11: accuracy: 0.1577547183286018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starting experiment 2 with run number 0\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=12,\n",
      "\toffset=0.05,\n",
      "\trate=0.009672964844509264\n",
      "\n",
      "script: /tmp/ipykernel_17968/4246270235.py, line number: 20\n",
      "time spent on this experiment: 0.001718759536743164\n",
      "score: 0.1660755781341112\n",
      "0 - validation_accuracy: 0.1660755781341112\n",
      "0 - test_accuracy: 0.06607557813411119\n",
      "finished experiment 2\n",
      "\u001b[32m[I 2022-01-07 23:03:22,813]\u001b[0m Trial 2 finished with value: 0.1660755781341112 and parameters: {'rate': 0.009672964844509264, 'offset': 0.05}. Best is trial 2 with value: 0.1660755781341112.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 12 epochs\n",
      "epoch 0: accuracy: 0.05967296484450926\n",
      "epoch 1: accuracy: 0.06934592968901852\n",
      "epoch 2: accuracy: 0.07901889453352778\n",
      "epoch 3: accuracy: 0.08869185937803704\n",
      "epoch 4: accuracy: 0.0983648242225463\n",
      "epoch 5: accuracy: 0.10803778906705556\n",
      "epoch 6: accuracy: 0.11771075391156482\n",
      "epoch 7: accuracy: 0.1273837187560741\n",
      "epoch 8: accuracy: 0.13705668360058337\n",
      "epoch 9: accuracy: 0.14672964844509265\n",
      "epoch 10: accuracy: 0.15640261328960192\n",
      "epoch 11: accuracy: 0.1660755781341112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starting experiment 3 with run number 0\n",
      "running experiment 3\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=12,\n",
      "\toffset=0.01,\n",
      "\trate=0.006112401049845392\n",
      "\n",
      "script: /tmp/ipykernel_17968/4246270235.py, line number: 20\n",
      "time spent on this experiment: 0.0020475387573242188\n",
      "score: 0.08334881259814472\n",
      "0 - validation_accuracy: 0.08334881259814472\n",
      "0 - test_accuracy: 0.0\n",
      "finished experiment 3\n",
      "\u001b[32m[I 2022-01-07 23:03:23,061]\u001b[0m Trial 3 finished with value: 0.08334881259814472 and parameters: {'rate': 0.006112401049845392, 'offset': 0.01}. Best is trial 2 with value: 0.1660755781341112.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 12 epochs\n",
      "epoch 0: accuracy: 0.01611240104984539\n",
      "epoch 1: accuracy: 0.022224802099690782\n",
      "epoch 2: accuracy: 0.028337203149536173\n",
      "epoch 3: accuracy: 0.03444960419938156\n",
      "epoch 4: accuracy: 0.04056200524922696\n",
      "epoch 5: accuracy: 0.04667440629907235\n",
      "epoch 6: accuracy: 0.05278680734891775\n",
      "epoch 7: accuracy: 0.05889920839876314\n",
      "epoch 8: accuracy: 0.06501160944860854\n",
      "epoch 9: accuracy: 0.07112401049845393\n",
      "epoch 10: accuracy: 0.07723641154829933\n",
      "epoch 11: accuracy: 0.08334881259814472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starting experiment 4 with run number 0\n",
      "running experiment 4\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=12,\n",
      "\toffset=0.1,\n",
      "\trate=0.0011819655769629315\n",
      "\n",
      "script: /tmp/ipykernel_17968/4246270235.py, line number: 20\n",
      "time spent on this experiment: 0.0018162727355957031\n",
      "score: 0.11418358692355515\n",
      "0 - validation_accuracy: 0.11418358692355515\n",
      "0 - test_accuracy: 0.014183586923555147\n",
      "finished experiment 4\n",
      "\u001b[32m[I 2022-01-07 23:03:23,340]\u001b[0m Trial 4 finished with value: 0.11418358692355515 and parameters: {'rate': 0.0011819655769629315, 'offset': 0.1}. Best is trial 2 with value: 0.1660755781341112.\u001b[0m\n",
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "Value: 0.1660755781341112\n",
      "best params: {'offset': 0.05, 'rate': 0.009672964844509264}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 12 epochs\n",
      "epoch 0: accuracy: 0.10118196557696293\n",
      "epoch 1: accuracy: 0.10236393115392586\n",
      "epoch 2: accuracy: 0.10354589673088879\n",
      "epoch 3: accuracy: 0.10472786230785172\n",
      "epoch 4: accuracy: 0.10590982788481465\n",
      "epoch 5: accuracy: 0.10709179346177758\n",
      "epoch 6: accuracy: 0.10827375903874051\n",
      "epoch 7: accuracy: 0.10945572461570344\n",
      "epoch 8: accuracy: 0.11063769019266637\n",
      "epoch 9: accuracy: 0.1118196557696293\n",
      "epoch 10: accuracy: 0.11300162134659222\n",
      "epoch 11: accuracy: 0.11418358692355515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>rate</th>\n",
       "      <th>offset</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.081272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>23:03:22.210886</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.157755</td>\n",
       "      <td>0.057755</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>23:03:22.479159</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.166076</td>\n",
       "      <td>0.066076</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>23:03:22.743439</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.083349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>23:03:22.992142</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.114184</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>23:03:23.256664</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs      rate  offset  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0    12.0  0.005939    0.01               0.081272         0.000000  0.002821   \n",
       "1    12.0  0.004813    0.10               0.157755         0.057755  0.002794   \n",
       "2    12.0  0.009673    0.05               0.166076         0.066076  0.002721   \n",
       "3    12.0  0.006112    0.01               0.083349         0.000000  0.003307   \n",
       "4    12.0  0.001182    0.10               0.114184         0.014184  0.002832   \n",
       "\n",
       "              date 0_finished  \n",
       "0  23:03:22.210886       True  \n",
       "1  23:03:22.479159       True  \n",
       "2  23:03:22.743439       True  \n",
       "3  23:03:22.992142       True  \n",
       "4  23:03:23.256664       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_hp_optimization, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rerun_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def parameter_sampler (trial):\n",
    "    epochs = trial.suggest_categorical('epochs', [2, 4])\n",
    "    offset = trial.suggest_categorical('offset', [0.02, 0.06])\n",
    "    \n",
    "    parameters = dict(epochs=epochs, \n",
    "                      offset=offset)\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def test_rerun_experiment ():\n",
    "    em = init_em ('rerun_experiment')\n",
    "    \n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5},\n",
    "                                          other_parameters={'halt': True})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 2})\n",
    "    _ = em.create_experiment_and_run (parameters={'rate': 0.04})\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(3,8)\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 1: re-running finished experiment\n",
    "    # ****************************************\n",
    "    em.raise_error_if_run = True\n",
    "    em.rerun_experiment (experiments=[1])\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 2: re-running interrupted experiment\n",
    "    # ****************************************\n",
    "    em.raise_error_if_run = False\n",
    "    em.rerun_experiment (experiments=[0], other_parameters={'halt':False, 'verbose':False})\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.loc[0,'0_validation_accuracy']==0.35\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 3: adding more runs to previous experiment\n",
    "    # ****************************************\n",
    "    em.rerun_experiment (experiments=[1], nruns=5, other_parameters={'noise': 0.001, 'verbose':False})\n",
    "    df = em.get_experiment_data ()\n",
    "    x=[f'{i}_validation_accuracy' for i in range(5)]; assert df.columns.isin(x).sum()==5\n",
    "    assert df.shape==(3,24)\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 4: using previous experiment parameters as fixed, and using grid search with other \n",
    "    # parameters\n",
    "    # ****************************************\n",
    "    em.rerun_experiment (experiments=[2], \n",
    "                         parameters_multiple_values={'offset': [0.01,0.05], 'epochs': [3,5]},\n",
    "                         other_parameters={'verbose':False},\n",
    "                         nruns=2)\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(7,24)\n",
    "    assert np.max(np.abs(df['0_validation_accuracy'].values- [0.35, 0.16, 0.9,  0.13, 0.17, 0.21, 0.25])) < 1e-10\n",
    "    assert df.isna()['1_validation_accuracy'].sum()==2\n",
    "    n1 = (~df.isna())['1_validation_accuracy'].sum()\n",
    "    n0 = (~df.isna())['0_validation_accuracy'].sum()\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 5: using previous experiment parameters as fixed, and using BO with other \n",
    "    # parameters\n",
    "    # ****************************************\n",
    "    em.rerun_experiment (experiments=[2], \n",
    "                         parameter_sampler=parameter_sampler,\n",
    "                         other_parameters={'n_trials':4, 'verbose':False, 'sampler_method':'skopt'})\n",
    "    df2 = em.get_experiment_data ()\n",
    "    display (df2)\n",
    "    print (df2.shape)\n",
    "    assert df2.shape[0]>7\n",
    "    n1 = (~df2.isna())['1_validation_accuracy'].sum()\n",
    "    n0 = (~df2.isna())['0_validation_accuracy'].sum()\n",
    "    #assert (n0+n1)==16\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 16\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_rerun_experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 16\n",
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 18\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 18\n",
      "time spent on this experiment: 0.0007839202880859375\n",
      "score: 0.16\n",
      "0 - validation_accuracy: 0.16\n",
      "0 - test_accuracy: 0.26\n",
      "finished experiment 1\n",
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 19\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0021576881408691406\n",
      "score: 0.9000000000000004\n",
      "0 - validation_accuracy: 0.9000000000000004\n",
      "0 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "requiring experiment number to be 1\n",
      "running experiment 1 with parameters:\n",
      "{'offset': 0.1, 'rate': 0.03, 'epochs': 2}\n",
      "other_parameters:\n",
      "{'script_path': '/tmp/ipykernel_17968/1270020730.py', 'lineno': 18, 'experiment_number': 1, 'suffix_results': '_validation_accuracy', 'path_results_big': 'test_rerun_experiment/experiments/00001/0', 'git_hash': \"b'1314053a6166d51cb2713a9356811095a91da6c8\\\\n'\"}\n",
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 27\n",
      "doing run 0 out of 1\n",
      "\n",
      "found completed: experiment number: 1, run number: 0 - score: 0.160000\n",
      "{'offset': 0.1, 'rate': 0.03, 'epochs': 2}\n",
      "skipping...\n",
      "mean : 0.16, std: 0.0\n",
      "requiring experiment number to be 0\n",
      "running experiment 0 with parameters:\n",
      "{'offset': 0.1, 'rate': 0.05, 'epochs': 5}\n",
      "other_parameters:\n",
      "{'halt': False, 'script_path': '/tmp/ipykernel_17968/1270020730.py', 'lineno': 16, 'experiment_number': 0, 'suffix_results': '_validation_accuracy', 'path_results_big': 'test_rerun_experiment/experiments/00000/0', 'git_hash': \"b'1314053a6166d51cb2713a9356811095a91da6c8\\\\n'\", 'verbose': False}\n",
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 33\n",
      "doing run 0 out of 1\n",
      "\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.05\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 16\n",
      "time spent on this experiment: 0.0003070831298828125\n",
      "score: 0.35\n",
      "0 - validation_accuracy: 0.35\n",
      "0 - test_accuracy: 0.44999999999999996\n",
      "finished experiment 0\n",
      "mean : 0.35, std: 0.0\n",
      "requiring experiment number to be 1\n",
      "running experiment 1 with parameters:\n",
      "{'offset': 0.1, 'rate': 0.03, 'epochs': 2}\n",
      "other_parameters:\n",
      "{'script_path': '/tmp/ipykernel_17968/1270020730.py', 'lineno': 18, 'experiment_number': 1, 'suffix_results': '_validation_accuracy', 'path_results_big': 'test_rerun_experiment/experiments/00001/0', 'git_hash': \"b'1314053a6166d51cb2713a9356811095a91da6c8\\\\n'\", 'noise': 0.001, 'verbose': False}\n",
      "experiment script: /tmp/ipykernel_17968/1270020730.py, line: 40\n",
      "doing run 0 out of 5\n",
      "\n",
      "found completed: experiment number: 1, run number: 0 - score: 0.160000\n",
      "{'offset': 0.1, 'rate': 0.03, 'epochs': 2}\n",
      "skipping...\n",
      "doing run 1 out of 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running experiment 1\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 18\n",
      "time spent on this experiment: 0.00024080276489257812\n",
      "score: 0.15977653721467416\n",
      "1 - validation_accuracy: 0.15977653721467416\n",
      "1 - test_accuracy: 0.2607140004940921\n",
      "finished experiment 1\n",
      "doing run 2 out of 5\n",
      "\n",
      "running experiment 1\n",
      "run number: 2\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 18\n",
      "time spent on this experiment: 0.00023031234741210938\n",
      "score: 0.15955348504793299\n",
      "2 - validation_accuracy: 0.15955348504793299\n",
      "2 - test_accuracy: 0.2608563987943235\n",
      "finished experiment 1\n",
      "doing run 3 out of 5\n",
      "\n",
      "running experiment 1\n",
      "run number: 3\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 18\n",
      "time spent on this experiment: 0.0002415180206298828\n",
      "score: 0.15911614256379886\n",
      "3 - validation_accuracy: 0.15911614256379886\n",
      "3 - test_accuracy: 0.26015372510594553\n",
      "finished experiment 1\n",
      "doing run 4 out of 5\n",
      "\n",
      "running experiment 1\n",
      "run number: 4\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 18\n",
      "time spent on this experiment: 0.0002465248107910156\n",
      "score: 0.1610830512431753\n",
      "4 - validation_accuracy: 0.1610830512431753\n",
      "4 - test_accuracy: 0.26105380205203493\n",
      "finished experiment 1\n",
      "mean : 0.15990584321391627, std: 0.0006571434668150468\n",
      "running experiment 2 with parameters:\n",
      "{'rate': 0.04}\n",
      "other_parameters:\n",
      "{'script_path': '/tmp/ipykernel_17968/1270020730.py', 'lineno': 19, 'suffix_results': '_validation_accuracy', 'path_results_big': 'test_rerun_experiment/experiments/00002/0', 'git_hash': \"b'1314053a6166d51cb2713a9356811095a91da6c8\\\\n'\", 'verbose': False}\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 3\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=3,\n",
      "\toffset=0.01,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0002465248107910156\n",
      "score: 0.13\n",
      "0 - validation_accuracy: 0.13\n",
      "0 - test_accuracy: 0.23\n",
      "finished experiment 3\n",
      "processing hyper-parameter 0 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 3\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=3,\n",
      "\toffset=0.01,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0002498626708984375\n",
      "score: 0.13\n",
      "1 - validation_accuracy: 0.13\n",
      "1 - test_accuracy: 0.23\n",
      "finished experiment 3\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 4\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=3,\n",
      "\toffset=0.05,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0003306865692138672\n",
      "score: 0.17\n",
      "0 - validation_accuracy: 0.17\n",
      "0 - test_accuracy: 0.27\n",
      "finished experiment 4\n",
      "processing hyper-parameter 1 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 4\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=3,\n",
      "\toffset=0.05,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0002810955047607422\n",
      "score: 0.17\n",
      "1 - validation_accuracy: 0.17\n",
      "1 - test_accuracy: 0.27\n",
      "finished experiment 4\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 5\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.01,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.00025534629821777344\n",
      "score: 0.21000000000000002\n",
      "0 - validation_accuracy: 0.21000000000000002\n",
      "0 - test_accuracy: 0.31000000000000005\n",
      "finished experiment 5\n",
      "processing hyper-parameter 2 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 5\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.01,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0003008842468261719\n",
      "score: 0.21000000000000002\n",
      "1 - validation_accuracy: 0.21000000000000002\n",
      "1 - test_accuracy: 0.31000000000000005\n",
      "finished experiment 5\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 0 out of 2\n",
      "\n",
      "running experiment 6\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.05,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0002739429473876953\n",
      "score: 0.25\n",
      "0 - validation_accuracy: 0.25\n",
      "0 - test_accuracy: 0.35\n",
      "finished experiment 6\n",
      "processing hyper-parameter 3 out of 4\n",
      "doing run 1 out of 2\n",
      "\n",
      "running experiment 6\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.05,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.00023126602172851562\n",
      "score: 0.25\n",
      "1 - validation_accuracy: 0.25\n",
      "1 - test_accuracy: 0.35\n",
      "finished experiment 6\n",
      "running experiment 2 with parameters:\n",
      "{'rate': 0.04}\n",
      "other_parameters:\n",
      "{'script_path': '/tmp/ipykernel_17968/1270020730.py', 'lineno': 19, 'suffix_results': '_validation_accuracy', 'path_results_big': 'test_rerun_experiment/experiments/00002/0', 'git_hash': \"b'1314053a6166d51cb2713a9356811095a91da6c8\\\\n'\", 'n_trials': 4, 'verbose': False, 'sampler_method': 'skopt'}\n",
      "running hp_optimization\n",
      "Sampler: skopt - Pruner: halving\n",
      "\u001b[32m[I 2022-01-07 23:03:25,202]\u001b[0m A new study created in RDB with name: hp_study\u001b[0m\n",
      "starting experiment 7 with run number 0\n",
      "running experiment 7\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.02,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0002543926239013672\n",
      "score: 0.1\n",
      "0 - validation_accuracy: 0.1\n",
      "0 - test_accuracy: 0.2\n",
      "finished experiment 7\n",
      "\u001b[32m[I 2022-01-07 23:03:25,592]\u001b[0m Trial 0 finished with value: 0.1 and parameters: {'epochs': 2, 'offset': 0.02}. Best is trial 0 with value: 0.1.\u001b[0m\n",
      "starting experiment 8 with run number 0\n",
      "running experiment 8\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=4,\n",
      "\toffset=0.02,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.0003159046173095703\n",
      "score: 0.18000000000000002\n",
      "0 - validation_accuracy: 0.18000000000000002\n",
      "0 - test_accuracy: 0.28\n",
      "finished experiment 8\n",
      "\u001b[32m[I 2022-01-07 23:03:25,882]\u001b[0m Trial 1 finished with value: 0.18000000000000002 and parameters: {'epochs': 4, 'offset': 0.02}. Best is trial 1 with value: 0.18000000000000002.\u001b[0m\n",
      "starting experiment 9 with run number 0\n",
      "running experiment 9\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=4,\n",
      "\toffset=0.06,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.00029277801513671875\n",
      "score: 0.22000000000000003\n",
      "0 - validation_accuracy: 0.22000000000000003\n",
      "0 - test_accuracy: 0.32000000000000006\n",
      "finished experiment 9\n",
      "\u001b[32m[I 2022-01-07 23:03:26,177]\u001b[0m Trial 2 finished with value: 0.22000000000000003 and parameters: {'epochs': 4, 'offset': 0.06}. Best is trial 2 with value: 0.22000000000000003.\u001b[0m\n",
      "found previous run for experiment number 7, run 0, with score validation_accuracy = 0.1\n",
      "starting experiment 7 with run number 1\n",
      "running experiment 7\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.02,\n",
      "\trate=0.04\n",
      "\n",
      "script: /tmp/ipykernel_17968/1270020730.py, line number: 19\n",
      "time spent on this experiment: 0.00029087066650390625\n",
      "score: 0.1\n",
      "1 - validation_accuracy: 0.1\n",
      "1 - test_accuracy: 0.2\n",
      "finished experiment 7\n",
      "\u001b[32m[I 2022-01-07 23:03:26,456]\u001b[0m Trial 3 finished with value: 0.1 and parameters: {'epochs': 2, 'offset': 0.02}. Best is trial 2 with value: 0.22000000000000003.\u001b[0m\n",
      "Number of finished trials: 4\n",
      "Best trial:\n",
      "Value: 0.22000000000000003\n",
      "best params: {'epochs': 4, 'offset': 0.06}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "      <th>3_validation_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>time_3</th>\n",
       "      <th>3_finished</th>\n",
       "      <th>4_validation_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "      <th>time_4</th>\n",
       "      <th>4_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>23:03:23.605901</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>23:03:23.801889</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159777</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159116</td>\n",
       "      <td>0.260154</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>True</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>0.261054</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>23:03:23.543798</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>23:03:23.901293</td>\n",
       "      <td>True</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>23:03:24.000448</td>\n",
       "      <td>True</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>23:03:24.105126</td>\n",
       "      <td>True</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>23:03:24.208955</td>\n",
       "      <td>True</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>23:03:26.377771</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>23:03:25.807008</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>23:03:26.089913</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0    0.10  0.05     5.0                   0.35             0.45  0.001425   \n",
       "1    0.10  0.03     2.0                   0.16             0.26  0.001879   \n",
       "2     NaN  0.04     NaN                   0.90             0.80  0.003241   \n",
       "3    0.01  0.04     3.0                   0.13             0.23  0.001298   \n",
       "4    0.05  0.04     3.0                   0.17             0.27  0.001418   \n",
       "5    0.01  0.04     5.0                   0.21             0.31  0.001335   \n",
       "6    0.05  0.04     5.0                   0.25             0.35  0.001387   \n",
       "7    0.02  0.04     2.0                   0.10             0.20  0.001314   \n",
       "8    0.02  0.04     4.0                   0.18             0.28  0.001367   \n",
       "9    0.06  0.04     4.0                   0.22             0.32  0.001762   \n",
       "\n",
       "              date 0_finished  1_validation_accuracy  1_test_accuracy  ...  \\\n",
       "0  23:03:23.605901       True                    NaN              NaN  ...   \n",
       "1  23:03:23.801889       True               0.159777         0.260714  ...   \n",
       "2  23:03:23.543798       True                    NaN              NaN  ...   \n",
       "3  23:03:23.901293       True               0.130000         0.230000  ...   \n",
       "4  23:03:24.000448       True               0.170000         0.270000  ...   \n",
       "5  23:03:24.105126       True               0.210000         0.310000  ...   \n",
       "6  23:03:24.208955       True               0.250000         0.350000  ...   \n",
       "7  23:03:26.377771       True               0.100000         0.200000  ...   \n",
       "8  23:03:25.807008       True                    NaN              NaN  ...   \n",
       "9  23:03:26.089913       True                    NaN              NaN  ...   \n",
       "\n",
       "     time_2 2_finished  3_validation_accuracy  3_test_accuracy   time_3  \\\n",
       "0       NaN        NaN                    NaN              NaN      NaN   \n",
       "1  0.001259       True               0.159116         0.260154  0.00132   \n",
       "2       NaN        NaN                    NaN              NaN      NaN   \n",
       "3       NaN        NaN                    NaN              NaN      NaN   \n",
       "4       NaN        NaN                    NaN              NaN      NaN   \n",
       "5       NaN        NaN                    NaN              NaN      NaN   \n",
       "6       NaN        NaN                    NaN              NaN      NaN   \n",
       "7       NaN        NaN                    NaN              NaN      NaN   \n",
       "8       NaN        NaN                    NaN              NaN      NaN   \n",
       "9       NaN        NaN                    NaN              NaN      NaN   \n",
       "\n",
       "  3_finished  4_validation_accuracy  4_test_accuracy    time_4 4_finished  \n",
       "0        NaN                    NaN              NaN       NaN        NaN  \n",
       "1       True               0.161083         0.261054  0.001281       True  \n",
       "2        NaN                    NaN              NaN       NaN        NaN  \n",
       "3        NaN                    NaN              NaN       NaN        NaN  \n",
       "4        NaN                    NaN              NaN       NaN        NaN  \n",
       "5        NaN                    NaN              NaN       NaN        NaN  \n",
       "6        NaN                    NaN              NaN       NaN        NaN  \n",
       "7        NaN                    NaN              NaN       NaN        NaN  \n",
       "8        NaN                    NaN              NaN       NaN        NaN  \n",
       "9        NaN                    NaN              NaN       NaN        NaN  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 24)\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_rerun_experiment, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rerun_experiment_pipeline\n",
    "\n",
    "Allows to update some of the parameters on previous experiments and re-run them with those updated parameters, keeping the experiment number unchanged. Optionally, it can save the result to the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_rerun_experiment_pipeline ():\n",
    "    em = init_em ('rerun_experiment_pipeline')\n",
    "    \n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5},\n",
    "                                          other_parameters={'halt': True})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 2})\n",
    "    _ = em.run_multiple_repetitions (parameters={'rate': 0.04}, nruns=5)\n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    assert np.abs(df.loc[1,'0_validation_accuracy']-0.16)<1e-5 and (df.loc[1, '0_test_accuracy']-0.26)<1e-5\n",
    "    #print (df.shape)\n",
    "    assert df.shape==(3,24)\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 1: re-running finished experiment\n",
    "    # ****************************************\n",
    "    # the following produces an error since run_numbers must be indicated\n",
    "    with pytest.raises (TypeError):\n",
    "        em.rerun_experiment_pipeline (experiments=[1])\n",
    "    \n",
    "    em.raise_error_if_run = True\n",
    "    with pytest.raises (RuntimeError):\n",
    "        em.rerun_experiment_pipeline (experiments=[1], run_numbers=[0])\n",
    "    em.raise_error_if_run = False\n",
    "    # ****************************************\n",
    "    # case 2: changing parameters of prev experiment number\n",
    "    # ****************************************\n",
    "    em.rerun_experiment_pipeline (experiments=[1], run_numbers=[0], \n",
    "                                  new_parameters={'rate': 0.04}, save_results=True)\n",
    "    df = em.get_experiment_data ()\n",
    "    assert np.abs(df.loc[1,'0_validation_accuracy']-0.18)<1e-5 and np.abs(df.loc[1, '0_test_accuracy']-0.28)<1e-5\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 2: re-running interrupted experiment\n",
    "    # ****************************************\n",
    "    # the following produces an error since halt is True in loaded parameters\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        em.rerun_experiment_pipeline (experiments=[0], run_numbers=[0])\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 3: adding more runs to previous experiment\n",
    "    # ****************************************\n",
    "    # the following produces an error since run_numbers must be a subset of those already run\n",
    "    with pytest.raises (FileNotFoundError):\n",
    "        em.rerun_experiment_pipeline (experiments=[1], run_numbers=list(range(5)))\n",
    "        \n",
    "    em.rerun_experiment_pipeline (experiments=[2], run_numbers=list(range(5)))\n",
    "    df2 = em.get_experiment_data ()\n",
    "    pd.testing.assert_frame_equal(df,df2)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/258747340.py, line: 7\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.05\n",
      "\n",
      "script: /tmp/ipykernel_17968/258747340.py, line number: 7\n",
      "experiment script: /tmp/ipykernel_17968/258747340.py, line: 9\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/258747340.py, line number: 9\n",
      "time spent on this experiment: 0.0006632804870605469\n",
      "score: 0.16\n",
      "0 - validation_accuracy: 0.16\n",
      "0 - test_accuracy: 0.26\n",
      "finished experiment 1\n",
      "doing run 0 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015058517456054688\n",
      "score: 0.9000000000000004\n",
      "0 - validation_accuracy: 0.9000000000000004\n",
      "0 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 1 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_rerun_experiment_pipeline\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0016970634460449219\n",
      "score: 0.9000000000000004\n",
      "1 - validation_accuracy: 0.9000000000000004\n",
      "1 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 2 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 2\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015330314636230469\n",
      "score: 0.9000000000000004\n",
      "2 - validation_accuracy: 0.9000000000000004\n",
      "2 - test_accuracy: 0.8000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finished experiment 2\n",
      "doing run 3 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 3\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015239715576171875\n",
      "score: 0.9000000000000004\n",
      "3 - validation_accuracy: 0.9000000000000004\n",
      "3 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 4 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 4\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015299320220947266\n",
      "score: 0.9000000000000004\n",
      "4 - validation_accuracy: 0.9000000000000004\n",
      "4 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "mean : 0.9000000000000004, std: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "      <th>3_validation_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>time_3</th>\n",
       "      <th>3_finished</th>\n",
       "      <th>4_validation_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "      <th>time_4</th>\n",
       "      <th>4_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>23:03:26.631063</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>23:03:26.856945</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05     5.0                    NaN              NaN       NaN   \n",
       "1     0.1  0.03     2.0                   0.16             0.26  0.001702   \n",
       "2     NaN  0.04     NaN                   0.90             0.80  0.002523   \n",
       "\n",
       "              date 0_finished  1_validation_accuracy  1_test_accuracy  ...  \\\n",
       "0              NaN        NaN                    NaN              NaN  ...   \n",
       "1  23:03:26.631063       True                    NaN              NaN  ...   \n",
       "2  23:03:26.856945       True                    0.9              0.8  ...   \n",
       "\n",
       "     time_2 2_finished  3_validation_accuracy  3_test_accuracy    time_3  \\\n",
       "0       NaN        NaN                    NaN              NaN       NaN   \n",
       "1       NaN        NaN                    NaN              NaN       NaN   \n",
       "2  0.002529       True                    0.9              0.8  0.002537   \n",
       "\n",
       "  3_finished  4_validation_accuracy  4_test_accuracy    time_4 4_finished  \n",
       "0        NaN                    NaN              NaN       NaN        NaN  \n",
       "1        NaN                    NaN              NaN       NaN        NaN  \n",
       "2       True                    0.9              0.8  0.002591       True  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time spent on this experiment: 0.0006670951843261719\n",
      "score: 0.18000000000000002\n",
      "time spent on this experiment: 0.0007505416870117188\n",
      "score: 0.16\n",
      "time spent on this experiment: 0.0014848709106445312\n",
      "score: 0.9000000000000004\n",
      "time spent on this experiment: 0.0017549991607666016\n",
      "score: 0.9000000000000004\n",
      "time spent on this experiment: 0.0014443397521972656\n",
      "score: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.14\n",
      "epoch 1: accuracy: 0.18000000000000002\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time spent on this experiment: 0.0020360946655273438\n",
      "score: 0.9000000000000004\n",
      "time spent on this experiment: 0.00164794921875\n",
      "score: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_rerun_experiment_pipeline, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### rerun_experiment_par\n",
    "\n",
    "The only difference with `rerun_experiment_pipeline` is that now we need to introduce all the parameters to be used. Therefore, `rerun_experiment_par` is not about updating *some* of the parameters but about using entirely new parameters. There is no saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export tests.test_experiment_manager\n",
    "def test_rerun_experiment_par ():\n",
    "    em = init_em ('rerun_experiment_par')\n",
    "    \n",
    "    # first 3 experiments\n",
    "    with pytest.raises (KeyboardInterrupt):\n",
    "        _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5},\n",
    "                                          other_parameters={'halt': True})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.03, 'epochs': 2})\n",
    "    _ = em.run_multiple_repetitions (parameters={'rate': 0.04}, nruns=5)\n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    assert np.abs(df.loc[1,'0_validation_accuracy']-0.16)<1e-5 and (df.loc[1, '0_test_accuracy']-0.26)<1e-5\n",
    "    #print (df.shape)\n",
    "    assert df.shape==(3,24)\n",
    "    \n",
    "    # ****************************************\n",
    "    # case 1: re-running finished experiment\n",
    "    # ****************************************\n",
    "    # the following produces an error since run_numbers must be indicated\n",
    "    with pytest.raises (TypeError):\n",
    "        em.rerun_experiment_par (experiments=[1])\n",
    "    \n",
    "    em.raise_error_if_run = True\n",
    "    with pytest.raises (RuntimeError):\n",
    "        em.rerun_experiment_par (experiments=[1], run_numbers=[0])\n",
    "    em.raise_error_if_run = False\n",
    "    # ****************************************\n",
    "    # case 2: changing parameters of prev experiment number\n",
    "    # ****************************************\n",
    "    em.rerun_experiment_par (experiments=[1], run_numbers=[0], \n",
    "                                  parameters={'rate': 0.04})\n",
    "    df2 = em.get_experiment_data ()\n",
    "\n",
    "    pd.testing.assert_frame_equal(df,df2)\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "experiment script: /tmp/ipykernel_17968/2626610475.py, line: 7\n",
      "running experiment 0\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=5,\n",
      "\toffset=0.1,\n",
      "\trate=0.05\n",
      "\n",
      "script: /tmp/ipykernel_17968/2626610475.py, line number: 7\n",
      "experiment script: /tmp/ipykernel_17968/2626610475.py, line: 9\n",
      "running experiment 1\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\tepochs=2,\n",
      "\toffset=0.1,\n",
      "\trate=0.03\n",
      "\n",
      "script: /tmp/ipykernel_17968/2626610475.py, line number: 9\n",
      "time spent on this experiment: 0.0006229877471923828\n",
      "score: 0.16\n",
      "0 - validation_accuracy: 0.16\n",
      "0 - test_accuracy: 0.26\n",
      "finished experiment 1\n",
      "doing run 0 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 0\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0024886131286621094\n",
      "score: 0.9000000000000004\n",
      "0 - validation_accuracy: 0.9000000000000004\n",
      "0 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 1 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 1\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.001641988754272461\n",
      "score: 0.9000000000000004\n",
      "1 - validation_accuracy: 0.9000000000000004\n",
      "1 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 2 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 2\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015268325805664062\n",
      "score: 0.9000000000000004\n",
      "2 - validation_accuracy: 0.9000000000000004\n",
      "2 - test_accuracy: 0.8000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_rerun_experiment_par\n",
      "fitting model with 5 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "fitting model with 2 epochs\n",
      "epoch 0: accuracy: 0.13\n",
      "epoch 1: accuracy: 0.16\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "finished experiment 2\n",
      "doing run 3 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 3\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0015747547149658203\n",
      "score: 0.9000000000000004\n",
      "3 - validation_accuracy: 0.9000000000000004\n",
      "3 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "doing run 4 out of 5\n",
      "\n",
      "experiment script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line: 605\n",
      "running experiment 2\n",
      "run number: 4\n",
      "\n",
      "parameters:\n",
      "\trate=0.04\n",
      "\n",
      "script: /home/jcidatascience/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py, line number: 605\n",
      "time spent on this experiment: 0.0017032623291015625\n",
      "score: 0.9000000000000004\n",
      "4 - validation_accuracy: 0.9000000000000004\n",
      "4 - test_accuracy: 0.8000000000000004\n",
      "finished experiment 2\n",
      "mean : 0.9000000000000004, std: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "      <th>3_validation_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>time_3</th>\n",
       "      <th>3_finished</th>\n",
       "      <th>4_validation_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "      <th>time_4</th>\n",
       "      <th>4_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>23:12:45.584655</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>23:12:45.810447</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  epochs  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05     5.0                    NaN              NaN       NaN   \n",
       "1     0.1  0.03     2.0                   0.16             0.26  0.001598   \n",
       "2     NaN  0.04     NaN                   0.90             0.80  0.003520   \n",
       "\n",
       "              date 0_finished  1_validation_accuracy  1_test_accuracy  ...  \\\n",
       "0              NaN        NaN                    NaN              NaN  ...   \n",
       "1  23:12:45.584655       True                    NaN              NaN  ...   \n",
       "2  23:12:45.810447       True                    0.9              0.8  ...   \n",
       "\n",
       "     time_2 2_finished  3_validation_accuracy  3_test_accuracy    time_3  \\\n",
       "0       NaN        NaN                    NaN              NaN       NaN   \n",
       "1       NaN        NaN                    NaN              NaN       NaN   \n",
       "2  0.002526       True                    0.9              0.8  0.002574   \n",
       "\n",
       "  3_finished  4_validation_accuracy  4_test_accuracy   time_4 4_finished  \n",
       "0        NaN                    NaN              NaN      NaN        NaN  \n",
       "1        NaN                    NaN              NaN      NaN        NaN  \n",
       "2       True                    0.9              0.8  0.00264       True  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time spent on this experiment: 0.0016181468963623047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.54\n",
      "epoch 1: accuracy: 0.5800000000000001\n",
      "epoch 2: accuracy: 0.6200000000000001\n",
      "epoch 3: accuracy: 0.6600000000000001\n",
      "epoch 4: accuracy: 0.7000000000000002\n",
      "epoch 5: accuracy: 0.7400000000000002\n",
      "epoch 6: accuracy: 0.7800000000000002\n",
      "epoch 7: accuracy: 0.8200000000000003\n",
      "epoch 8: accuracy: 0.8600000000000003\n",
      "epoch 9: accuracy: 0.9000000000000004\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_rerun_experiment_par, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get_git_revision_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_git_revision_hash (root_path=None):\n",
    "    try:\n",
    "        git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n",
    "        git_hash = str(git_hash)\n",
    "        json.dump(git_hash, open('%s/git_hash.json' %root_path, 'wt'))\n",
    "    except:\n",
    "        logger = logging.getLogger(\"experiment_manager\")\n",
    "        if root_path is not None:\n",
    "            logger.info ('could not get git hash, retrieving it from disk...')\n",
    "            git_hash = json.load(open('%s/git_hash.json' %root_path, 'rt'))\n",
    "        else:\n",
    "            logger.info ('could not get git hash, using empty string...')\n",
    "            git_hash = ''\n",
    "\n",
    "    return str(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## record_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def record_parameters (path_save, parameters, other_parameters=None):\n",
    "    with open('%s/parameters.txt' %path_save, 'wt') as f:\n",
    "        f.write('%s\\n' %mypprint(parameters, dict_name='parameters'))\n",
    "        if other_parameters is not None:\n",
    "            f.write('\\n\\n%s\\n' %mypprint(other_parameters, dict_name='other_parameters'))\n",
    "    if other_parameters is not None:\n",
    "        pickle.dump ([parameters,other_parameters],open('%s/parameters.pk' %path_save, 'wb'))\n",
    "    else:\n",
    "        pickle.dump (parameters,open('%s/parameters.pk' %path_save, 'wb'))\n",
    "    try:\n",
    "        json.dump(parameters,open('%s/parameters.json' %path_save, 'wt'))\n",
    "    except:\n",
    "        pass\n",
    "    if other_parameters is not None:\n",
    "        try:\n",
    "            json.dump(parameters,open('%s/other_parameters.json' %path_save, 'wt'))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## mypprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def mypprint(parameters, dict_name=None):\n",
    "    if dict_name is not None:\n",
    "        text = '%s=dict(' %dict_name\n",
    "        tpad = ' ' * len(text)\n",
    "    else:\n",
    "        text = '\\t'\n",
    "        tpad = '\\t'\n",
    "    for idx, (key, value) in enumerate(sorted(parameters.items(), key=lambda x: x[0])):\n",
    "        if type(value) is str:\n",
    "            value = '%s%s%s' %(\"'\",value,\"'\")\n",
    "        text += '{}={}'.format(key, value)\n",
    "        if idx < (len(parameters)-1):\n",
    "            text += ',\\n{}'.format(tpad)\n",
    "\n",
    "    if dict_name is not None:\n",
    "        text += ')\\n'\n",
    "    else:\n",
    "        text += '\\n'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_or_create_experiment_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_or_create_experiment_values (path_csv, parameters, precision=1e-15):\n",
    "\n",
    "    logger = logging.getLogger(\"experiment_manager\")\n",
    "    path_pickle = path_csv.replace('csv', 'pk')\n",
    "    experiment_numbers = []\n",
    "    changed_dataframe = False\n",
    "\n",
    "    if os.path.exists (path_pickle) or os.path.exists (path_csv):\n",
    "        if os.path.exists (path_pickle):\n",
    "            experiment_data = pd.read_pickle (path_pickle)\n",
    "        else:\n",
    "            experiment_data = pd.read_csv (path_csv, index_col=0)\n",
    "            experiment_data.to_pickle(path_pickle)\n",
    "\n",
    "        experiment_data, removed_defaults = remove_defaults_from_experiment_data (experiment_data)\n",
    "\n",
    "        # Finds rows that match parameters. If the dataframe doesn't have any parameter with that name, a new column is created and changed_dataframe is set to True\n",
    "        experiment_numbers, changed_dataframe, _ = experiment_utils.find_rows_with_parameters_dict (\n",
    "            experiment_data, parameters, precision = precision\n",
    "        )\n",
    "\n",
    "        changed_dataframe = changed_dataframe or removed_defaults\n",
    "\n",
    "        if len(experiment_numbers) > 1:\n",
    "            logger.info ('more than one matching experiment: ', experiment_numbers)\n",
    "    else:\n",
    "        experiment_data = pd.DataFrame()\n",
    "\n",
    "    if len(experiment_numbers) == 0:\n",
    "        experiment_data = experiment_data.append (parameters, ignore_index=True)\n",
    "        changed_dataframe = True\n",
    "        experiment_number = experiment_data.shape[0]-1\n",
    "    else:\n",
    "        experiment_number = experiment_numbers[0]\n",
    "\n",
    "    if changed_dataframe:\n",
    "        experiment_data.to_csv(path_csv)\n",
    "        experiment_data.to_pickle(path_pickle)\n",
    "\n",
    "    return experiment_number, experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_parameters (root_path, experiment_number, parameters):\n",
    "    \"\"\" Keeps track of dictionary to map experiment number and parameters values for the different experiments.\"\"\"\n",
    "    path_hp_dictionary = '%s/parameters.pk' %root_path\n",
    "    if os.path.exists(path_hp_dictionary):\n",
    "        all_parameters = pickle.load (open(path_hp_dictionary,'rb'))\n",
    "    else:\n",
    "        all_parameters = {}\n",
    "    if experiment_number not in all_parameters.keys():\n",
    "        str_par = '\\n\\nExperiment %d => parameters: \\n%s\\n' %(experiment_number,mypprint(parameters))\n",
    "        f = open('%s/parameters.txt' %root_path, 'at')\n",
    "        f.write(str_par)\n",
    "        f.close()\n",
    "        all_parameters[experiment_number] = parameters\n",
    "        pickle.dump (all_parameters, open(path_hp_dictionary,'wb'))\n",
    "\n",
    "    # pickle number of current experiment, for visualization\n",
    "    pickle.dump(experiment_number, open('%s/current_experiment_number.pkl' %root_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isnull (experiment_data, experiment_number, name_column):\n",
    "    return (name_column not in experiment_data.columns) or (experiment_data.loc[experiment_number, name_column] is None) or np.isnan(experiment_data.loc[experiment_number, name_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_experiment_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_experiment_number (root_path, parameters = {}):\n",
    "\n",
    "    path_csv = '%s/experiments_data.csv' %root_path\n",
    "    path_pickle = path_csv.replace('csv', 'pk')\n",
    "    experiment_number, _ = load_or_create_experiment_values (path_csv, parameters)\n",
    "\n",
    "    return experiment_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_experiment_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_experiment_numbers (path_results_base, parameters_single_value, parameters_multiple_values_all):\n",
    "\n",
    "    experiment_numbers = []\n",
    "\n",
    "    parameters_multiple_values_all = list(ParameterGrid(parameters_multiple_values_all))\n",
    "\n",
    "    for (i_hp, parameters_multiple_values) in enumerate(parameters_multiple_values_all):\n",
    "        parameters = parameters_multiple_values.copy()\n",
    "        parameters.update(parameters_single_value)\n",
    "        parameters = remove_defaults (parameters)\n",
    "\n",
    "        experiment_number = get_experiment_number (path_results_base, parameters=parameters)\n",
    "        experiment_numbers.append(experiment_number)\n",
    "\n",
    "    return experiment_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert_experiment_script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_experiment_script_path (other_parameters, logger):\n",
    "    if other_parameters.get('script_path') is None:\n",
    "        stack_level = other_parameters.get('stack_level', -3)\n",
    "        stack = traceback.extract_stack()[stack_level]\n",
    "        other_parameters['script_path'] = stack.filename\n",
    "        other_parameters['lineno'] = stack.lineno\n",
    "        logger.info ('experiment script: {}, line: {}'.format(stack.filename, stack.lineno))\n",
    "        if 'stack_level' in other_parameters:\n",
    "            del other_parameters['stack_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_parameters (experiment=None, root_path=None, root_folder = None, \n",
    "                     other_parameters={}, parameters = {}, \n",
    "                     check_experiment_matches=True, em=None):\n",
    "\n",
    "    if em is None:\n",
    "        from hpsearch.config.hpconfig import get_experiment_manager\n",
    "        em = get_experiment_manager ()\n",
    "    if root_folder is not None:\n",
    "        other_parameters['root_folder'] = root_folder\n",
    "\n",
    "    if root_path is None:\n",
    "        root_path = em.get_path_experiments(folder  = other_parameters.get('root_folder'))\n",
    "\n",
    "    path_root_experiment = em.get_path_experiment (experiment, root_path=root_path)\n",
    "\n",
    "    if os.path.exists('%s/parameters.pk' %path_root_experiment):\n",
    "        parameters2, other_parameters2=pickle.load(open(f'{path_root_experiment}/parameters.pk','rb'))\n",
    "\n",
    "        other_parameters2.update(other_parameters)\n",
    "        other_parameters = other_parameters2\n",
    "\n",
    "        # if we don't add or modify parameters, we require that the old experiment number matches the new one\n",
    "        if (len(parameters) == 0) and check_experiment_matches:\n",
    "            em.logger.info (f'requiring experiment number to be {experiment}')\n",
    "            other_parameters['experiment_number'] = experiment\n",
    "        elif 'experiment_number' in other_parameters:\n",
    "            del other_parameters['experiment_number']\n",
    "\n",
    "        parameters2.update(parameters)\n",
    "        parameters = parameters2\n",
    "    else:\n",
    "        raise FileNotFoundError (f'file {path_root_experiment}/parameters.pk not found')\n",
    "\n",
    "    return parameters, other_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_other_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_other_parameters (experiment_number, other_parameters, root_path):\n",
    "    parameters_to_save = {}\n",
    "    for k in other_parameters.keys():\n",
    "        if type(other_parameters[k]) is str:\n",
    "            parameters_to_save[k] = other_parameters[k]\n",
    "        elif np.isscalar(other_parameters[k]) and np.isreal(other_parameters[k]):\n",
    "            parameters_to_save[k] = other_parameters[k]\n",
    "\n",
    "    path_csv = '%s/other_parameters.csv' %root_path\n",
    "    df = pd.DataFrame (index = [experiment_number], data=parameters_to_save)\n",
    "\n",
    "    if os.path.exists (path_csv):\n",
    "        df_all = pd.read_csv (path_csv, index_col=0)\n",
    "        df_all = pd.concat([df_all, df], sort=True)\n",
    "        df_all = df_all.loc[~df_all.index.duplicated(keep='last')]\n",
    "    else:\n",
    "        df_all = df\n",
    "    df_all.to_csv (path_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hpsearch)",
   "language": "python",
   "name": "hpsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
