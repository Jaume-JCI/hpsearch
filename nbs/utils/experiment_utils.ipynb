{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp utils.experiment_utils\n",
    "from nbdev.showdoc import *\n",
    "from dsblocks.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])\n",
    "#tst = TestRunner (targets=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment Utils\n",
    "\n",
    "> Helper functions for querying and retrieving results from past experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import pytest\n",
    "import pandas as pd\n",
    "from dsblocks.utils.nbdev_utils import md\n",
    "from hpsearch.examples.dummy_experiment_manager import (DummyExperimentManager, \n",
    "                                                        run_multiple_experiments)\n",
    "from hpsearch.examples.complex_dummy_experiment_manager import generate_data, init_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.utils.test_experiment_utils\n",
    "def generate_data_exp_utils (name_folder):\n",
    "    path_experiments = f'test_{name_folder}'\n",
    "    manager_path = f'{path_experiments}/managers'\n",
    "    em = DummyExperimentManager (path_experiments=path_experiments, manager_path=manager_path,\n",
    "                                 verbose=0)\n",
    "    em.remove_previous_experiments ()\n",
    "    run_multiple_experiments(em=em, nruns=5, noise=0.1, verbose=False,\n",
    "                             values_to_explore=dict(offset=[0.1, 0.3, 0.6], epochs=[5, 10, 100]))\n",
    "    run_multiple_experiments(em=em, nruns=5, noise=0.1, verbose=False, rate=0.0001,\n",
    "                             values_to_explore=dict(offset=[0.1, 0.3, 0.6], epochs=[5, 10, 100]))\n",
    "    return em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_experiment_data (path_experiments=None, folder_experiments=None, experiments=None):\n",
    "    \"\"\"\n",
    "    Returns data stored from previous experiments in the form DataFrame. \n",
    "    \n",
    "    If path_experiments is not given, it uses the default one. \n",
    "    \"\"\"\n",
    "    from hpsearch.config.hpconfig import get_experiment_data\n",
    "    return get_experiment_data (path_experiments=path_experiments, folder_experiments=folder_experiments,\n",
    "                                experiments=experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_experiment_data ():\n",
    "    path_experiments = 'test_get_experiment_data'\n",
    "    em = generate_data (path_experiments)\n",
    "    \n",
    "    df = get_experiment_data ()\n",
    "    reference = em.get_experiment_data ()\n",
    "    pd.testing.assert_frame_equal (df, reference)\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_experiment_data\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_get_experiment_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get experiment parameters and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_parameters_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_parameters_columns (experiment_data, only_not_null=False):\n",
    "    parameters =  [par for par in experiment_data.columns if not par[0].isdigit() and (par.find('time_')<0) and (par.find('date')<0)]\n",
    "    if only_not_null:\n",
    "        parameters = np.array(parameters)[~experiment_data.loc[:,parameters].isnull().all(axis=0)].tolist()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_experiment_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_experiment_parameters (experiment_data, only_not_null=False):\n",
    "    return experiment_data[get_parameters_columns (experiment_data, only_not_null=only_not_null)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_scores_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_scores_columns (experiment_data=None, suffix_results='', class_ids = None):\n",
    "    \"\"\"\n",
    "    Determine the columnns that provide evaluation scores. \n",
    "    \n",
    "    We assume that they start with the class number, and that the other columns \n",
    "    do not start with a digit.\n",
    "    \"\"\"\n",
    "    if class_ids is not None:\n",
    "        scores_columns = ['%d%s' %(col,suffix_results) for col in class_ids]\n",
    "    else:\n",
    "        if experiment_data is None:\n",
    "            raise ValueError ('Either experiment_data or class_ids should be different than None')\n",
    "        scores_columns = [col for col in experiment_data.columns if col[0].isdigit()]\n",
    "        # For some experiments, we have multiple scores per class (e.g., due to different evaluation criteria). The argument suffix_results can be used to select the appropriate score.\n",
    "        if len(suffix_results) > 0:\n",
    "            scores_columns = [col for col in scores_columns if (len(col.split(suffix_results))==2) and (len(col.split(suffix_results)[1])==0) and (col.split(suffix_results)[0].isdigit()) ]\n",
    "        else:\n",
    "            # We assume that default scores are in columns whose names only have the class number \n",
    "            scores_columns = [col for col in scores_columns if (len(col.split('_'))>=1)]\n",
    "    return scores_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_experiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_experiment_scores (experiment_data = None, suffix_results = '', class_ids = None, remove_suffix=False):\n",
    "    df = experiment_data[get_scores_columns (experiment_data, suffix_results=suffix_results, class_ids=class_ids)]\n",
    "    if remove_suffix:\n",
    "        df.columns=[c.split('_')[0] for c in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_parameters_and_scores ():\n",
    "    path_experiments = 'test_get_parameters_and_scores'\n",
    "    em = generate_data (path_experiments)\n",
    "    df = em.get_experiment_data ()\n",
    "\n",
    "    # ************************************************************\n",
    "    # get_parameters_columns\n",
    "    # ************************************************************\n",
    "    assert get_parameters_columns (df) ==['epochs', 'offset', 'rate', 'noise']\n",
    "\n",
    "    offset = df.offset.values.copy()\n",
    "    md ('- We can take only those which have at least some value that is not None.')\n",
    "    df.loc[:, 'offset'] = None\n",
    "    assert get_parameters_columns (df, only_not_null=True)==['epochs', 'rate', 'noise']\n",
    "\n",
    "    md ('- If only some elements are None for a given parameter, we still include it.')\n",
    "    df.loc[:, 'offset'] = offset\n",
    "    df.loc[2, 'offset'] = None\n",
    "    assert get_parameters_columns (df, only_not_null=True)==['epochs', 'offset', 'rate', 'noise']\n",
    "    df.loc[:, 'offset'] = offset\n",
    "\n",
    "    # ************************************************************\n",
    "    # get_experiment_parameters\n",
    "    # ************************************************************\n",
    "    md ('- Same as get_parameters_columns, but returning dataframe of parameter values.')\n",
    "    result = get_experiment_parameters (df)\n",
    "    assert result.shape == (9, 4)\n",
    "    assert sorted(result.columns) == sorted(['epochs', 'offset', 'rate', 'noise'])\n",
    "\n",
    "    # ************************************************************\n",
    "    # get_scores_columns\n",
    "    # ************************************************************\n",
    "    md ('- Retrieve all columns that have scores, for all runs')\n",
    "    assert get_scores_columns (df) == ['0_validation_accuracy',\n",
    "     '0_test_accuracy',\n",
    "     '0_finished',\n",
    "     '1_validation_accuracy',\n",
    "     '1_test_accuracy',\n",
    "     '1_finished',\n",
    "     '2_validation_accuracy',\n",
    "     '2_test_accuracy',\n",
    "     '2_finished',\n",
    "     '3_validation_accuracy',\n",
    "     '3_test_accuracy',\n",
    "     '3_finished',\n",
    "     '4_validation_accuracy',\n",
    "     '4_test_accuracy',\n",
    "     '4_finished']\n",
    "\n",
    "    md ('- Retrieve all columns for given score name, for all runs')\n",
    "    assert get_scores_columns (df, suffix_results='_test_accuracy') == [\n",
    "         '0_test_accuracy',\n",
    "         '1_test_accuracy',\n",
    "         '2_test_accuracy',\n",
    "         '3_test_accuracy',\n",
    "         '4_test_accuracy']\n",
    "\n",
    "    md ('- Retrieve all columns for given score name, for given runs')\n",
    "    assert get_scores_columns (df, suffix_results='_test_accuracy', class_ids=[2, 4]) == [\n",
    "     '2_test_accuracy',\n",
    "     '4_test_accuracy']\n",
    "\n",
    "    # ************************************************************\n",
    "    # get_experiment_scores\n",
    "    # ************************************************************\n",
    "    md ('- Same, but returning dataframe with selected scores values:')\n",
    "    result = get_experiment_scores (df)\n",
    "    display (result)\n",
    "    assert result.shape==(9,15)\n",
    "\n",
    "    result = get_experiment_scores (df, suffix_results='_test_accuracy')\n",
    "    display (result)\n",
    "    assert result.shape==(9,5)\n",
    "\n",
    "    result = get_experiment_scores (df, suffix_results='_test_accuracy', class_ids=[2,4])\n",
    "    display (result)\n",
    "    assert result.shape==(9,2)\n",
    "\n",
    "    md ('- We can remove the metric name and only keep the run number in each column:')\n",
    "    result = get_experiment_scores (df, suffix_results='_test_accuracy', class_ids=[2,4], remove_suffix=True)\n",
    "    display (result)\n",
    "    assert result.shape==(9,2)\n",
    "    \n",
    "    # ************************************************************\n",
    "    # get_scores_columns, first usage example: we do not indicate the name of the score\n",
    "    # ************************************************************\n",
    "    assert get_scores_columns (df)==['0_validation_accuracy', '0_test_accuracy', '0_finished', \n",
    "                                     '1_validation_accuracy', '1_test_accuracy', '1_finished', \n",
    "                                     '2_validation_accuracy', '2_test_accuracy', '2_finished', \n",
    "                                     '3_validation_accuracy', '3_test_accuracy', '3_finished', \n",
    "                                     '4_validation_accuracy', '4_test_accuracy', '4_finished']\n",
    "    \n",
    "    # ************************************************************\n",
    "    # get_scores_columns, second usage: we indicate the name of the score\n",
    "    # ************************************************************\n",
    "    result = get_scores_columns (df, class_ids=range(5), suffix_results='_validation_accuracy')\n",
    "    assert result == ['0_validation_accuracy', '1_validation_accuracy', '2_validation_accuracy',\n",
    "                     '3_validation_accuracy', '4_validation_accuracy']\n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_parameters_and_scores\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- We can take only those which have at least some value that is not None."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- If only some elements are None for a given parameter, we still include it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Same as get_parameters_columns, but returning dataframe of parameter values."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Retrieve all columns that have scores, for all runs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Retrieve all columns for given score name, for all runs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Retrieve all columns for given score name, for given runs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Same, but returning dataframe with selected scores values:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>1_finished</th>\n",
       "      <th>2_validation_accuracy</th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>2_finished</th>\n",
       "      <th>3_validation_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>3_finished</th>\n",
       "      <th>4_validation_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "      <th>4_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203053</td>\n",
       "      <td>0.404256</td>\n",
       "      <td>True</td>\n",
       "      <td>0.159198</td>\n",
       "      <td>0.208770</td>\n",
       "      <td>True</td>\n",
       "      <td>0.189936</td>\n",
       "      <td>0.320831</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117181</td>\n",
       "      <td>0.369686</td>\n",
       "      <td>True</td>\n",
       "      <td>0.284362</td>\n",
       "      <td>0.173696</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483126</td>\n",
       "      <td>0.647555</td>\n",
       "      <td>True</td>\n",
       "      <td>0.486164</td>\n",
       "      <td>0.485488</td>\n",
       "      <td>True</td>\n",
       "      <td>0.459176</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>True</td>\n",
       "      <td>0.397024</td>\n",
       "      <td>0.601327</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>0.526541</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775755</td>\n",
       "      <td>0.842555</td>\n",
       "      <td>True</td>\n",
       "      <td>0.864282</td>\n",
       "      <td>0.925193</td>\n",
       "      <td>True</td>\n",
       "      <td>0.759965</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>True</td>\n",
       "      <td>0.831352</td>\n",
       "      <td>0.726914</td>\n",
       "      <td>True</td>\n",
       "      <td>0.802194</td>\n",
       "      <td>0.879698</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523534</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>True</td>\n",
       "      <td>0.601505</td>\n",
       "      <td>0.835273</td>\n",
       "      <td>True</td>\n",
       "      <td>0.483821</td>\n",
       "      <td>0.535243</td>\n",
       "      <td>True</td>\n",
       "      <td>0.505996</td>\n",
       "      <td>0.463074</td>\n",
       "      <td>True</td>\n",
       "      <td>0.631286</td>\n",
       "      <td>0.512963</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.712835</td>\n",
       "      <td>True</td>\n",
       "      <td>0.782272</td>\n",
       "      <td>0.567277</td>\n",
       "      <td>True</td>\n",
       "      <td>0.845042</td>\n",
       "      <td>0.592310</td>\n",
       "      <td>True</td>\n",
       "      <td>0.867930</td>\n",
       "      <td>0.656752</td>\n",
       "      <td>True</td>\n",
       "      <td>0.698613</td>\n",
       "      <td>0.544079</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866905</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892311</td>\n",
       "      <td>True</td>\n",
       "      <td>0.862921</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987730</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.419808</td>\n",
       "      <td>0.285564</td>\n",
       "      <td>True</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.294305</td>\n",
       "      <td>True</td>\n",
       "      <td>0.392557</td>\n",
       "      <td>0.362067</td>\n",
       "      <td>True</td>\n",
       "      <td>0.498432</td>\n",
       "      <td>0.278601</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520651</td>\n",
       "      <td>0.218306</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656977</td>\n",
       "      <td>0.544771</td>\n",
       "      <td>True</td>\n",
       "      <td>0.567965</td>\n",
       "      <td>0.542417</td>\n",
       "      <td>True</td>\n",
       "      <td>0.750076</td>\n",
       "      <td>0.585022</td>\n",
       "      <td>True</td>\n",
       "      <td>0.659740</td>\n",
       "      <td>0.570117</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622391</td>\n",
       "      <td>0.636414</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.829499</td>\n",
       "      <td>0.794423</td>\n",
       "      <td>True</td>\n",
       "      <td>0.839049</td>\n",
       "      <td>0.781303</td>\n",
       "      <td>True</td>\n",
       "      <td>0.839438</td>\n",
       "      <td>0.982601</td>\n",
       "      <td>True</td>\n",
       "      <td>0.949097</td>\n",
       "      <td>0.873488</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859253</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_validation_accuracy  0_test_accuracy 0_finished  1_validation_accuracy  \\\n",
       "0               0.203053         0.404256       True               0.159198   \n",
       "1               0.483126         0.647555       True               0.486164   \n",
       "2               0.775755         0.842555       True               0.864282   \n",
       "3               0.523534         0.722017       True               0.601505   \n",
       "4               0.812412         0.712835       True               0.782272   \n",
       "5               1.000000         1.000000       True               1.000000   \n",
       "6               0.419808         0.285564       True               0.363639   \n",
       "7               0.656977         0.544771       True               0.567965   \n",
       "8               0.829499         0.794423       True               0.839049   \n",
       "\n",
       "   1_test_accuracy 1_finished  2_validation_accuracy  2_test_accuracy  \\\n",
       "0         0.208770       True               0.189936         0.320831   \n",
       "1         0.485488       True               0.459176         0.351243   \n",
       "2         0.925193       True               0.759965         0.799652   \n",
       "3         0.835273       True               0.483821         0.535243   \n",
       "4         0.567277       True               0.845042         0.592310   \n",
       "5         0.866905       True               1.000000         0.892311   \n",
       "6         0.294305       True               0.392557         0.362067   \n",
       "7         0.542417       True               0.750076         0.585022   \n",
       "8         0.781303       True               0.839438         0.982601   \n",
       "\n",
       "  2_finished  3_validation_accuracy  3_test_accuracy 3_finished  \\\n",
       "0       True               0.117181         0.369686       True   \n",
       "1       True               0.397024         0.601327       True   \n",
       "2       True               0.831352         0.726914       True   \n",
       "3       True               0.505996         0.463074       True   \n",
       "4       True               0.867930         0.656752       True   \n",
       "5       True               0.862921         0.914849       True   \n",
       "6       True               0.498432         0.278601       True   \n",
       "7       True               0.659740         0.570117       True   \n",
       "8       True               0.949097         0.873488       True   \n",
       "\n",
       "   4_validation_accuracy  4_test_accuracy 4_finished  \n",
       "0               0.284362         0.173696       True  \n",
       "1               0.450511         0.526541       True  \n",
       "2               0.802194         0.879698       True  \n",
       "3               0.631286         0.512963       True  \n",
       "4               0.698613         0.544079       True  \n",
       "5               1.000000         0.987730       True  \n",
       "6               0.520651         0.218306       True  \n",
       "7               0.622391         0.636414       True  \n",
       "8               1.000000         0.859253       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>3_test_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404256</td>\n",
       "      <td>0.208770</td>\n",
       "      <td>0.320831</td>\n",
       "      <td>0.369686</td>\n",
       "      <td>0.173696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647555</td>\n",
       "      <td>0.485488</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.601327</td>\n",
       "      <td>0.526541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.842555</td>\n",
       "      <td>0.925193</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>0.726914</td>\n",
       "      <td>0.879698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.835273</td>\n",
       "      <td>0.535243</td>\n",
       "      <td>0.463074</td>\n",
       "      <td>0.512963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712835</td>\n",
       "      <td>0.567277</td>\n",
       "      <td>0.592310</td>\n",
       "      <td>0.656752</td>\n",
       "      <td>0.544079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866905</td>\n",
       "      <td>0.892311</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.987730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.285564</td>\n",
       "      <td>0.294305</td>\n",
       "      <td>0.362067</td>\n",
       "      <td>0.278601</td>\n",
       "      <td>0.218306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.544771</td>\n",
       "      <td>0.542417</td>\n",
       "      <td>0.585022</td>\n",
       "      <td>0.570117</td>\n",
       "      <td>0.636414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.794423</td>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.982601</td>\n",
       "      <td>0.873488</td>\n",
       "      <td>0.859253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_test_accuracy  1_test_accuracy  2_test_accuracy  3_test_accuracy  \\\n",
       "0         0.404256         0.208770         0.320831         0.369686   \n",
       "1         0.647555         0.485488         0.351243         0.601327   \n",
       "2         0.842555         0.925193         0.799652         0.726914   \n",
       "3         0.722017         0.835273         0.535243         0.463074   \n",
       "4         0.712835         0.567277         0.592310         0.656752   \n",
       "5         1.000000         0.866905         0.892311         0.914849   \n",
       "6         0.285564         0.294305         0.362067         0.278601   \n",
       "7         0.544771         0.542417         0.585022         0.570117   \n",
       "8         0.794423         0.781303         0.982601         0.873488   \n",
       "\n",
       "   4_test_accuracy  \n",
       "0         0.173696  \n",
       "1         0.526541  \n",
       "2         0.879698  \n",
       "3         0.512963  \n",
       "4         0.544079  \n",
       "5         0.987730  \n",
       "6         0.218306  \n",
       "7         0.636414  \n",
       "8         0.859253  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>4_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320831</td>\n",
       "      <td>0.173696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.526541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799652</td>\n",
       "      <td>0.879698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535243</td>\n",
       "      <td>0.512963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592310</td>\n",
       "      <td>0.544079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.892311</td>\n",
       "      <td>0.987730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.362067</td>\n",
       "      <td>0.218306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.585022</td>\n",
       "      <td>0.636414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.982601</td>\n",
       "      <td>0.859253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2_test_accuracy  4_test_accuracy\n",
       "0         0.320831         0.173696\n",
       "1         0.351243         0.526541\n",
       "2         0.799652         0.879698\n",
       "3         0.535243         0.512963\n",
       "4         0.592310         0.544079\n",
       "5         0.892311         0.987730\n",
       "6         0.362067         0.218306\n",
       "7         0.585022         0.636414\n",
       "8         0.982601         0.859253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- We can remove the metric name and only keep the run number in each column:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320831</td>\n",
       "      <td>0.173696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.526541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799652</td>\n",
       "      <td>0.879698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535243</td>\n",
       "      <td>0.512963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592310</td>\n",
       "      <td>0.544079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.892311</td>\n",
       "      <td>0.987730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.362067</td>\n",
       "      <td>0.218306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.585022</td>\n",
       "      <td>0.636414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.982601</td>\n",
       "      <td>0.859253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2         4\n",
       "0  0.320831  0.173696\n",
       "1  0.351243  0.526541\n",
       "2  0.799652  0.879698\n",
       "3  0.535243  0.512963\n",
       "4  0.592310  0.544079\n",
       "5  0.892311  0.987730\n",
       "6  0.362067  0.218306\n",
       "7  0.585022  0.636414\n",
       "8  0.982601  0.859253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_get_parameters_and_scores, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get_scores_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_scores_names (experiment_data=None, run_number=None, experiment=None, only_valid=True):\n",
    "    \"\"\" \n",
    "    Determine the names of the scores included in experiment data. \n",
    "    \n",
    "    We assume that the score columns start with the class number, and that the other columns do not start with a digit.\n",
    "\n",
    "    If run_number is provided, we provide the scores stored for that run number. If, in addition to this, \n",
    "    experiment is provided, and only_valid=True, we provide only the scores that are not NaN for the given \n",
    "    experiment number.\n",
    "    \"\"\"\n",
    "    \n",
    "    if run_number is None:\n",
    "        scores_names = np.unique([('_'.join(col.split('_')[1:]) if (len(col.split('_')) > 1) else '') \n",
    "                                    for col in experiment_data.columns if col[0].isdigit()])\n",
    "        \n",
    "    else:\n",
    "        scores_names = [col.split(f'{run_number}')[1] for col in experiment_data.columns if col.startswith(str(run_number))]\n",
    "        scores_names = [('_'.join(col.split('_')[1:]) if (len(col.split('_')) > 1) else '')\n",
    "                                    for col in scores_names]\n",
    "        if (experiment is not None) and only_valid:\n",
    "            scores_names = [name for name in scores_names if not np.isnan(experiment_data.loc[experiment, f'{run_number}_{name}'])]\n",
    "        scores_names = list(np.sort(scores_names))\n",
    "    # remove special names\n",
    "    scores_names = [name for name in scores_names if name != 'finished']\n",
    "    return scores_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_scores_names ():\n",
    "    em = generate_data_exp_utils ('get_scores_names')\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    scores_names = get_scores_names (df)\n",
    "    print (scores_names)\n",
    "    assert scores_names == ['test_accuracy', 'validation_accuracy']\n",
    "    \n",
    "    scores_names=get_scores_names (df, run_number=3, experiment=7)\n",
    "    print(scores_names)\n",
    "    assert list(np.sort(scores_names))==['test_accuracy', 'validation_accuracy']\n",
    "\n",
    "    # test when only some scores are valid\n",
    "    df2 = df.copy()\n",
    "    df2.loc[7, '3_test_accuracy']=np.nan\n",
    "    scores_names=get_scores_names (df2, run_number=3, experiment=7)\n",
    "    print (scores_names)\n",
    "    assert scores_names==['validation_accuracy']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_scores_names\n",
      "['test_accuracy', 'validation_accuracy']\n",
      "['test_accuracy', 'validation_accuracy']\n",
      "['validation_accuracy']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_get_scores_names, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get_monitored_training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_monitored_training_metrics (experiment, run_number=0, history_file_name='model_history.pk', \n",
    "                                    path_results=None, root_path=None, root_folder=None):\n",
    "    if path_results is None:\n",
    "        from hpsearch.config.hpconfig import get_path_results\n",
    "        path_results = get_path_results(experiment, run_number, root_path=root_path, root_folder=root_folder)\n",
    "    path_history = f'{path_results}/{history_file_name}'\n",
    "    if os.path.exists(path_history):\n",
    "        history=pickle.load(open(path_history,'rb'))\n",
    "        return list(history.keys())\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_monitored_training_metrics ():\n",
    "    em = generate_data_exp_utils ('get_monitored_training_metrics')\n",
    "    \n",
    "    monitored_metrics = get_monitored_training_metrics (0)\n",
    "    print (monitored_metrics)\n",
    "    assert monitored_metrics==['validation_accuracy', 'test_accuracy', 'accuracy']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_monitored_training_metrics\n",
      "['validation_accuracy', 'test_accuracy', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_get_monitored_training_metrics, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get_classes_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_classes_with_results (experiment_data = None, suffix_results = '', class_ids = None):\n",
    "    \"\"\"\n",
    "    Gets the list of class_ids for whom there are results in experiment_data.\n",
    "    \"\"\"\n",
    "    assert experiment_data is not None, 'experiment_data must be introduced'\n",
    "    result_columns = get_scores_columns (experiment_data, suffix_results=suffix_results, class_ids=class_ids)\n",
    "    completed_results = ~experiment_data.loc[:,result_columns].isnull()\n",
    "    completed_results = completed_results.all(axis=0)\n",
    "    completed_results = completed_results.iloc[np.where(completed_results)]\n",
    "    completed_results = completed_results.index\n",
    "\n",
    "    return [int(x[:-len(suffix_results)]) for x in completed_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_classes_with_results ():\n",
    "    em = generate_data ('get_classes_with_results')\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    # we need to introduce experiment_data df, and suffix_results\n",
    "    result = get_classes_with_results (df, suffix_results='_validation_accuracy')\n",
    "    display (result)\n",
    "    assert result==[0,1,2,3,4]\n",
    "    \n",
    "    # we can also restrict to certain class_ids\n",
    "    result = get_classes_with_results (df, suffix_results='_validation_accuracy', class_ids=[0,2])\n",
    "    display (result)\n",
    "    assert result==[0,2]\n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_classes_with_results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_get_classes_with_results, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true"
   },
   "source": [
    "## get_parameters_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_parameters_unique(df):\n",
    "    parameters = []\n",
    "    for k in df.columns:\n",
    "        if len(df[k].unique()) > 1:\n",
    "            parameters += [k]\n",
    "    return parameters, df[parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_get_parameters_unique ():\n",
    "    em = generate_data_exp_utils ('get_parameters_unique')\n",
    "    df = em.get_experiment_data ()\n",
    "    \n",
    "    # keeps only those parameters with more than one value,\n",
    "    # removing 'noise' in this case, since it has the same value in all rows\n",
    "    result = get_parameters_unique (df[['epochs','offset','rate', 'noise']])\n",
    "    assert result[1].shape==(18,3)\n",
    "    assert result[0] == ['epochs', 'offset', 'rate']\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_get_parameters_unique\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_get_parameters_unique, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true",
    "tags": []
   },
   "source": [
    "## compact_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compact_parameters (df, number_characters=1):\n",
    "    par_or = df.columns\n",
    "    par_new = [''.join(y[0].upper()+y[1:number_characters] for y in x.split('_')) for x in par_or]\n",
    "    dict_rename = {k:v for k,v in zip(par_or, par_new)}\n",
    "    df = df.rename (columns = dict_rename)\n",
    "    \n",
    "    return df, dict_rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_compact_parameters ():\n",
    "    em = generate_data_exp_utils ('compact_parameters')\n",
    "    df = em.get_experiment_data ()\n",
    "    \n",
    "    result = compact_parameters (df, number_characters=2)\n",
    "    display (result[0].head())\n",
    "    assert all(result[0].columns == ['Ep', 'Of', 'Ra', 'No', '0VaAc', '0TeAc', 'Ti0', 'Da', '0Fi', '1VaAc',\n",
    "           '1TeAc', 'Ti1', '1Fi', '2VaAc', '2TeAc', 'Ti2', '2Fi', '3VaAc', '3TeAc',\n",
    "           'Ti3', '3Fi', '4VaAc', '4TeAc', 'Ti4', '4Fi'])\n",
    "\n",
    "    assert result[1]=={'epochs': 'Ep',\n",
    "         'offset': 'Of',\n",
    "         'rate': 'Ra',\n",
    "         'noise': 'No',\n",
    "         '0_validation_accuracy': '0VaAc',\n",
    "         '0_test_accuracy': '0TeAc',\n",
    "         'time_0': 'Ti0',\n",
    "         'date': 'Da',\n",
    "         '0_finished': '0Fi',\n",
    "         '1_validation_accuracy': '1VaAc',\n",
    "         '1_test_accuracy': '1TeAc',\n",
    "         'time_1': 'Ti1',\n",
    "         '1_finished': '1Fi',\n",
    "         '2_validation_accuracy': '2VaAc',\n",
    "         '2_test_accuracy': '2TeAc',\n",
    "         'time_2': 'Ti2',\n",
    "         '2_finished': '2Fi',\n",
    "         '3_validation_accuracy': '3VaAc',\n",
    "         '3_test_accuracy': '3TeAc',\n",
    "         'time_3': 'Ti3',\n",
    "         '3_finished': '3Fi',\n",
    "         '4_validation_accuracy': '4VaAc',\n",
    "         '4_test_accuracy': '4TeAc',\n",
    "         'time_4': 'Ti4',\n",
    "         '4_finished': '4Fi'}\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_compact_parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ep</th>\n",
       "      <th>Of</th>\n",
       "      <th>Ra</th>\n",
       "      <th>No</th>\n",
       "      <th>0VaAc</th>\n",
       "      <th>0TeAc</th>\n",
       "      <th>Ti0</th>\n",
       "      <th>Da</th>\n",
       "      <th>0Fi</th>\n",
       "      <th>1VaAc</th>\n",
       "      <th>...</th>\n",
       "      <th>Ti2</th>\n",
       "      <th>2Fi</th>\n",
       "      <th>3VaAc</th>\n",
       "      <th>3TeAc</th>\n",
       "      <th>Ti3</th>\n",
       "      <th>3Fi</th>\n",
       "      <th>4VaAc</th>\n",
       "      <th>4TeAc</th>\n",
       "      <th>Ti4</th>\n",
       "      <th>4Fi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.345908</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>15:54:30.168643</td>\n",
       "      <td>True</td>\n",
       "      <td>0.195008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>True</td>\n",
       "      <td>0.247587</td>\n",
       "      <td>0.401060</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>True</td>\n",
       "      <td>0.171343</td>\n",
       "      <td>0.383237</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.363557</td>\n",
       "      <td>0.708952</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>15:54:30.331643</td>\n",
       "      <td>True</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>True</td>\n",
       "      <td>0.507114</td>\n",
       "      <td>0.477651</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>True</td>\n",
       "      <td>0.272012</td>\n",
       "      <td>0.656417</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.689966</td>\n",
       "      <td>0.909354</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>15:54:30.504931</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>True</td>\n",
       "      <td>0.783208</td>\n",
       "      <td>0.914613</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>True</td>\n",
       "      <td>0.706492</td>\n",
       "      <td>0.818832</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.444584</td>\n",
       "      <td>0.127774</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>15:54:30.687728</td>\n",
       "      <td>True</td>\n",
       "      <td>0.330040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>True</td>\n",
       "      <td>0.464690</td>\n",
       "      <td>0.231556</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>True</td>\n",
       "      <td>0.424691</td>\n",
       "      <td>0.187480</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.638497</td>\n",
       "      <td>0.579857</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>15:54:30.890817</td>\n",
       "      <td>True</td>\n",
       "      <td>0.803721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641315</td>\n",
       "      <td>0.476679</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>True</td>\n",
       "      <td>0.404541</td>\n",
       "      <td>0.468960</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ep   Of    Ra   No     0VaAc     0TeAc       Ti0               Da   0Fi  \\\n",
       "0  5.0  0.1  0.03  0.1  0.187291  0.345908  0.000287  15:54:30.168643  True   \n",
       "1  5.0  0.3  0.03  0.1  0.363557  0.708952  0.000270  15:54:30.331643  True   \n",
       "2  5.0  0.6  0.03  0.1  0.689966  0.909354  0.000295  15:54:30.504931  True   \n",
       "3  NaN  0.1  0.03  0.1  0.444584  0.127774  0.000306  15:54:30.687728  True   \n",
       "4  NaN  0.3  0.03  0.1  0.638497  0.579857  0.000299  15:54:30.890817  True   \n",
       "\n",
       "      1VaAc  ...       Ti2   2Fi     3VaAc     3TeAc       Ti3   3Fi  \\\n",
       "0  0.195008  ...  0.000288  True  0.247587  0.401060  0.000281  True   \n",
       "1  0.329114  ...  0.000270  True  0.507114  0.477651  0.000274  True   \n",
       "2  0.686573  ...  0.000289  True  0.783208  0.914613  0.000306  True   \n",
       "3  0.330040  ...  0.000306  True  0.464690  0.231556  0.000312  True   \n",
       "4  0.803721  ...  0.000333  True  0.641315  0.476679  0.000329  True   \n",
       "\n",
       "      4VaAc     4TeAc       Ti4   4Fi  \n",
       "0  0.171343  0.383237  0.000295  True  \n",
       "1  0.272012  0.656417  0.000276  True  \n",
       "2  0.706492  0.818832  0.000283  True  \n",
       "3  0.424691  0.187480  0.000306  True  \n",
       "4  0.404541  0.468960  0.000318  True  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_compact_parameters, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## replace_with_default_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replace_with_default_values (df, parameters={}):\n",
    "    from hpsearch.config.hpconfig import get_default_parameters\n",
    "    \n",
    "    parameters_names = get_parameters_columns (df)\n",
    "    \n",
    "    for k in df.columns:\n",
    "        experiments_idx=np.argwhere(df[k].isna().ravel()).ravel()\n",
    "        experiments=df.index[experiments_idx]\n",
    "        for experiment in experiments:\n",
    "            parameters = df.loc[experiment, parameters_names].copy()\n",
    "            parameters[parameters.isna().values] = None\n",
    "            parameters = parameters.to_dict()\n",
    "            parameters = {k:parameters[k] for k in parameters if parameters[k] is not None}\n",
    "            defaults = get_default_parameters(parameters)\n",
    "            df.loc[experiment, k] = defaults.get(k)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_replace_with_default_values ():\n",
    "    em = generate_data_exp_utils ('replace_with_default_values')\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    df=replace_with_default_values(df)\n",
    "    assert (df.epochs.values == ([5.]*3 + [10.]*3 + [100.]*3)*2).all()\n",
    "    \n",
    "    em.remove_previous_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_replace_with_default_values\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_replace_with_default_values, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_defaults (parameters):\n",
    "    from hpsearch.config.hpconfig import get_default_parameters\n",
    "    \n",
    "    defaults = get_default_parameters(parameters)\n",
    "    for key in defaults.keys():\n",
    "        if key in parameters.keys() and (parameters[key] == defaults[key]):\n",
    "            del parameters[key]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_remove_defaults ():\n",
    "    em = init_em ('remove_defaults')\n",
    "    result, dict_results = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05})\n",
    "    \n",
    "    parameters = remove_defaults ({'offset':0.1, 'rate': 0.05})\n",
    "    assert parameters=={'offset':0.1, 'rate': 0.05}\n",
    "    \n",
    "    parameters = remove_defaults ({'offset':0.1, 'rate': 0.01, 'epochs': 10})\n",
    "    assert parameters=={'offset':0.1}\n",
    "    \n",
    "    parameters = remove_defaults ({'offset':0.5, 'rate': 0.000001, 'epochs': 10})\n",
    "    assert parameters=={'rate': 0.000001, 'epochs': 10}\n",
    "    \n",
    "    parameters = remove_defaults ({'offset':0.5, 'rate': 0.000001, 'epochs': 100})\n",
    "    assert parameters=={'rate': 0.000001}\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_remove_defaults\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.15000000000000002\n",
      "epoch 1: accuracy: 0.2\n",
      "epoch 2: accuracy: 0.25\n",
      "epoch 3: accuracy: 0.3\n",
      "epoch 4: accuracy: 0.35\n",
      "epoch 5: accuracy: 0.39999999999999997\n",
      "epoch 6: accuracy: 0.44999999999999996\n",
      "epoch 7: accuracy: 0.49999999999999994\n",
      "epoch 8: accuracy: 0.5499999999999999\n",
      "epoch 9: accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_remove_defaults, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true"
   },
   "source": [
    "## find_rows_with_parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_rows_with_parameters_dict (experiment_data, parameters_dict, create_if_not_exists=True, \n",
    "                                    exact_match=True, ignore_keys=[], precision = 1e-10):\n",
    "    \"\"\" Finds rows that match parameters. If the dataframe doesn't have any parameter with that name, a new column is created and changed_dataframe is set to True.\"\"\"\n",
    "    changed_dataframe = False\n",
    "    matching_all_condition = pd.Series([True]*experiment_data.shape[0])\n",
    "    existing_keys = [par for par in parameters_dict.keys() if par not in ignore_keys]\n",
    "    for parameter in existing_keys:\n",
    "        if parameter not in experiment_data.columns:\n",
    "            if create_if_not_exists:\n",
    "                experiment_data[parameter] = None\n",
    "                changed_dataframe = True\n",
    "            else:\n",
    "                raise ValueError ('parameter %s not found in experiment_data' %parameter)\n",
    "        if parameters_dict[parameter] is None:\n",
    "            matching_condition = experiment_data[parameter].isnull()\n",
    "        elif experiment_data[parameter].isnull().all():\n",
    "            matching_condition = ~experiment_data[parameter].isnull()\n",
    "        elif (type(parameters_dict[parameter]) == float) or (type(parameters_dict[parameter]) == np.float32) or (type(parameters_dict[parameter]) == np.float64):\n",
    "            if parameters_dict[parameter] == np.floor(parameters_dict[parameter]):\n",
    "                matching_condition = experiment_data[parameter]==parameters_dict[parameter]\n",
    "            else:\n",
    "                matching_condition = experiment_data[parameter]==parameters_dict[parameter]\n",
    "                for idx, v in enumerate(experiment_data[parameter]):\n",
    "                    if (type(v) == float or type(v) == np.float32 or type(v) == np.float64) and (np.abs(v-parameters_dict[parameter]) < precision):\n",
    "                        matching_condition.iloc[idx]=True\n",
    "                    else:\n",
    "                        matching_condition.iloc[idx]=False\n",
    "        else:\n",
    "            matching_condition = experiment_data[parameter]==parameters_dict[parameter]\n",
    "\n",
    "        matching_all_condition = matching_all_condition & matching_condition.values\n",
    "            \n",
    "    # We assume that all the columns correspond to parameters, except for those that start with a digit (corresponding to the class evaluated) and those that start with time (giving an estimation of the computational cost)\n",
    "    if exact_match:\n",
    "        rest_parameters = get_parameters_columns (experiment_data)\n",
    "        rest_parameters = [par for par in rest_parameters if par not in parameters_dict.keys()]\n",
    "        rest_parameters = [par for par in rest_parameters if par not in ignore_keys]\n",
    "        for parameter in rest_parameters:\n",
    "            matching_condition = experiment_data[parameter].isnull()\n",
    "            matching_all_condition = matching_all_condition & matching_condition.values\n",
    "    \n",
    "    matching_rows = matching_all_condition.index[matching_all_condition].tolist()\n",
    "    \n",
    "    return matching_rows, changed_dataframe, matching_all_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_find_rows_with_parameters_dict ():\n",
    "    em = generate_data_exp_utils ('find_rows_with_parameters_dict')\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    result = find_rows_with_parameters_dict (df, dict (rate=0.0001))\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert matching_rows==[]\n",
    "    assert not changed_dataframe\n",
    "    \n",
    "    result = find_rows_with_parameters_dict (df, dict (rate=0.0001), exact_match=False)\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert matching_rows == [9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "    \n",
    "    result = find_rows_with_parameters_dict (df, dict (rate=0.0001, epochs=5, offset=0.6), exact_match=False,\n",
    "                                        ignore_keys=['epochs'])\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert matching_rows==[11, 14, 17]\n",
    "\n",
    "    df.loc[16, 'rate']=0.00011\n",
    "    result = find_rows_with_parameters_dict (df, dict (rate=0.0001), exact_match=False)\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert matching_rows==[9, 10, 11, 12, 13, 14, 15, 17]\n",
    "\n",
    "    result = find_rows_with_parameters_dict (df, dict (rate=0.0001), exact_match=False, precision = 0.0001)\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert matching_rows==[9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "    result = find_rows_with_parameters_dict (df, dict (new_par=4), exact_match=False)\n",
    "    matching_rows, changed_dataframe, matching_all_condition = result\n",
    "    assert changed_dataframe\n",
    "    assert df.shape == (18, 26)\n",
    "    assert matching_rows==[]\n",
    "    assert 'new_par' in df.columns\n",
    "    assert matching_rows==[]\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_find_rows_with_parameters_dict\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_find_rows_with_parameters_dict, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarize_results(path_experiments = None, \n",
    "                      folder_experiments = None,\n",
    "                      intersection = False, \n",
    "                      experiments = None, \n",
    "                      suffix_results='', \n",
    "                      min_results=0, \n",
    "                      class_ids = None, \n",
    "                      parameters = None,\n",
    "                      output='all',\n",
    "                      data = None,\n",
    "                      ascending=False,\n",
    "                      suffix_test_set = None,\n",
    "                      stats = ['mean','median','rank','min','max','std']):\n",
    "    \"\"\"Obtains summary scores for the desired list of experiments. Uses the experiment_data csv for \n",
    "    that purpose\n",
    "    \n",
    "    Example use: \n",
    "        - restricting class_ids:\n",
    "            summarize_results(class_ids= [1058,1059],suffix_results='_m3');\n",
    "    \n",
    "        - with a predetermined list of class_ids:\n",
    "            summarize_results(class_ids='qualified',suffix_results='_m3',min_results=96);\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if data is None:\n",
    "        experiment_data = get_experiment_data (path_experiments=path_experiments, folder_experiments=folder_experiments)\n",
    "        experiment_data_original = experiment_data.copy()\n",
    "        if experiments is not None:\n",
    "            experiment_data = experiment_data.loc[experiments,:]\n",
    "        if parameters is not None:\n",
    "            experiment_rows, _, _ = find_rows_with_parameters_dict (experiment_data, parameters, create_if_not_exists=False, exact_match=False)\n",
    "            experiment_data = experiment_data.loc[experiment_rows]\n",
    "    else:\n",
    "        experiment_data = data.copy()\n",
    "        experiment_data_original = experiment_data.copy()\n",
    "        \n",
    "    # Determine the columnns that provide evaluation scores. \n",
    "    result_columns = get_scores_columns (experiment_data, suffix_results=suffix_results, class_ids=class_ids)\n",
    "    \n",
    "    experiment_data.loc[:,'num_results'] = np.sum(~experiment_data.loc[:,result_columns].isnull(),axis=1)\n",
    "    if min_results > 0:\n",
    "        number_before = experiment_data.shape[0]\n",
    "        experiment_data = experiment_data[experiment_data.num_results>=min_results]\n",
    "        print (f'{experiment_data.shape[0]} out of {number_before} experiments have {min_results} runs completed')\n",
    "    \n",
    "    # Take only those class_ids where all experiments provide some score\n",
    "    if intersection:\n",
    "        number_before = len(result_columns)\n",
    "        all_have_results = ~experiment_data.loc[:,result_columns].isnull().any(axis=0)\n",
    "        result_columns = (np.array(result_columns)[all_have_results]).tolist()\n",
    "        print (f'{len(result_columns)} out of {number_before} runs for whom all the selected experiments have completed')\n",
    "        \n",
    "    print (f'total data examined: {experiment_data.shape[0]} experiments with at least {experiment_data[\"num_results\"].min()} runs done for each one')\n",
    "        \n",
    "    scores = -experiment_data.loc[:,result_columns].values\n",
    "    rank = np.argsort(scores,axis=0)\n",
    "    rank = np.argsort(rank,axis=0).astype(np.float32)\n",
    "    rank[experiment_data.loc[:,result_columns].isnull()]=np.nan\n",
    "    \n",
    "    parameters = get_parameters_columns(experiment_data, True)\n",
    "    experiment_data.loc[:,'mean'] = experiment_data.loc[:,result_columns].mean(axis=1)\n",
    "    experiment_data.loc[:,'min'] = experiment_data.loc[:,result_columns].min(axis=1)\n",
    "    experiment_data.loc[:,'max'] = experiment_data.loc[:,result_columns].max(axis=1)\n",
    "    experiment_data.loc[:,'std'] = experiment_data.loc[:,result_columns].std(axis=1)\n",
    "    experiment_data.loc[:,'median'] = experiment_data.loc[:,result_columns].median(axis=1)\n",
    "    experiment_data.loc[:,'rank'] = np.nanmean(rank,axis=1)\n",
    "    experiment_data.loc[:,'good'] = (experiment_data.loc[:,result_columns]>=0.1666666).sum(axis=1)\n",
    "    \n",
    "    scores_to_return = dict(mean=['mean'], median=['median'], rank=['rank'], good=['good'])\n",
    "    if suffix_test_set is not None:\n",
    "        def add_score_to_return (suffix_test_set_i):\n",
    "            result_columns_test_set = get_scores_columns (experiment_data, suffix_results=suffix_test_set_i, class_ids=class_ids)\n",
    "            experiment_data.loc[:,'mean%s' %suffix_test_set_i] = experiment_data.loc[:,result_columns_test_set].mean(axis=1)\n",
    "            experiment_data.loc[:,'median%s' %suffix_test_set_i] = experiment_data.loc[:,result_columns_test_set].median(axis=1)\n",
    "            scores_test_set = -experiment_data.loc[:,result_columns_test_set].values\n",
    "            rank_test_set = np.argsort(scores_test_set,axis=0)\n",
    "            rank_test_set = np.argsort(rank_test_set,axis=0).astype(np.float32)\n",
    "            rank_test_set[experiment_data.loc[:,result_columns].isnull()]=np.nan\n",
    "            experiment_data.loc[:,'rank%s' %suffix_test_set_i] = np.nanmean(rank_test_set,axis=1)\n",
    "            experiment_data.loc[:,'good%s' %suffix_test_set_i] = (experiment_data.loc[:,result_columns_test_set]>=0.1666666).sum(axis=1)\n",
    "            for k in scores_to_return.keys():\n",
    "                scores_to_return[k] += ['%s%s' %(k, suffix_test_set_i)]\n",
    "        if type(suffix_test_set) == str:\n",
    "            suffix_test_set = [suffix_test_set]\n",
    "        for suffix_test_set_i in suffix_test_set:\n",
    "            add_score_to_return(suffix_test_set_i)\n",
    "        \n",
    "    if output == 'all':\n",
    "        summary = dict (mean = experiment_data.loc[:,parameters+scores_to_return['mean']].sort_values(by='mean',ascending=ascending),\n",
    "                        median = experiment_data.loc[:,parameters+scores_to_return['median']].sort_values(by='median',ascending=ascending),\n",
    "                        rank = experiment_data.loc[:,parameters+scores_to_return['rank']].sort_values(by='rank'),\n",
    "                        good = experiment_data.loc[:,parameters+scores_to_return['good']].sort_values(by='good',ascending=False),\n",
    "                        stats = experiment_data.loc[:,parameters+stats].sort_values(by='mean',ascending=ascending),\n",
    "                        unordered = experiment_data.loc[:,parameters],\n",
    "                        allcols = experiment_data,\n",
    "                        original = experiment_data_original\n",
    "                        )\n",
    "    elif output == 'stats':\n",
    "        summary = experiment_data.loc[:,parameters+['mean','median','rank']]\n",
    "    elif output == 'unordered':\n",
    "        summary = experiment_data.loc[:,parameters]\n",
    "    elif output == 'allcols':\n",
    "        summary = experiment_data\n",
    "    elif output == 'original':\n",
    "        summary = experiment_data_original\n",
    "    else:\n",
    "        summary = experiment_data.loc[:,parameters+[output]].sort_values(by=output, ascending=output=='rank')\n",
    "        \n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_summarize_results ():\n",
    "    em = init_em ('summarize_results')\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.1, rate=0.01), nruns=3)\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.2, rate=0.001), nruns=5)\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.3, rate=0.02), nruns=2)\n",
    "    \n",
    "    md ('\\n\\n')\n",
    "    md ('- We need to indicate the metric to be retrieved, otherwise it will count '\n",
    "        'as many results as num_results*num_metrics: ')\n",
    "    d = summarize_results ()\n",
    "    display (d['mean'])\n",
    "    assert d['mean'].num_results.sum() == 30\n",
    "    assert d['mean'].shape[0]==3\n",
    "    \n",
    "    md ('\\n\\n')\n",
    "    md ('- The metric is indicated with `_` at the beginning: ')\n",
    "    d = summarize_results (suffix_results='_validation_accuracy')\n",
    "    display (d['mean'])\n",
    "    assert d['mean'].num_results.sum() == 10\n",
    "    assert d['mean'].shape[0]==3\n",
    "    \n",
    "    md ('\\n\\n')\n",
    "    md ('- We can filter those results that have less than X runs: ')\n",
    "    d = summarize_results (suffix_results='_validation_accuracy', min_results=5)\n",
    "    display (d['mean'])\n",
    "    assert d['mean'].num_results.sum() == 5\n",
    "    assert d['mean'].shape[0]==1\n",
    "    \n",
    "    md ('\\n\\n')\n",
    "    md ('- We can filter by experiment number and/or number of results, and retrieve the original dataframe,'\n",
    "        'plus new columns with stats: ')\n",
    "    d = summarize_results (suffix_results='_validation_accuracy', experiments=[0,2], output='allcols')\n",
    "    display (d)\n",
    "    assert d.shape[0]==2\n",
    "    assert all(d.index==[0,2])\n",
    "    assert {'mean', 'min', 'max', 'std', 'median'}.issubset(d.columns)\n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "lines_to_next_cell": 1,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_summarize_results\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.32\n",
      "epoch 1: accuracy: 0.34\n",
      "epoch 2: accuracy: 0.36000000000000004\n",
      "epoch 3: accuracy: 0.38000000000000006\n",
      "epoch 4: accuracy: 0.4000000000000001\n",
      "epoch 5: accuracy: 0.4200000000000001\n",
      "epoch 6: accuracy: 0.4400000000000001\n",
      "epoch 7: accuracy: 0.46000000000000013\n",
      "epoch 8: accuracy: 0.48000000000000015\n",
      "epoch 9: accuracy: 0.5000000000000001\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.32\n",
      "epoch 1: accuracy: 0.34\n",
      "epoch 2: accuracy: 0.36000000000000004\n",
      "epoch 3: accuracy: 0.38000000000000006\n",
      "epoch 4: accuracy: 0.4000000000000001\n",
      "epoch 5: accuracy: 0.4200000000000001\n",
      "epoch 6: accuracy: 0.4400000000000001\n",
      "epoch 7: accuracy: 0.46000000000000013\n",
      "epoch 8: accuracy: 0.48000000000000015\n",
      "epoch 9: accuracy: 0.5000000000000001\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- We need to indicate the metric to be retrieved, otherwise it will count as many results as num_results*num_metrics: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 3 experiments with at least 6 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset   rate  num_results      mean\n",
       "2     0.3  0.020            6  0.633333\n",
       "1     0.2  0.001           15  0.440000\n",
       "0     0.1    NaN            9  0.433333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- The metric is indicated with `_` at the beginning: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 3 experiments with at least 2 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset   rate  num_results  mean\n",
       "2     0.3  0.020            2  0.50\n",
       "1     0.2  0.001            5  0.21\n",
       "0     0.1    NaN            3  0.20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- We can filter those results that have less than X runs: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 3 experiments have 5 runs completed\n",
      "total data examined: 1 experiments with at least 5 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset   rate  num_results  mean\n",
       "1     0.2  0.001            5  0.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- We can filter by experiment number and/or number of results, and retrieve the original dataframe,plus new columns with stats: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 2 experiments with at least 2 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>time_1</th>\n",
       "      <th>1_finished</th>\n",
       "      <th>...</th>\n",
       "      <th>time_4</th>\n",
       "      <th>4_finished</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>rank</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>15:54:43.969089</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>15:54:44.225272</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  0_validation_accuracy  0_test_accuracy    time_0             date  \\\n",
       "0     0.1                    0.2              0.1  0.002003  15:54:43.969089   \n",
       "2     0.3                    0.5              0.4  0.002099  15:54:44.225272   \n",
       "\n",
       "  0_finished  1_validation_accuracy  1_test_accuracy    time_1 1_finished  \\\n",
       "0       True                    0.2              0.1  0.001967       True   \n",
       "2       True                    0.5              0.4  0.002191       True   \n",
       "\n",
       "   ...  time_4  4_finished  num_results mean  min  max  std  median      rank  \\\n",
       "0  ...     NaN         NaN            3  0.2  0.2  0.2  0.0     0.2  0.666667   \n",
       "2  ...     NaN         NaN            2  0.5  0.5  0.5  0.0     0.5  0.000000   \n",
       "\n",
       "   good  \n",
       "0     3  \n",
       "2     2  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_summarize_results, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def query (path_experiments = None, \n",
    "              folder_experiments = None,\n",
    "              intersection = False, \n",
    "              experiments = None, \n",
    "              suffix_results='', \n",
    "              min_results=0, \n",
    "              classes = None, \n",
    "              parameters_fixed = {},\n",
    "              parameters_variable = {},\n",
    "              parameters_all = [],\n",
    "              exact_match = True,\n",
    "              output='all',\n",
    "              ascending=False,\n",
    "              suffix_test_set = None,\n",
    "              stats = ['mean','median','rank','min','max','std'],\n",
    "              query_other_parameters=False):\n",
    "  \n",
    "    if path_experiments is None:\n",
    "        from hpsearch.config.hpconfig import get_path_experiments\n",
    "        path_experiments = get_path_experiments()\n",
    "    \n",
    "    path_pickle = None\n",
    "    if query_other_parameters:\n",
    "        path_csv = '%s/other_parameters.csv' %path_experiments\n",
    "    else:\n",
    "        path_pickle = '%s/experiments_data.pk' %path_experiments\n",
    "        if not os.path.exists(path_pickle):\n",
    "            path_pickle = None\n",
    "            path_csv = '%s/experiments_data.csv' %path_experiments\n",
    "    if path_pickle is not None:\n",
    "        experiment_data = pd.read_pickle(path_pickle)\n",
    "    else:\n",
    "        experiment_data = pd.read_csv(path_csv, index_col=0)\n",
    "    \n",
    "    non_valid_pars = set(parameters_fixed.keys()).difference(set(experiment_data.columns))\n",
    "    if len(non_valid_pars) > 0:\n",
    "        print (f'\\n**The following query parameters are not valid: {list(non_valid_pars)}**')\n",
    "        print (f'\\nValid parameters:\\n{sorted(get_parameters_columns(experiment_data))}\\n')\n",
    "    \n",
    "    parameters_multiple_values_all = list(ParameterGrid(parameters_variable))\n",
    "    experiment_numbers = []\n",
    "    for (i, parameters_multiple_values) in enumerate(parameters_multiple_values_all):\n",
    "        parameters = parameters_multiple_values.copy()\n",
    "        parameters.update(parameters_fixed)\n",
    "        parameters_none = {k:v for k,v in parameters.items() if v is None}\n",
    "        parameters_not_none = {k:v for k,v in parameters.items() if v is not None}\n",
    "\n",
    "        parameters = remove_defaults (parameters_not_none)\n",
    "        parameters.update(parameters_none)\n",
    "    \n",
    "        experiment_numbers_i, _, _ = find_rows_with_parameters_dict (experiment_data, parameters, ignore_keys=parameters_all, exact_match = exact_match)\n",
    "        experiment_numbers += experiment_numbers_i\n",
    "    \n",
    "    experiment_data = experiment_data.iloc[experiment_numbers]\n",
    "    \n",
    "    if experiments is not None:\n",
    "        experiment_data = experiment_data.loc[experiments]\n",
    "        \n",
    "    if query_other_parameters:\n",
    "        return experiment_data\n",
    "  \n",
    "    d=summarize_results(path_experiments=path_experiments, \n",
    "                      folder_experiments=folder_experiments,\n",
    "                      intersection=intersection, \n",
    "                      experiments=experiments, \n",
    "                      suffix_results=suffix_results, \n",
    "                      min_results=min_results, \n",
    "                      class_ids=classes, \n",
    "                      parameters=None,\n",
    "                      output='all',\n",
    "                      data=experiment_data,\n",
    "                      ascending=ascending,\n",
    "                      suffix_test_set=suffix_test_set,\n",
    "                      stats=stats)\n",
    "                      \n",
    "    return d['mean'], d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_query ():\n",
    "    em = generate_data_exp_utils ('query')\n",
    "        \n",
    "    dmean, d = query (parameters_fixed=dict (rate=0.0001))\n",
    "    assert dmean.empty\n",
    "    \n",
    "    md ('the dataframe only has mean. Results are sorted by mean score')\n",
    "    dmean, d = query (parameters_fixed=dict (rate=0.0001), exact_match=False)\n",
    "    assert dmean.shape[0]==9 and (dmean.rate==0.0001).all() and len(dmean.offset.unique())==3 and dmean['mean'].iloc[0]>dmean['mean'].iloc[1] and dmean['mean'].iloc[1] > dmean['mean'].iloc[2]\n",
    "    display (dmean)\n",
    "    md ('The second output d contains a field \"stats\" which is a dataframe. Results are sorted by mean score')\n",
    "    assert {'mean', 'median', 'rank', 'min', 'max', 'std'}.issubset(d['stats'])\n",
    "    display (d['stats'])\n",
    "    \n",
    "    md ('We can request parameter be in specific list of values')   \n",
    "    dmean, d = query (parameters_fixed=dict(rate=0.0001), exact_match=False, \n",
    "                  parameters_variable=dict(epochs=[5,10], offset=[0.1, 0.3]))\n",
    "    assert sorted(dmean.epochs.unique()) == [5,10]\n",
    "    assert sorted(dmean.offset.unique()) == [0.1, 0.3]\n",
    "    assert dmean.shape[0]==4\n",
    "    display (dmean)\n",
    "    \n",
    "    md ('If we want a value that is the default, we need to indicate None')\n",
    "    dmean, d = query (parameters_fixed=dict(rate=0.0001), exact_match=False, \n",
    "              parameters_variable=dict(epochs=[10, None], offset=[0.1, 0.3]))\n",
    "    assert dmean.shape[0]==4\n",
    "    assert dmean.epochs.isna().sum() == 2\n",
    "    assert (dmean.epochs == 10).sum() == 2\n",
    "    display (dmean)\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_query\n",
      "total data examined: 0 experiments with at least nan runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "the dataframe only has mean. Results are sorted by mean score"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 9 experiments with at least 15 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>noise</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.731242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.693155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.679728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.548471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.505715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.481352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.432128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.380060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  offset    rate  noise  num_results      mean\n",
       "11     5.0     0.6  0.0001    0.1           15  0.731242\n",
       "14    10.0     0.6  0.0001    0.1           15  0.693155\n",
       "17     NaN     0.6  0.0001    0.1           15  0.679728\n",
       "10     5.0     0.3  0.0001    0.1           15  0.548471\n",
       "13    10.0     0.3  0.0001    0.1           15  0.505715\n",
       "16     NaN     0.3  0.0001    0.1           15  0.481352\n",
       "9      5.0     0.1  0.0001    0.1           15  0.432128\n",
       "12    10.0     0.1  0.0001    0.1           15  0.386496\n",
       "15     NaN     0.1  0.0001    0.1           15  0.380060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The second output d contains a field \"stats\" which is a dataframe. Results are sorted by mean score"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>noise</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rank</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.731242</td>\n",
       "      <td>0.717476</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.693155</td>\n",
       "      <td>0.581141</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>0.288745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.679728</td>\n",
       "      <td>0.670236</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.548471</td>\n",
       "      <td>0.426426</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>0.095076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.346302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.505715</td>\n",
       "      <td>0.315252</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.126844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.481352</td>\n",
       "      <td>0.298419</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>0.065535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.390327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.432128</td>\n",
       "      <td>0.236860</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386496</td>\n",
       "      <td>0.119425</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.451545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.380060</td>\n",
       "      <td>0.152559</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.457517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  offset    rate  noise  num_results      mean    median      rank  \\\n",
       "11     5.0     0.6  0.0001    0.1           15  0.731242  0.717476  1.066667   \n",
       "14    10.0     0.6  0.0001    0.1           15  0.693155  0.581141  2.533333   \n",
       "17     NaN     0.6  0.0001    0.1           15  0.679728  0.670236  3.666667   \n",
       "10     5.0     0.3  0.0001    0.1           15  0.548471  0.426426  2.733333   \n",
       "13    10.0     0.3  0.0001    0.1           15  0.505715  0.315252  4.200000   \n",
       "16     NaN     0.3  0.0001    0.1           15  0.481352  0.298419  5.466667   \n",
       "9      5.0     0.1  0.0001    0.1           15  0.432128  0.236860  4.000000   \n",
       "12    10.0     0.1  0.0001    0.1           15  0.386496  0.119425  5.533333   \n",
       "15     NaN     0.1  0.0001    0.1           15  0.380060  0.152559  6.800000   \n",
       "\n",
       "         min  max       std  \n",
       "11  0.412303  1.0  0.216686  \n",
       "14  0.288745  1.0  0.260617  \n",
       "17  0.312746  1.0  0.263702  \n",
       "10  0.095076  1.0  0.346302  \n",
       "13  0.126844  1.0  0.367088  \n",
       "16  0.065535  1.0  0.390327  \n",
       "9   0.000000  1.0  0.425926  \n",
       "12  0.000000  1.0  0.451545  \n",
       "15  0.000000  1.0  0.457517  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "We can request parameter be in specific list of values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 4 experiments with at least 15 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>noise</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.548471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.505715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.432128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  offset    rate  noise  num_results      mean\n",
       "10     5.0     0.3  0.0001    0.1           15  0.548471\n",
       "13    10.0     0.3  0.0001    0.1           15  0.505715\n",
       "9      5.0     0.1  0.0001    0.1           15  0.432128\n",
       "12    10.0     0.1  0.0001    0.1           15  0.386496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "If we want a value that is the default, we need to indicate None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data examined: 4 experiments with at least 15 runs done for each one\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>noise</th>\n",
       "      <th>num_results</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.505715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.481352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.380060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  offset    rate  noise  num_results      mean\n",
       "13    10.0     0.3  0.0001    0.1           15  0.505715\n",
       "16     NaN     0.3  0.0001    0.1           15  0.481352\n",
       "12    10.0     0.1  0.0001    0.1           15  0.386496\n",
       "15     NaN     0.1  0.0001    0.1           15  0.380060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_query, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summary (df, experiments = None, score=None, compact=True):\n",
    "    if experiments is not None:\n",
    "        df = df.loc[experiments]\n",
    "    if compact:\n",
    "        _, df = get_parameters_unique(df)\n",
    "    parameters_columns = get_parameters_columns(df, True)\n",
    "    scores_columns = get_scores_columns (df, suffix_results=score)\n",
    "    df = df[parameters_columns + scores_columns]\n",
    "    df.columns=[c.split('_')[0] for c in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_experiment_utils\n",
    "def test_summary ():\n",
    "    em = init_em ('summary')\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.1, rate=0.01), nruns=3)\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.2, rate=0.001), nruns=5)\n",
    "    em.run_multiple_repetitions (parameters=dict(offset=0.3, rate=0.02), nruns=2)\n",
    "    df = em.get_experiment_data()\n",
    "    result = summary (df, score='_validation_accuracy')\n",
    "    display (result)\n",
    "    assert all(result.columns == ['offset', 'rate', '0', '1', '2', '3', '4'])\n",
    "    assert result.shape[0] == 3\n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_summary\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.11\n",
      "epoch 1: accuracy: 0.12\n",
      "epoch 2: accuracy: 0.13\n",
      "epoch 3: accuracy: 0.14\n",
      "epoch 4: accuracy: 0.15000000000000002\n",
      "epoch 5: accuracy: 0.16000000000000003\n",
      "epoch 6: accuracy: 0.17000000000000004\n",
      "epoch 7: accuracy: 0.18000000000000005\n",
      "epoch 8: accuracy: 0.19000000000000006\n",
      "epoch 9: accuracy: 0.20000000000000007\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.201\n",
      "epoch 1: accuracy: 0.202\n",
      "epoch 2: accuracy: 0.203\n",
      "epoch 3: accuracy: 0.20400000000000001\n",
      "epoch 4: accuracy: 0.20500000000000002\n",
      "epoch 5: accuracy: 0.20600000000000002\n",
      "epoch 6: accuracy: 0.20700000000000002\n",
      "epoch 7: accuracy: 0.20800000000000002\n",
      "epoch 8: accuracy: 0.20900000000000002\n",
      "epoch 9: accuracy: 0.21000000000000002\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.32\n",
      "epoch 1: accuracy: 0.34\n",
      "epoch 2: accuracy: 0.36000000000000004\n",
      "epoch 3: accuracy: 0.38000000000000006\n",
      "epoch 4: accuracy: 0.4000000000000001\n",
      "epoch 5: accuracy: 0.4200000000000001\n",
      "epoch 6: accuracy: 0.4400000000000001\n",
      "epoch 7: accuracy: 0.46000000000000013\n",
      "epoch 8: accuracy: 0.48000000000000015\n",
      "epoch 9: accuracy: 0.5000000000000001\n",
      "fitting model with 10 epochs\n",
      "epoch 0: accuracy: 0.32\n",
      "epoch 1: accuracy: 0.34\n",
      "epoch 2: accuracy: 0.36000000000000004\n",
      "epoch 3: accuracy: 0.38000000000000006\n",
      "epoch 4: accuracy: 0.4000000000000001\n",
      "epoch 5: accuracy: 0.4200000000000001\n",
      "epoch 6: accuracy: 0.4400000000000001\n",
      "epoch 7: accuracy: 0.46000000000000013\n",
      "epoch 8: accuracy: 0.48000000000000015\n",
      "epoch 9: accuracy: 0.5000000000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset   rate     0     1     2     3     4\n",
       "0     0.1    NaN  0.20  0.20  0.20   NaN   NaN\n",
       "1     0.2  0.001  0.21  0.21  0.21  0.21  0.21\n",
       "2     0.3  0.020  0.50  0.50   NaN   NaN   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_summary, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (hpsearch)",
   "language": "python",
   "name": "hpsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
