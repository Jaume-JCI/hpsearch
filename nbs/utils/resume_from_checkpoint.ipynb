{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp utils.resume_from_checkpoint\n",
    "from nbdev.showdoc import show_doc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume utilities\n",
    "\n",
    "> Routines for resuming from previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def make_resume_from_checkpoint (parameters, prev_path_results, use_best=False):\n",
    "\n",
    "    if parameters.get('previous_model_file_name') is not None:\n",
    "        previous_model_file_name = parameters['previous_model_file_name']\n",
    "    else:\n",
    "        model_extension = parameters.get('model_extension', 'h5')\n",
    "        model_name = parameters.get('model_name', 'checkpoint_')\n",
    "        epoch_offset = parameters.get('epoch_offset', 0)\n",
    "        name_best_model = parameters.get('name_best_model', 'best_model')\n",
    "\n",
    "    found = False\n",
    "    name_model_history = parameters.get('name_model_history', 'model_history.pk')\n",
    "    name_last_epoch = parameters.get('name_last_epoch', 'last_epoch')\n",
    "    path_model_history = f'{prev_path_results}/{name_model_history}'\n",
    "    if os.path.exists(path_model_history):\n",
    "        parameters['resume_summary'] = path_model_history\n",
    "        found = True\n",
    "        parameters['prev_path_results'] = prev_path_results\n",
    "        if parameters.get('previous_model_file_name') is not None:\n",
    "            parameters['resume'] = f'{prev_path_results}/{previous_model_file_name}'\n",
    "        elif use_best:\n",
    "            parameters['resume'] = f'{prev_path_results}/{name_best_model}.{model_extension}'\n",
    "        else:\n",
    "            summary = pickle.load(open(path_model_history, 'rb'))\n",
    "            prev_epoch = summary.get(name_last_epoch,-1)\n",
    "            if prev_epoch >= 0:\n",
    "                parameters['resume'] = f'{prev_path_results}/{model_name}{prev_epoch+epoch_offset}.{model_extension}'\n",
    "        if not os.path.exists(parameters['resume']):\n",
    "            parameters['resume'] = ''\n",
    "            parameters['prev_path_results'] = ''\n",
    "            found = False\n",
    "\n",
    "    return found\n",
    "    \n",
    "def exists_current_checkpoint (parameters, path_results):\n",
    "\n",
    "    model_extension = parameters.get('model_extension', 'h5')\n",
    "\n",
    "    return os.path.exists('%s/best_model.%s' %(path_results, model_extension))\n",
    "        \n",
    "def finished_all_epochs (parameters, path_results, name_epoch='max_epoch'):\n",
    "    from hpsearch.config.default_parameters import get_default_parameters\n",
    "    \n",
    "    finished = True\n",
    "    defaults = get_default_parameters(parameters)\n",
    "    current_epoch = parameters.get(name_epoch, defaults.get(name_epoch))\n",
    "    \n",
    "    name_model_history = parameters.get('name_model_history', 'model_history.pk')\n",
    "    path_model_history = f'{path_results}/{name_model_history}'\n",
    "    \n",
    "    if os.path.exists(path_model_history):\n",
    "        summary = pickle.load(open(path_model_history, 'rb'))\n",
    "        prev_epoch = summary.get('last_epoch',-1)\n",
    "        if (prev_epoch+1) >= current_epoch:\n",
    "            finished = True\n",
    "        else:\n",
    "            finished = False\n",
    "    else:\n",
    "        finished = False\n",
    "\n",
    "    return finished\n",
    "    \n",
    "def obtain_last_result (parameters, path_results):\n",
    "    \n",
    "    if parameters.get('use_last_result_from_dict', False):\n",
    "        return obtain_last_result_from_dict (parameters, path_results)\n",
    "    if 'result_file' in parameters.keys():\n",
    "        name_result_file = parameters['result_file']\n",
    "    else:\n",
    "        name_result_file = parameters.get('name_model_history', 'model_history.pk')\n",
    "    path_results_file = '%s/%s' %(path_results, name_result_file)\n",
    "    dict_results = None\n",
    "    if os.path.exists (path_results_file):\n",
    "        history = pickle.load(open(path_results_file, 'rb'))\n",
    "        metrics = parameters.get('key_scores')\n",
    "        if metrics is None:\n",
    "            metrics = history.keys()\n",
    "        ops = parameters.get('ops')\n",
    "        if ops is None:\n",
    "            ops = ['max'] * len(metrics)\n",
    "        if type(ops) is str:\n",
    "            ops = [ops] * len(metrics)\n",
    "        if type(ops) is dict:\n",
    "            ops_dict = ops\n",
    "            ops = ['max'] * len(metrics)\n",
    "            i = 0\n",
    "            for k in metrics:\n",
    "                if k in ops_dict.keys():\n",
    "                    ops[i] = ops_dict[k]\n",
    "                i += 1\n",
    "        dict_results = {}\n",
    "        max_last_position = -1\n",
    "        for metric, op in zip(metrics, ops):\n",
    "            if metric in history.keys():\n",
    "                history_array = history[metric]\n",
    "                score = min(history_array) if op == 'min' else max(history_array)\n",
    "                last_position = np.where(np.array(history_array).ravel()==0)[0]\n",
    "                if len(last_position) > 0:\n",
    "                    last_position = last_position[0] - 1\n",
    "                else:\n",
    "                    last_position = len(history_array)\n",
    "                dict_results[metric] = score\n",
    "            else:\n",
    "                last_position = -1\n",
    "            max_last_position = max(last_position, max_last_position)\n",
    "        \n",
    "        dict_results['last'] = max_last_position\n",
    "        if max_last_position < parameters.get('min_iterations', 50):\n",
    "            dict_results = None\n",
    "            print ('not storing result from {} with iterations {}'.format(path_results, max_last_position))\n",
    "        else:\n",
    "            print ('storing result from {} with iterations {}'.format(path_results, max_last_position))\n",
    "        \n",
    "    return dict_results\n",
    "        \n",
    "def obtain_last_result_from_dict (parameters, path_results):\n",
    "    name_result_file = parameters.get('result_file', 'dict_results.pk')\n",
    "    path_results_file = '%s/%s' %(path_results, name_result_file)\n",
    "    dict_results = None\n",
    "    if os.path.exists (path_results_file):\n",
    "        dict_results = pickle.load(open(path_results_file, 'rb'))\n",
    "        if 'last' not in dict_results.keys() and 'epoch' in dict_results.keys():\n",
    "            dict_results['last'] = dict_results['epoch']\n",
    "        max_last_position = dict_results['last']\n",
    "        if max_last_position < parameters.get('min_iterations', 50):\n",
    "            dict_results = None\n",
    "            print ('not storing result from {} with iterations {}'.format(path_results, max_last_position))\n",
    "        else:\n",
    "            print ('storing result from {} with iterations {}'.format(path_results, max_last_position))\n",
    "    \n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted default_parameters.ipynb.\n",
      "Converted get_paths.ipynb.\n",
      "Converted hpconfig.ipynb.\n",
      "Converted manager_factory.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted example_experiment.ipynb.\n",
      "Converted example_experiment_manager.ipynb.\n",
      "Converted experiment_manager.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted experiment_utils.ipynb.\n",
      "Converted organize_experiments.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script(recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ra)",
   "language": "python",
   "name": "ra"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
