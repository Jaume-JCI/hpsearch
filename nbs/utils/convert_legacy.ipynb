{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp utils.convert_legacy\n",
    "from nbdev.showdoc import *\n",
    "from dsblocks.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])\n",
    "#tst = TestRunner (targets=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert legacy data format\n",
    "\n",
    "> Utilities for converting data to/from legacy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hpsearch.config import hp_defaults as dflt\n",
    "from hpsearch.utils.experiment_utils import read_df, write_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import pytest\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "\n",
    "from dsblocks.utils.nbdev_utils import md\n",
    "from dsblocks.utils.utils import remove_previous_results\n",
    "\n",
    "from hpsearch.utils.experiment_utils import read_df, write_df\n",
    "from hpsearch.config import hp_defaults as dflt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert `experiment_data` from and to older version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## legacy data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_parameters_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_parameters_columns (experiment_data, only_not_null=False):\n",
    "    parameters =  [par for par in experiment_data.columns if not par[0].isdigit() and (par.find('time_')<0) and (par.find('date')<0)]\n",
    "    if only_not_null:\n",
    "        parameters = np.array(parameters)[~experiment_data.loc[:,parameters].isnull().all(axis=0)].tolist()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_scores_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_scores_columns (experiment_data=None, suffix_results='', class_ids = None):\n",
    "    \"\"\"\n",
    "    Determine the columnns that provide evaluation scores. \n",
    "    \n",
    "    We assume that they start with the class number, and that the other columns \n",
    "    do not start with a digit.\n",
    "    \"\"\"\n",
    "    if class_ids is not None:\n",
    "        scores_columns = ['%d%s' %(col,suffix_results) for col in class_ids]\n",
    "    else:\n",
    "        if experiment_data is None:\n",
    "            raise ValueError ('Either experiment_data or class_ids should be different than None')\n",
    "        scores_columns = [col for col in experiment_data.columns if col[0].isdigit()]\n",
    "        # For some experiments, we have multiple scores per class (e.g., due to different evaluation criteria). The argument suffix_results can be used to select the appropriate score.\n",
    "        if len(suffix_results) > 0:\n",
    "            scores_columns = [col for col in scores_columns if (len(col.split(suffix_results))==2) and (len(col.split(suffix_results)[1])==0) and (col.split(suffix_results)[0].isdigit()) ]\n",
    "        else:\n",
    "            # We assume that default scores are in columns whose names only have the class number \n",
    "            scores_columns = [col for col in scores_columns if (len(col.split('_'))>=1)]\n",
    "    return scores_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get_scores_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_scores_names (experiment_data=None, run_number=None, experiment=None, only_valid=True, \n",
    "                      sort=False):\n",
    "    \"\"\" \n",
    "    Determine the names of the scores included in experiment data. \n",
    "    \n",
    "    We assume that the score columns start with the class number, and that the other columns do not start with a digit.\n",
    "\n",
    "    If run_number is provided, we provide the scores stored for that run number. If, in addition to this, \n",
    "    experiment is provided, and only_valid=True, we provide only the scores that are not NaN for the given \n",
    "    experiment number.\n",
    "    \"\"\"\n",
    "    \n",
    "    if run_number is None:\n",
    "        scores_names = np.unique([('_'.join(col.split('_')[1:]) if (len(col.split('_')) > 1) else '') \n",
    "                                    for col in experiment_data.columns if col[0].isdigit()])\n",
    "        \n",
    "    else:\n",
    "        scores_names = [col.split(f'{run_number}')[1] for col in experiment_data.columns if col.startswith(str(run_number))]\n",
    "        scores_names = [('_'.join(col.split('_')[1:]) if (len(col.split('_')) > 1) else '')\n",
    "                                    for col in scores_names]\n",
    "        if (experiment is not None) and only_valid:\n",
    "            scores_names = [name for name in scores_names if not np.isnan(experiment_data.loc[experiment, f'{run_number}_{name}'])]\n",
    "        if sort:\n",
    "            scores_names = list(np.sort(scores_names))\n",
    "    # remove special names\n",
    "    scores_names = [name for name in scores_names if name != 'finished']\n",
    "    return scores_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `update_data_format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_data_format (df):\n",
    "    par_cols_src = get_parameters_columns(df)\n",
    "    par_cols_dst = pd.MultiIndex.from_product ([[dflt.parameters_col], par_cols_src, ['']])\n",
    "    par_df = df[par_cols_src]\n",
    "    par_df.columns = par_cols_dst\n",
    "\n",
    "    score_cols_src = [c for c in get_scores_columns (df) if not c.endswith('finished')]\n",
    "    score_cols_src = np.sort(score_cols_src).tolist()\n",
    "    run_number = np.unique([c.split('_')[0] for c in score_cols_src])\n",
    "    scores_names = get_scores_names (df)\n",
    "    scores_names = np.sort(scores_names).tolist()\n",
    "    score_cols_dst = pd.MultiIndex.from_product ([[dflt.scores_col], scores_names, run_number.tolist()])\n",
    "    scores_dst_sort = np.sort(pd.MultiIndex.from_tuples([(t[0], t[2], t[1]) for t in score_cols_dst]))\n",
    "    score_cols_dst = pd.MultiIndex.from_tuples([(t[0], t[2], t[1]) for t in scores_dst_sort])\n",
    "    score_df = df[score_cols_src]\n",
    "    score_df.columns = score_cols_dst\n",
    "\n",
    "    finished_cols_src = [c for c in get_scores_columns (df) if c.endswith('finished')]\n",
    "    finished_cols_src = np.sort(finished_cols_src).tolist()\n",
    "    finished_cols_dst = pd.MultiIndex.from_product ([[dflt.run_info_col], ['finished'], run_number.tolist()])\n",
    "    finished_df = df[finished_cols_src]\n",
    "    finished_df.columns = finished_cols_dst\n",
    "\n",
    "    time_cols_src = [c for c in df.columns if c.startswith('time')]\n",
    "    time_cols_src = np.sort(time_cols_src).tolist()\n",
    "    time_cols_dst = pd.MultiIndex.from_product ([[dflt.run_info_col], ['time'], run_number.tolist()])\n",
    "    time_df = df[time_cols_src]\n",
    "    time_df.columns = time_cols_dst\n",
    "\n",
    "    date_cols_src = [c for c in df.columns if c.startswith('date')]\n",
    "    date_cols_src = np.sort(date_cols_src).tolist()\n",
    "    date_cols_dst = pd.MultiIndex.from_product ([[dflt.run_info_col], ['date'], run_number.tolist()])\n",
    "    date_df = df[date_cols_src*len(date_cols_dst)]\n",
    "    date_df.columns = date_cols_dst\n",
    "\n",
    "    df = pd.concat ([par_df, score_df, finished_df, time_df, date_df], axis=1)\n",
    "    df = df[df.columns.sort_values()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_convert_legacy\n",
    "def generate_data ():\n",
    "    df = pd.DataFrame ([[0.1, 0.05, 0.6, 0.5, 0.0034384727478027344,\n",
    "            datetime.time(10, 42, 26, 630428), True, 0.61, 0.51,\n",
    "            0.002204418182373047, True, 0.62, 0.52, 0.002073526382446289, True],\n",
    "           [0.2, 0.05, 0.7000000000000001, 0.6000000000000001,\n",
    "            0.0020360946655273438, datetime.time(10, 42, 26, 669600), True,\n",
    "            None, None, None, None, None, None, None, None]])\n",
    "    df.columns = ['offset', 'rate', '0_validation_accuracy', '0_test_accuracy', 'time_0',\n",
    "                                   'date', '0_finished', '1_validation_accuracy', '1_test_accuracy',\n",
    "                                   'time_1', '1_finished', '2_validation_accuracy', '2_test_accuracy',\n",
    "                                   'time_2', '2_finished']\n",
    "    return df\n",
    "\n",
    "def test_update_data_format ():\n",
    "    # get data\n",
    "    df = generate_data ()\n",
    "    display (df)\n",
    "    \n",
    "    # run function\n",
    "    df = update_data_format (df)\n",
    "\n",
    "    # check results\n",
    "    np.testing.assert_array_equal (df[('scores','validation_accuracy')].values, \n",
    "                               np.array([[0.6, 0.61, 0.62], [0.7000000000000001, np.nan, np.nan]]))\n",
    "    np.testing.assert_array_equal (df[('scores','test_accuracy')].values, \n",
    "                               np.array([[0.5, 0.51, 0.52], [0.6000000000000001, np.nan, np.nan]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_update_data_format\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>time_1</th>\n",
       "      <th>1_finished</th>\n",
       "      <th>2_validation_accuracy</th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>10:42:26.630428</td>\n",
       "      <td>True</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>True</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>10:42:26.669600</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.003438   \n",
       "1     0.2  0.05                    0.7              0.6  0.002036   \n",
       "\n",
       "              date  0_finished  1_validation_accuracy  1_test_accuracy  \\\n",
       "0  10:42:26.630428        True                   0.61             0.51   \n",
       "1  10:42:26.669600        True                    NaN              NaN   \n",
       "\n",
       "     time_1 1_finished  2_validation_accuracy  2_test_accuracy    time_2  \\\n",
       "0  0.002204       True                   0.62             0.52  0.002074   \n",
       "1       NaN       None                    NaN              NaN       NaN   \n",
       "\n",
       "  2_finished  \n",
       "0       True  \n",
       "1       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_update_data_format, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `update_and_replace_experiment_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_and_replace_experiment_data (path_experiments):\n",
    "    df = read_df (path_experiments)\n",
    "    df = update_data_format (df)\n",
    "    write_df (df, path_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_convert_legacy\n",
    "def test_update_and_replace_experiment_data ():\n",
    "    path_experiments = 'test_update_and_replace_experiment_data'\n",
    "    os.makedirs (path_experiments, exist_ok=True)\n",
    "    \n",
    "    # get and write data\n",
    "    df = generate_data ()\n",
    "    write_df (df, path_experiments)\n",
    "    display (df)\n",
    "    \n",
    "    # run function\n",
    "    update_and_replace_experiment_data (path_experiments)\n",
    "    print ('\\nfiles written: ', os.listdir (path_experiments))\n",
    "    \n",
    "    # check results\n",
    "    df = read_df (path_experiments)\n",
    "    np.testing.assert_array_equal (df[('scores','validation_accuracy')].values, \n",
    "                               np.array([[0.6, 0.61, 0.62], [0.7000000000000001, np.nan, np.nan]]))\n",
    "    np.testing.assert_array_equal (df[('scores','test_accuracy')].values, \n",
    "                               np.array([[0.5, 0.51, 0.52], [0.6000000000000001, np.nan, np.nan]]))\n",
    "    \n",
    "    remove_previous_results (path_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_update_and_replace_experiment_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>rate</th>\n",
       "      <th>0_validation_accuracy</th>\n",
       "      <th>0_test_accuracy</th>\n",
       "      <th>time_0</th>\n",
       "      <th>date</th>\n",
       "      <th>0_finished</th>\n",
       "      <th>1_validation_accuracy</th>\n",
       "      <th>1_test_accuracy</th>\n",
       "      <th>time_1</th>\n",
       "      <th>1_finished</th>\n",
       "      <th>2_validation_accuracy</th>\n",
       "      <th>2_test_accuracy</th>\n",
       "      <th>time_2</th>\n",
       "      <th>2_finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>10:42:26.630428</td>\n",
       "      <td>True</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>True</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>10:42:26.669600</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  rate  0_validation_accuracy  0_test_accuracy    time_0  \\\n",
       "0     0.1  0.05                    0.6              0.5  0.003438   \n",
       "1     0.2  0.05                    0.7              0.6  0.002036   \n",
       "\n",
       "              date  0_finished  1_validation_accuracy  1_test_accuracy  \\\n",
       "0  10:42:26.630428        True                   0.61             0.51   \n",
       "1  10:42:26.669600        True                    NaN              NaN   \n",
       "\n",
       "     time_1 1_finished  2_validation_accuracy  2_test_accuracy    time_2  \\\n",
       "0  0.002204       True                   0.62             0.52  0.002074   \n",
       "1       NaN       None                    NaN              NaN       NaN   \n",
       "\n",
       "  2_finished  \n",
       "0       True  \n",
       "1       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "files written:  ['experiments_data.csv', 'experiments_data.pk']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_update_and_replace_experiment_data, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (test_hpsearch)",
   "language": "python",
   "name": "test_hpsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
