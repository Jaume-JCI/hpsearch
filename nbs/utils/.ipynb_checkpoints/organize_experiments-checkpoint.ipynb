{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp utils.organize_experiments\n",
    "from nbdev.showdoc import *\n",
    "from block_types.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize experiments\n",
    "\n",
    "> Routines for organizing the experiments folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from hpsearch.utils import experiment_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from hpsearch.examples.dummy_experiment_manager import generate_data\n",
    "from hpsearch.config.hpconfig import get_path_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_experiments (path_source, path_destination, key_score=None):\n",
    "    experiment_data_source = pd.read_pickle ('%s/experiments_data.pk' %path_source)\n",
    "    experiment_data_destination = pd.read_pickle ('%s/experiments_data.pk' %path_destination)\n",
    "    experiment_data_source, changed_source = remove_defaults_from_experiment_data (experiment_data_source)\n",
    "    experiment_data_destination, changed_destination = remove_defaults_from_experiment_data (experiment_data_destination)\n",
    "    \n",
    "    for experiment_number_source in range(experiment_data_source.shape[0]):\n",
    "        path_experiment_source = '%s/experiments/%05d' %(path_source, experiment_number_source)\n",
    "        parameters_source, _ = pickle.load(open('%s/parameters.pk' %path_experiment_source,'rb'))\n",
    "        experiment_number_destination, changed_dataframe, _ = experiment_utils.find_rows_with_parameters_dict (experiment_data_destination, parameters_source)\n",
    "        path_experiment_destination = '%s/experiments/%05d' %(path_destination, experiment_number_destination)\n",
    "        if changed_dataframe:\n",
    "            # move folders\n",
    "            os.rename (path_experiment_source, path_experiment_destination)\n",
    "            # copy results to dataframe\n",
    "            missing_cols = [col for col in experiment_data_source.columns if col not in experiment_data_destination.columns]\n",
    "            for column in missing_cols:\n",
    "                experiment_data_destination[column] = None\n",
    "            experiment_data_destination.loc[experiment_number_destination] = experiment_data_source.loc[experiment_number_source]\n",
    "        else:\n",
    "            class_ids_source = [int(x) for x in os.listdir(path_experiment_source) if os.path.isdir('%s/%s' %(path_experiment_source, x))]\n",
    "            class_ids_destination = [int(x) for x in os.listdir(path_experiment_destination) if os.path.isdir('%s/%s' %(path_experiment_destination, x))]\n",
    "            last_id_destination = max(class_ids_destination)\n",
    "            \n",
    "            class_ids_both = [x for x in class_ids_source if x in class_ids_destination]\n",
    "            class_ids_source = [x for x in class_ids_source if x not in class_ids_both]\n",
    "            class_ids_destination = [x for x in class_ids_destination if x not in class_ids_both]\n",
    "            for (idx, class_id_source) in enumerate(class_ids_both):\n",
    "                if key_score is not None:\n",
    "                    scores_name = '%d_%s' %(class_id_source, key_score)\n",
    "                    if experiment_data_source.loc[experiment_number_source, scores_name] != experiment_data_destination.loc[experiment_number_destination, scores_name]:\n",
    "                        is_new = True\n",
    "                else:\n",
    "                    is_new = False\n",
    "                    scores_name_source = [x for x in experiment_data_source.columns if x.startswith('%d_' %class_id_source)]\n",
    "                    scores_name_source = [x for x in scores_name_source if not np.isnan(experiment_data_source.loc[experiment_number_source, x])]\n",
    "                    for scores_name in scores_name_source:\n",
    "                        if experiment_data_source.loc[experiment_number_source, scores_name] != experiment_data_destination.loc[experiment_number_destination, scores_name]:\n",
    "                            is_new = True\n",
    "                            break\n",
    "                if not is_new:\n",
    "                    del class_ids_both[idx]\n",
    "            class_ids_source += class_ids_both\n",
    "            class_ids_destination += class_ids_both\n",
    "                \n",
    "            last_id_source = len(class_ids_source)\n",
    "            new_ids_destination = range(last_id_destination+1, last_id_destination+last_id_source)\n",
    "            for (new_id_destination, class_id_source) in zip(new_ids_destination, class_ids_source):\n",
    "                # move folders\n",
    "                os.rename ('%s/%d' %(path_experiment_source, class_id_source), '%s/%d' %(path_experiment_destination, new_id_destination))\n",
    "                # copy results to dataframe\n",
    "                scores_name_source = [x for x in experiment_data_source.columns if x.startswith('%d_' %class_id_source)]\n",
    "                scores_name_destination = ['%d_%s' (new_id_destination, x[len('%d_' %class_id_source):]) for x in scores_name_source]\n",
    "                for score_name_source, score_name_destination in zip(scores_name_source, scores_name_destination):\n",
    "                    experiment_data_destination.loc[experiment_number_destination, score_name_destination] = experiment_data_source.loc[experiment_number_source, score_name_source]\n",
    "        \n",
    "        experiment_data_destination.to_csv ('%s/experiments_data.csv' %path_destination)\n",
    "        experiment_data_destination.to_pickle ('%s/experiments_data.pk' %path_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_defaults_from_experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_defaults_from_experiment_data (experiment_data):\n",
    "    from hpsearch.config.hpconfig import get_default_parameters\n",
    "    \n",
    "    experiment_data_original = experiment_data.copy()\n",
    "    parameters_names = experiment_utils.get_parameters_columns (experiment_data)\n",
    "    parameters_data = experiment_data_original[parameters_names]\n",
    "    changed_df = False\n",
    "    for experiment_number in range(experiment_data.shape[0]):\n",
    "        good_params = ~(experiment_data.loc[experiment_number, parameters_names].isna()).values\n",
    "        parameters_names_i = np.array(parameters_names)[good_params]\n",
    "        parameters_names_i = parameters_names_i.tolist()\n",
    "        parameters = experiment_data.loc[experiment_number, parameters_names_i].to_dict()\n",
    "\n",
    "        defaults = get_default_parameters(parameters)\n",
    "        default_names = [default_name for default_name in defaults.keys() if default_name in parameters_names_i]\n",
    "        \n",
    "        for default_name in default_names:\n",
    "            has_default = experiment_data.loc[experiment_number, default_name] == defaults[default_name]\n",
    "            if has_default:\n",
    "                print ('found experiment with default in experiment_number {}, parameter {}, values: {}'.format(experiment_number, default_name, experiment_data.loc[experiment_number, default_name]))\n",
    "                changed_df = True\n",
    "                experiment_data.loc[experiment_number, default_name] = None\n",
    "    \n",
    "    # check if there are repeated experiments\n",
    "    if changed_df:\n",
    "        if experiment_data[parameters_names].duplicated().any():\n",
    "            print ('duplicated experiments: {}'.format(experiment_data[parameters_names].duplicated()))\n",
    "            experiment_data = experiment_data_original\n",
    "            changed_df = False\n",
    "        \n",
    "    return experiment_data, changed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_experiments (experiments=[], root_path=None, root_folder=None):\n",
    "    from hpsearch.config.hpconfig import get_path_experiment, get_path_experiments\n",
    "    \n",
    "    if type(experiments) is not list:\n",
    "        experiments = [experiments]\n",
    "    if root_path is None:\n",
    "        root_path = get_path_experiments(folder = root_folder)\n",
    "    \n",
    "    # 1. remove experiments from csv file\n",
    "    path_csv = f'{root_path}/experiments_data.csv'\n",
    "    path_pickle = path_csv.replace('csv', 'pk')\n",
    "    experiment_data = pd.read_pickle (path_pickle)\n",
    "    experiment_data = experiment_data.drop (index=experiments)\n",
    "    \n",
    "    # 2. remove experiments folders\n",
    "    for experiment in experiments:\n",
    "        path_experiment = get_path_experiment (experiment, root_path=root_path, root_folder=root_folder)\n",
    "        shutil.rmtree(path_experiment)\n",
    "        \n",
    "    # 3. move experiment folders\n",
    "    for new_number, original_number in enumerate(experiment_data.index):\n",
    "        path_new_experiment = get_path_experiment (new_number, root_path=root_path, root_folder=root_folder)\n",
    "        path_original_experiment = get_path_experiment (original_number, root_path=root_path, root_folder=root_folder)\n",
    "        if path_new_experiment != path_original_experiment:\n",
    "            shutil.move (path_original_experiment, path_new_experiment)\n",
    "            \n",
    "    # 4. move experiment indexes\n",
    "    experiment_data.index = range(len(experiment_data.index))\n",
    "    \n",
    "    # 5. save experiment data\n",
    "    experiment_data.to_csv (path_csv)\n",
    "    experiment_data.to_pickle (path_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports tests.utils.test_organize_experiments\n",
    "def test_remove_experiments ():\n",
    "    generate_data ('remove_experiments')\n",
    "    \n",
    "    path_experiments = get_path_experiments ()\n",
    "    print (f'path_experiments: {path_experiments}\\n')\n",
    "    print (f'experiments content: {os.listdir(path_experiments)}\\n')\n",
    "    print (f'experiments inside: {os.listdir(f\"{path_experiments}/experiments\")}\\n')\n",
    "\n",
    "    experiments_data = pd.read_pickle (f'{path_experiments}/experiments_data.pk')\n",
    "    old_experiments_data = experiments_data\n",
    "    print (f'csv data index {experiments_data.index}\\n')\n",
    "    print ('csv content:')\n",
    "\n",
    "    remove_experiments (experiments=[3,7])\n",
    "\n",
    "    # we check that the remaining experiments do not contain number 3 or 7\n",
    "    experiment_folders = os.listdir(f\"{path_experiments}/experiments\")\n",
    "    print (f'experiment folders after removal: {experiment_folders}\\n')\n",
    "    assert len(experiment_folders)==7 and ('00007' not in experiment_folders) and ('00008' not in experiment_folders)\n",
    "\n",
    "    # we check that neither 3 nor 7 are in the new dataframe index\n",
    "    experiments_data = pd.read_pickle (f'{path_experiments}/experiments_data.pk')\n",
    "    print (f'csv data index after removal: {experiments_data.index}\\n')\n",
    "    assert (experiments_data.index==range(7)).all()\n",
    "\n",
    "    assert (experiments_data.loc[3] == old_experiments_data.loc[4]).all() and (experiments_data.loc[6] == old_experiments_data.loc[8]).all()\n",
    "    assert (experiments_data.loc[4] == old_experiments_data.loc[5]).all()\n",
    "\n",
    "    print ('csv content:')\n",
    "    experiments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "class2import not found, switching to original method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_remove_experiments\n",
      "path_experiments: test_remove_experiments\n",
      "\n",
      "experiments content: ['other_parameters.csv', 'git_hash.json', 'experiments_data.csv', 'current_experiment_number.pkl', 'experiments', 'parameters.pk', 'parameters.txt', 'experiments_data.pk', 'summary.txt']\n",
      "\n",
      "experiments inside: ['00000', '00002', '00004', '00007', '00006', '00008', '00003', '00005', '00001']\n",
      "\n",
      "csv data index RangeIndex(start=0, stop=9, step=1)\n",
      "\n",
      "csv content:\n",
      "experiment folders after removal: ['00000', '00002', '00004', '00006', '00003', '00005', '00001']\n",
      "\n",
      "csv data index after removal: RangeIndex(start=0, stop=7, step=1)\n",
      "\n",
      "csv content:\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_remove_experiments, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hpsearch)",
   "language": "python",
   "name": "hpsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
