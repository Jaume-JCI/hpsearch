{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp tools.rerun\n",
    "from nbdev.showdoc import *\n",
    "from dsblocks.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-run previous experiments with new parameters\n",
    "\n",
    "> Utility that allows to:\n",
    "> - Perform more runs on previous experiments, each run having a different random seed. \n",
    "> - Increase the number of epochs used in previous experiments, when NN models are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from hpsearch.config.hpconfig import get_experiment_manager\n",
    "import hpsearch.config.hp_defaults as dflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "import pytest\n",
    "import pandas as pd\n",
    "\n",
    "from hpsearch.examples.complex_dummy_experiment_manager import generate_data, init_em\n",
    "import hpsearch.utils.experiment_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def rerun (experiments=None, folder=None, epochs=None, runs=None, unfinished=False, \n",
    "           verbose=None, debug=False, em_attrs=None, store=False, from_dict=False, \n",
    "           range_exp=None, min_iterations=None, manager_path=dflt.manager_path):\n",
    "    em_args = dict(use_process=not debug)\n",
    "    if range_exp is not None:\n",
    "        assert len(range_exp) == 2\n",
    "        experiments += range(range_exp[0], range_exp[1])\n",
    "    \n",
    "    em = get_experiment_manager (manager_path=manager_path)\n",
    "    if folder is not None:\n",
    "        em.set_path_experiments (folder=folder)\n",
    "    if verbose is not None:\n",
    "        em.set_verbose (verbose)\n",
    "    if em_attrs is not None:\n",
    "        for k in em_attrs:\n",
    "            setattr (em, k, em_attrs[k])\n",
    "    \n",
    "    if epochs is not None:\n",
    "        parameters = {em.name_epoch: int(epochs)}\n",
    "        em_args.update (prev_epoch=True)\n",
    "        check_experiment_matches=False\n",
    "    else:\n",
    "        check_experiment_matches=True\n",
    "        parameters = {}\n",
    "    if unfinished:\n",
    "        em_args.update (check_finished=True, use_previous_best=False)\n",
    "    if store:\n",
    "        em_args.update (use_last_result=True)\n",
    "        if from_dict:\n",
    "            em_args.update (use_last_result_from_dict=True)\n",
    "        if min_iterations is not None:\n",
    "            em_args.update (min_iterations=min_iterations)\n",
    "    \n",
    "    \n",
    "    em.rerun_experiment (experiments=experiments, nruns=runs, \n",
    "                         parameters=parameters, check_experiment_matches=check_experiment_matches,\n",
    "                         **em_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse_arguments_and_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_args (args):\n",
    "    parser = argparse.ArgumentParser(description='run experiment')\n",
    "    parser.add_argument('-d', '--debug', action= \"store_true\")\n",
    "    parser.add_argument('-e', '--experiments', type=int, nargs='+', default=[],  help=\"experiment numbers\")\n",
    "    parser.add_argument('--range-exp', type=int, nargs='+', default=None, help='include this range of experiments')\n",
    "    parser.add_argument('--epochs', type=int, default=None,  help=\"number of epochs\")\n",
    "    parser.add_argument('-u', '--unfinished', action= \"store_true\")\n",
    "    parser.add_argument('--runs', type=int, default=None,  help=\"number of runs\")\n",
    "    parser.add_argument('-s', '--store', action= \"store_true\",  help=\"store the result from experiments that were not saved in csv file.\")\n",
    "    parser.add_argument('-f', '--from-dict', action= \"store_true\",  help=\"when storing the result from experiments that were not saved in csv file, we use the dictionary of results typically named dict_results.pk\")\n",
    "    parser.add_argument('--min-iterations', type=int, default=None,  help=\"number of iterations to be present in model history in order to consider the experiment good enough for storage.\")\n",
    "    parser.add_argument('--folder', type=str, default=None, help='name of experiments folder')\n",
    "    parser.add_argument('-v', '--verbose', type=int, default=None, help='verbosity level: 0, 1, 2')\n",
    "    parser.add_argument('-p', '--path', default=dflt.manager_path, type=str)\n",
    "    pars = parser.parse_args(args)\n",
    "    \n",
    "    return pars\n",
    "\n",
    "def parse_arguments_and_run (args, em_attrs = None):\n",
    "    \n",
    "    pars = parse_args(args)\n",
    "    pars = vars(pars)\n",
    "    pars['manager_path'] = pars['path']\n",
    "    del pars['path']\n",
    "    rerun (**pars, em_attrs=em_attrs)\n",
    "\n",
    "def main():\n",
    "    parse_arguments_and_run (sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### usage: performing more runs on previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.tools.test_rerun\n",
    "def test_parse_arguments_and_run_more_runs ():\n",
    "    em = generate_data ('parse_arguments_and_run_more_runs', \n",
    "                        folder='new_folder')\n",
    "    \n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(9,25)\n",
    "\n",
    "    args = ['-e', '4', '3', '--verbose', '1', '-p', em.manager_path]\n",
    "    parse_arguments_and_run (args)\n",
    "    em.raise_error_if_run=True\n",
    "    df = em.get_experiment_data ()\n",
    "    x=[f'{i}_validation_accuracy' for i in range(5)]; assert df.columns.isin(x).sum()==5\n",
    "    assert df.shape==(9,25)\n",
    "\n",
    "    args = ['-e', '4', '3', '--runs', '10', '-p', em.manager_path]\n",
    "    em.raise_error_if_run=False\n",
    "    parse_arguments_and_run (args)\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(9,45)\n",
    "    x=[f'{i}_validation_accuracy' for i in range(10)]; assert df.columns.isin(x).sum()==10\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_parse_arguments_and_run_more_runs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "self.root != self.root_folder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101735/457577691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_parse_arguments_and_run_more_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dummy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jaume/workspace/remote/ds-blocks/dsblocks/utils/nbdev_utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, test_func, data_func, do, include, debug, exclude, tag, show, store)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'running {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mtest_func\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_101735/3688882243.py\u001b[0m in \u001b[0;36mtest_parse_arguments_and_run_more_runs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export tests.tools.test_rerun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_parse_arguments_and_run_more_runs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     em = generate_data ('parse_arguments_and_run_more_runs', \n\u001b[0m\u001b[1;32m      4\u001b[0m                         root_folder='newroot')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaume/workspace/remote/hpsearch/hpsearch/examples/complex_dummy_experiment_manager.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(name_folder, nruns, noise, verbose_model, verbose, parameters_multiple_values, parameters_single_value, other_parameters, em_args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mpath_experiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'test_{name_folder}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mmanager_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{path_experiments}/managers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     em = ComplexDummyExperimentManager (path_experiments=path_experiments, manager_path=manager_path,\n\u001b[0m\u001b[1;32m    119\u001b[0m                                         verbose=verbose, **kwargs)\n\u001b[1;32m    120\u001b[0m     \u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_previous_experiments\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaume/workspace/remote/hpsearch/hpsearch/examples/complex_dummy_experiment_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_file_name, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_weights.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error_if_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesired_path_results_previous_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaume/workspace/remote/hpsearch/hpsearch/examples/dummy_experiment_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_experiments, root, metric, op, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_experiments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath_experiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{os.path.dirname(hpsearch.__file__)}/../results'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         super().__init__ (path_experiments=path_experiments,\n\u001b[0m\u001b[1;32m    141\u001b[0m                           \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                           \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaume/workspace/remote/hpsearch/hpsearch/experiment_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, allow_base_class, path_experiments, defaults, root, metric, op, alternative_root_path, path_data, name_model_history, model_file_name, name_epoch, result_file, target_model_file, destination_model_file, root_folder, manager_path, non_pickable_fields, avoid_saving_fields, logger, verbose, name_logger)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'self.root != self.root_folder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         self.registered_name = (f'{class_name}-default' if (self.root_folder is None\n",
      "\u001b[0;31mValueError\u001b[0m: self.root != self.root_folder"
     ]
    }
   ],
   "source": [
    "tst.run (test_parse_arguments_and_run_more_runs, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Increasing the number of epochs used in previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.tools.test_rerun\n",
    "def test_parse_arguments_and_run_more_epochs ():\n",
    "    em = init_em ('parse_arguments_and_run_more_epochs')\n",
    "\n",
    "    # get reference result\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 7})\n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    em.remove_previous_experiments()\n",
    "\n",
    "    # first 3 experiments\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.05, 'rate': 0.03, 'epochs': 6})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 9})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.05, 'rate': 0.03, 'epochs': 10})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 11})\n",
    "    df = em.get_experiment_data ()\n",
    "    display (df)\n",
    "    assert df.shape==(5,8)\n",
    "\n",
    "    # more epochs\n",
    "    #args = ['-e', '4', '3', '--epochs', '7', '-d']\n",
    "    args = ['-e', '3', '--epochs', '7', '-d', '-p', em.manager_path]\n",
    "    parse_arguments_and_run (\n",
    "        args, \n",
    "        em_attrs={'desired_path_results_previous_experiment':'test_parse_arguments_and_run_more_epochs/experiments/00001/0',\n",
    "                 'desired_epochs': 1, 'desired_current_epoch': 7}\n",
    "    )\n",
    "\n",
    "    df = em.get_experiment_data ()\n",
    "    print (df.shape)\n",
    "    assert df.shape==(6,8)\n",
    "    \n",
    "    args = ['-e', '4', '--epochs', '7', '-d', '-p', em.manager_path]\n",
    "    parse_arguments_and_run (\n",
    "        args, \n",
    "        em_args={'desired_path_results_previous_experiment':'test_parse_arguments_and_run_more_epochs/experiments/00000/0',\n",
    "                 'desired_epochs': 2, 'desired_current_epoch': 7}\n",
    "    )\n",
    "\n",
    "    df = em.get_experiment_data ()\n",
    "    print (df.shape)\n",
    "    assert df.shape==(7,8)\n",
    "    \n",
    "    # *****************************************\n",
    "    # *****************************************\n",
    "    em.remove_previous_experiments ()\n",
    "    em.desired_path_results_previous_experiment, em.desired_epochs, em.desired_current_epoch = None, None, None\n",
    "    # first 3 experiments\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 5})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.05, 'rate': 0.03, 'epochs': 6})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 9})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.05, 'rate': 0.03, 'epochs': 10})\n",
    "    _ = em.create_experiment_and_run (parameters={'offset':0.1, 'rate': 0.05, 'epochs': 11})\n",
    "    \n",
    "    args = ['-e', '4', '3', '--epochs', '7', '-d', '-p', em.manager_path]\n",
    "    parse_arguments_and_run (args)\n",
    "    df = em.get_experiment_data ()\n",
    "    print (df.shape)\n",
    "    assert df.shape==(7,8)\n",
    "    \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.run (test_parse_arguments_and_run_more_epochs, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Storing results from interrupted experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export tests.tools.test_rerun\n",
    "def test_parse_arguments_and_run_store ():\n",
    "    path_experiments = 'test_parse_arguments_and_run_store'\n",
    "    em = generate_data (path_experiments, \n",
    "                        folder='new_folder')\n",
    "\n",
    "    df = em.get_experiment_data ()\n",
    "    assert df.shape==(9,25)\n",
    "    columns = ut.get_scores_columns (df, class_ids=range(5), suffix_results='_validation_accuracy')\n",
    "    columns += ut.get_scores_columns (df, class_ids=range(5), suffix_results='_test_accuracy')\n",
    "\n",
    "    # *************************************************\n",
    "    # The following simulates the case where \n",
    "    # many experiments were not saved probably\n",
    "    # because they were interrupted with Ctrl-C\n",
    "    # *************************************************\n",
    "    df_orig = df.copy()\n",
    "    columns = ut.get_scores_columns (df_orig)\n",
    "    df[columns] = None\n",
    "    path = em.path_experiments\n",
    "    df.to_csv (path/'experiments_data.csv')\n",
    "    df.to_pickle (path/'experiments_data.pk')\n",
    "    df_overwritten = em.get_experiment_data ()\n",
    "    assert (df_orig[columns]!=df_overwritten[columns]).all().all()\n",
    "\n",
    "    parse_arguments_and_run ('--range-exp 0 9 --store --from-dict --runs 5 '\n",
    "                             f'--min-iterations 1 -p {em.manager_path}'.split())\n",
    "\n",
    "    df_new = em.get_experiment_data ()\n",
    "    # TODO: see why finished is False after storing\n",
    "    #assert (df_orig[columns]==df_new[columns]).all().all()\n",
    "    x, y = df_orig[columns].astype('float'), df_new[columns].astype('float')\n",
    "    y[[f'{x}_finished' for x in range(5)]]=1.0\n",
    "    pd.testing.assert_frame_equal(x,y)\n",
    "\n",
    "    df = df_orig.copy()\n",
    "    df.loc[1,columns] = None\n",
    "    df.loc[3:,columns] = None\n",
    "    df.to_csv (f'{path}/experiments_data.csv')\n",
    "    df.to_pickle (f'{path}/experiments_data.pk')\n",
    "    df_overwritten = em.get_experiment_data ()\n",
    "    #assert (df_orig[columns]==df_overwritten[columns]).sum().sum() == 20\n",
    "    # TODO: see why is the following true, instead of the previous:\n",
    "    #assert (df_orig[columns]==df_overwritten[columns]).sum().sum() == 30\n",
    "\n",
    "    parse_arguments_and_run ('--range-exp 0 9 --store --from-dict --runs 5 '\n",
    "                             f'--min-iterations 1 -p {em.manager_path}'.split())\n",
    "\n",
    "    df_new = em.get_experiment_data ()\n",
    "    #assert (df_orig[columns]==df_new[columns]).all().all()\n",
    "    x, y = df_orig[columns].astype('float'), df_new[columns].astype('float')\n",
    "    y[[f'{x}_finished' for x in range(5)]]=1.0\n",
    "    pd.testing.assert_frame_equal(x,y)\n",
    "\n",
    "    # *************************************************\n",
    "    # The following simulates the case where \n",
    "    # many experiments were not saved because\n",
    "    # experiments_data.csv and experiments_data.pk\n",
    "    # were overwritten by accident with an old file\n",
    "    # *************************************************\n",
    "    df = df_orig.copy()\n",
    "    df.loc[1,columns] = None\n",
    "    df = df.drop (index=range(3,9))\n",
    "    df.to_csv (f'{path}/experiments_data.csv')\n",
    "    df.to_pickle (f'{path}/experiments_data.pk')\n",
    "    df_overwritten = em.get_experiment_data ()\n",
    "    assert df_overwritten.shape==(3,25)\n",
    "\n",
    "    assert df_overwritten.isna().sum().sum()==15\n",
    "\n",
    "    parse_arguments_and_run ('--range-exp 0 9 --store --from-dict --runs 5 '\n",
    "                             f'--min-iterations 1 -p {em.manager_path}'.split())\n",
    "\n",
    "    df_new = em.get_experiment_data ()\n",
    "    #assert (df_orig[columns]==df_new[columns]).all().all()\n",
    "    x, y = df_orig[columns].astype('float'), df_new[columns].astype('float')\n",
    "    y[[f'{x}_finished' for x in range(5)]]=1.0\n",
    "    pd.testing.assert_frame_equal(x,y)\n",
    "    \n",
    "    # *************************************************\n",
    "    # The following unrealistic scenario produces an error\n",
    "    # For each row of an existing csv, we need to either have \n",
    "    # the parameters of that row, or not have the row at all.\n",
    "    # *************************************************\n",
    "    df_orig = df.copy()\n",
    "    df.iloc[1,:] = None\n",
    "    df.iloc[3:,:] = None\n",
    "\n",
    "    path = em.path_experiments\n",
    "\n",
    "    df.to_csv (path/'experiments_data.csv')\n",
    "    df.to_pickle (path/'experiments_data.pk')\n",
    "\n",
    "    with pytest.raises (ValueError):\n",
    "        parse_arguments_and_run (\n",
    "            f'--range-exp 0 9 --store --from-dict --runs 5 -p {em.manager_path}'.split()\n",
    "        )\n",
    "        \n",
    "    em.remove_previous_experiments ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.run (test_parse_arguments_and_run_store, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hpsearch)",
   "language": "python",
   "name": "hpsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
