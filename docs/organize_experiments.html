---

title: Organize experiments


keywords: fastai
sidebar: home_sidebar

summary: "Routines for organizing the experiments folders"
description: "Routines for organizing the experiments folders"
nb_path: "nbs/utils/organize_experiments.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/utils/organize_experiments.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="join_experiments" class="doc_header"><code>join_experiments</code><a href="https://github.com/Jaume-JCI/hpsearch/tree/master/hpsearch/utils/organize_experiments.py#L12" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>join_experiments</code>(<strong><code>path_source</code></strong>, <strong><code>path_destination</code></strong>, <strong><code>key_score</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="remove_defaults_from_experiment_data" class="doc_header"><code>remove_defaults_from_experiment_data</code><a href="https://github.com/Jaume-JCI/hpsearch/tree/master/hpsearch/utils/organize_experiments.py#L71" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>remove_defaults_from_experiment_data</code>(<strong><code>experiment_data</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="remove_experiments" class="doc_header"><code>remove_experiments</code><a href="https://github.com/Jaume-JCI/hpsearch/tree/master/hpsearch/utils/organize_experiments.py#L103" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>remove_experiments</code>(<strong><code>experiments</code></strong>=<em><code>[]</code></em>, <strong><code>root_path</code></strong>=<em><code>None</code></em>, <strong><code>root_folder</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usage-example">Usage example<a class="anchor-link" href="#Usage-example"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Produce-data">Produce data<a class="anchor-link" href="#Produce-data"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">hpsearch.examples.dummy_experiment_manager</span> <span class="kn">import</span> <span class="n">remove_previous_experiments</span><span class="p">,</span> <span class="n">run_multiple_experiments</span>

<span class="n">remove_previous_experiments</span><span class="p">()</span>
<span class="n">run_multiple_experiments</span><span class="p">(</span><span class="n">nruns</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary data-open="Hide Output" data-close="Show Output"></summary>
        <summary></summary>
        
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>experiment script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line: 201
processing hyper-parameter 0 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 0
run number: 0

parameters:
	epochs=5,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009300708770751953
0 - validation_accuracy: 0.39818992477057
0 - test_accuracy: 0.5030049616919423
finished experiment 0
processing hyper-parameter 0 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 0
run number: 1

parameters:
	epochs=5,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009531974792480469
1 - validation_accuracy: 0.2375319443046206
1 - test_accuracy: 0.36513440595343305
finished experiment 0
processing hyper-parameter 0 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 0
run number: 2

parameters:
	epochs=5,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0008437633514404297
2 - validation_accuracy: 0.34427615496868985
2 - test_accuracy: 0.43556425391199405
finished experiment 0
processing hyper-parameter 0 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 0
run number: 3

parameters:
	epochs=5,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0008559226989746094
3 - validation_accuracy: 0.28802358813290185
3 - test_accuracy: 0.3242409934735058
finished experiment 0
processing hyper-parameter 0 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 0
run number: 4

parameters:
	epochs=5,
	noise=0.1,
	offset=0.1,
	rate=0.03

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>current path: /mnt/athena/hpsearch/nbs/utils
current path: /mnt/athena/hpsearch/nbs/utils
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009417533874511719
4 - validation_accuracy: 0.12371940103658746
4 - test_accuracy: 0.3411245339321954
finished experiment 0
processing hyper-parameter 1 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 1
run number: 0

parameters:
	epochs=5,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0008573532104492188
0 - validation_accuracy: 0.3792321065908727
0 - test_accuracy: 0.6546671705439889
finished experiment 1
processing hyper-parameter 1 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 1
run number: 1

parameters:
	epochs=5,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0010080337524414062
1 - validation_accuracy: 0.7451916165807193
1 - test_accuracy: 0.6351939575570454
finished experiment 1
processing hyper-parameter 1 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 1
run number: 2

parameters:
	epochs=5,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009734630584716797
2 - validation_accuracy: 0.30338697079864274
2 - test_accuracy: 0.5091540668232125
finished experiment 1
processing hyper-parameter 1 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 1
run number: 3

parameters:
	epochs=5,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0008924007415771484
3 - validation_accuracy: 0.426477583700882
3 - test_accuracy: 0.5580341973894007
finished experiment 1
processing hyper-parameter 1 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 5 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 1
run number: 4

parameters:
	epochs=5,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009436607360839844
4 - validation_accuracy: 0.4785422692285996
4 - test_accuracy: 0.5414592350384044
finished experiment 1
processing hyper-parameter 2 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 2
run number: 0

parameters:
	epochs=5,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0008647441864013672
0 - validation_accuracy: 0.7177950492870028
0 - test_accuracy: 0.8167067183795961
finished experiment 2
processing hyper-parameter 2 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 2
run number: 1

parameters:
	epochs=5,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0011663436889648438
1 - validation_accuracy: 0.6970479370844503
1 - test_accuracy: 0.7230022057931769
finished experiment 2
processing hyper-parameter 2 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 2
run number: 2

parameters:
	epochs=5,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009162425994873047
2 - validation_accuracy: 0.8622267072499568
2 - test_accuracy: 1.0
finished experiment 2
processing hyper-parameter 2 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 2
run number: 3

parameters:
	epochs=5,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009586811065673828
3 - validation_accuracy: 0.597638330484685
3 - test_accuracy: 0.8397938186237429
finished experiment 2
processing hyper-parameter 2 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 5 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 5 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 2
run number: 4

parameters:
	epochs=5,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0009493827819824219
4 - validation_accuracy: 0.8351258362537483
4 - test_accuracy: 0.6642193891134404
finished experiment 2
processing hyper-parameter 3 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 3
run number: 0

parameters:
	epochs=15,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0018765926361083984
0 - validation_accuracy: 0.7958398455949138
0 - test_accuracy: 0.3834165827055104
finished experiment 3
processing hyper-parameter 3 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 3
run number: 1

parameters:
	epochs=15,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0020904541015625
1 - validation_accuracy: 0.6842750340333574
1 - test_accuracy: 0.6361905567353944
finished experiment 3
processing hyper-parameter 3 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 3
run number: 2

parameters:
	epochs=15,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0020377635955810547
2 - validation_accuracy: 0.54825331281157
2 - test_accuracy: 0.2358643642906358
finished experiment 3
processing hyper-parameter 3 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 3
run number: 3

parameters:
	epochs=15,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0023751258850097656
3 - validation_accuracy: 0.39763199413408856
3 - test_accuracy: 0.40216948059404356
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 5 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>finished experiment 3
processing hyper-parameter 3 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 3
run number: 4

parameters:
	epochs=15,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0018706321716308594
4 - validation_accuracy: 0.5526095826600849
4 - test_accuracy: 0.4575187865623697
finished experiment 3
processing hyper-parameter 4 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 4
run number: 0

parameters:
	epochs=15,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.001913309097290039
0 - validation_accuracy: 0.7386886622679263
0 - test_accuracy: 0.709655235664695
finished experiment 4
processing hyper-parameter 4 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 4
run number: 1

parameters:
	epochs=15,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0021820068359375
1 - validation_accuracy: 0.6325544633831149
1 - test_accuracy: 0.7355869404012073
finished experiment 4
processing hyper-parameter 4 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 4
run number: 2

parameters:
	epochs=15,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.001827239990234375
2 - validation_accuracy: 0.79302130973968
2 - test_accuracy: 0.6348156111642492
finished experiment 4
processing hyper-parameter 4 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 4
run number: 3

parameters:
	epochs=15,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.001957416534423828
3 - validation_accuracy: 0.8547706593353122
3 - test_accuracy: 0.8302980004054916
finished experiment 4
processing hyper-parameter 4 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 4
run number: 4

parameters:
	epochs=15,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0018985271453857422
4 - validation_accuracy: 0.6619535570527927
4 - test_accuracy: 0.5507942290709636
finished experiment 4
processing hyper-parameter 5 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 5
run number: 0

parameters:
	epochs=15,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0018804073333740234
0 - validation_accuracy: 0.8967267293202953
0 - test_accuracy: 0.9122376811535008
finished experiment 5
processing hyper-parameter 5 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 5
run number: 1

parameters:
	epochs=15,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.002163410186767578
1 - validation_accuracy: 1.0
1 - test_accuracy: 1.0
finished experiment 5
processing hyper-parameter 5 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 5
run number: 2

parameters:
	epochs=15,
	noise=0.1,
	offset=0.6,
	rate=0.03

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 15 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0019512176513671875
2 - validation_accuracy: 0.7614828220473973
2 - test_accuracy: 1.0
finished experiment 5
processing hyper-parameter 5 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 5
run number: 3

parameters:
	epochs=15,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0019278526306152344
3 - validation_accuracy: 1.0
3 - test_accuracy: 1.0
finished experiment 5
processing hyper-parameter 5 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 5
run number: 4

parameters:
	epochs=15,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0018982887268066406
4 - validation_accuracy: 0.9490927602107447
4 - test_accuracy: 1.0
finished experiment 5
processing hyper-parameter 6 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 6
run number: 0

parameters:
	epochs=30,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0035088062286376953
0 - validation_accuracy: 0.2687269269562088
0 - test_accuracy: 0.1903807384272462
finished experiment 6
processing hyper-parameter 6 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 6
run number: 1

parameters:
	epochs=30,
	noise=0.1,
	offset=0.1,
	rate=0.03

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 15 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 15 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
epoch 15: accuracy: 0.5800000000000003
epoch 16: accuracy: 0.6100000000000003
epoch 17: accuracy: 0.6400000000000003
epoch 18: accuracy: 0.6700000000000004
epoch 19: accuracy: 0.7000000000000004
epoch 20: accuracy: 0.6700000000000004
epoch 21: accuracy: 0.6400000000000003
epoch 22: accuracy: 0.6100000000000003
epoch 23: accuracy: 0.5800000000000003
epoch 24: accuracy: 0.5500000000000003
epoch 25: accuracy: 0.5200000000000002
epoch 26: accuracy: 0.4900000000000002
epoch 27: accuracy: 0.4600000000000002
epoch 28: accuracy: 0.43000000000000016
epoch 29: accuracy: 0.40000000000000013
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0031890869140625
1 - validation_accuracy: 0.19153350840448907
1 - test_accuracy: 0.4227502498994028
finished experiment 6
processing hyper-parameter 6 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 6
run number: 2

parameters:
	epochs=30,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003171205520629883
2 - validation_accuracy: 0.47748214945720446
2 - test_accuracy: 0.3542913477435472
finished experiment 6
processing hyper-parameter 6 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 6
run number: 3

parameters:
	epochs=30,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003209352493286133
3 - validation_accuracy: 0.458991175226002
3 - test_accuracy: 0.2814268561643957
finished experiment 6
processing hyper-parameter 6 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 6
run number: 4

parameters:
	epochs=30,
	noise=0.1,
	offset=0.1,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0034584999084472656
4 - validation_accuracy: 0.37907896289504817
4 - test_accuracy: 0.4310441873855486
finished experiment 6
processing hyper-parameter 7 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 30 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
epoch 15: accuracy: 0.5800000000000003
epoch 16: accuracy: 0.6100000000000003
epoch 17: accuracy: 0.6400000000000003
epoch 18: accuracy: 0.6700000000000004
epoch 19: accuracy: 0.7000000000000004
epoch 20: accuracy: 0.6700000000000004
epoch 21: accuracy: 0.6400000000000003
epoch 22: accuracy: 0.6100000000000003
epoch 23: accuracy: 0.5800000000000003
epoch 24: accuracy: 0.5500000000000003
epoch 25: accuracy: 0.5200000000000002
epoch 26: accuracy: 0.4900000000000002
epoch 27: accuracy: 0.4600000000000002
epoch 28: accuracy: 0.43000000000000016
epoch 29: accuracy: 0.40000000000000013
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
epoch 15: accuracy: 0.5800000000000003
epoch 16: accuracy: 0.6100000000000003
epoch 17: accuracy: 0.6400000000000003
epoch 18: accuracy: 0.6700000000000004
epoch 19: accuracy: 0.7000000000000004
epoch 20: accuracy: 0.6700000000000004
epoch 21: accuracy: 0.6400000000000003
epoch 22: accuracy: 0.6100000000000003
epoch 23: accuracy: 0.5800000000000003
epoch 24: accuracy: 0.5500000000000003
epoch 25: accuracy: 0.5200000000000002
epoch 26: accuracy: 0.4900000000000002
epoch 27: accuracy: 0.4600000000000002
epoch 28: accuracy: 0.43000000000000016
epoch 29: accuracy: 0.40000000000000013
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
epoch 15: accuracy: 0.5800000000000003
epoch 16: accuracy: 0.6100000000000003
epoch 17: accuracy: 0.6400000000000003
epoch 18: accuracy: 0.6700000000000004
epoch 19: accuracy: 0.7000000000000004
epoch 20: accuracy: 0.6700000000000004
epoch 21: accuracy: 0.6400000000000003
epoch 22: accuracy: 0.6100000000000003
epoch 23: accuracy: 0.5800000000000003
epoch 24: accuracy: 0.5500000000000003
epoch 25: accuracy: 0.5200000000000002
epoch 26: accuracy: 0.4900000000000002
epoch 27: accuracy: 0.4600000000000002
epoch 28: accuracy: 0.43000000000000016
epoch 29: accuracy: 0.40000000000000013
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.13
epoch 1: accuracy: 0.16
epoch 2: accuracy: 0.19
epoch 3: accuracy: 0.22
epoch 4: accuracy: 0.25
epoch 5: accuracy: 0.28
epoch 6: accuracy: 0.31000000000000005
epoch 7: accuracy: 0.3400000000000001
epoch 8: accuracy: 0.3700000000000001
epoch 9: accuracy: 0.40000000000000013
epoch 10: accuracy: 0.43000000000000016
epoch 11: accuracy: 0.4600000000000002
epoch 12: accuracy: 0.4900000000000002
epoch 13: accuracy: 0.5200000000000002
epoch 14: accuracy: 0.5500000000000003
epoch 15: accuracy: 0.5800000000000003
epoch 16: accuracy: 0.6100000000000003
epoch 17: accuracy: 0.6400000000000003
epoch 18: accuracy: 0.6700000000000004
epoch 19: accuracy: 0.7000000000000004
epoch 20: accuracy: 0.6700000000000004
epoch 21: accuracy: 0.6400000000000003
epoch 22: accuracy: 0.6100000000000003
epoch 23: accuracy: 0.5800000000000003
epoch 24: accuracy: 0.5500000000000003
epoch 25: accuracy: 0.5200000000000002
epoch 26: accuracy: 0.4900000000000002
epoch 27: accuracy: 0.4600000000000002
epoch 28: accuracy: 0.43000000000000016
epoch 29: accuracy: 0.40000000000000013
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 7
run number: 0

parameters:
	epochs=30,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003395557403564453
0 - validation_accuracy: 0.6581418317309614
0 - test_accuracy: 0.533260020449676
finished experiment 7
processing hyper-parameter 7 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 7
run number: 1

parameters:
	epochs=30,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0032510757446289062
1 - validation_accuracy: 0.7902483102641822
1 - test_accuracy: 0.3242629172630299
finished experiment 7
processing hyper-parameter 7 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 7
run number: 2

parameters:
	epochs=30,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003275156021118164
2 - validation_accuracy: 0.5864351589716177
2 - test_accuracy: 0.6561407410789145
finished experiment 7
processing hyper-parameter 7 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
running experiment 7
run number: 3

parameters:
	epochs=30,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0034203529357910156
3 - validation_accuracy: 0.6696011513062484
3 - test_accuracy: 0.5424515853570778
finished experiment 7
processing hyper-parameter 7 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 30 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
epoch 15: accuracy: 0.7800000000000004
epoch 16: accuracy: 0.8100000000000004
epoch 17: accuracy: 0.8400000000000004
epoch 18: accuracy: 0.8700000000000004
epoch 19: accuracy: 0.9000000000000005
epoch 20: accuracy: 0.8700000000000004
epoch 21: accuracy: 0.8400000000000004
epoch 22: accuracy: 0.8100000000000004
epoch 23: accuracy: 0.7800000000000004
epoch 24: accuracy: 0.7500000000000003
epoch 25: accuracy: 0.7200000000000003
epoch 26: accuracy: 0.6900000000000003
epoch 27: accuracy: 0.6600000000000003
epoch 28: accuracy: 0.6300000000000002
epoch 29: accuracy: 0.6000000000000002
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
epoch 15: accuracy: 0.7800000000000004
epoch 16: accuracy: 0.8100000000000004
epoch 17: accuracy: 0.8400000000000004
epoch 18: accuracy: 0.8700000000000004
epoch 19: accuracy: 0.9000000000000005
epoch 20: accuracy: 0.8700000000000004
epoch 21: accuracy: 0.8400000000000004
epoch 22: accuracy: 0.8100000000000004
epoch 23: accuracy: 0.7800000000000004
epoch 24: accuracy: 0.7500000000000003
epoch 25: accuracy: 0.7200000000000003
epoch 26: accuracy: 0.6900000000000003
epoch 27: accuracy: 0.6600000000000003
epoch 28: accuracy: 0.6300000000000002
epoch 29: accuracy: 0.6000000000000002
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
epoch 15: accuracy: 0.7800000000000004
epoch 16: accuracy: 0.8100000000000004
epoch 17: accuracy: 0.8400000000000004
epoch 18: accuracy: 0.8700000000000004
epoch 19: accuracy: 0.9000000000000005
epoch 20: accuracy: 0.8700000000000004
epoch 21: accuracy: 0.8400000000000004
epoch 22: accuracy: 0.8100000000000004
epoch 23: accuracy: 0.7800000000000004
epoch 24: accuracy: 0.7500000000000003
epoch 25: accuracy: 0.7200000000000003
epoch 26: accuracy: 0.6900000000000003
epoch 27: accuracy: 0.6600000000000003
epoch 28: accuracy: 0.6300000000000002
epoch 29: accuracy: 0.6000000000000002
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
epoch 15: accuracy: 0.7800000000000004
epoch 16: accuracy: 0.8100000000000004
epoch 17: accuracy: 0.8400000000000004
epoch 18: accuracy: 0.8700000000000004
epoch 19: accuracy: 0.9000000000000005
epoch 20: accuracy: 0.8700000000000004
epoch 21: accuracy: 0.8400000000000004
epoch 22: accuracy: 0.8100000000000004
epoch 23: accuracy: 0.7800000000000004
epoch 24: accuracy: 0.7500000000000003
epoch 25: accuracy: 0.7200000000000003
epoch 26: accuracy: 0.6900000000000003
epoch 27: accuracy: 0.6600000000000003
epoch 28: accuracy: 0.6300000000000002
epoch 29: accuracy: 0.6000000000000002
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 7
run number: 4

parameters:
	epochs=30,
	noise=0.1,
	offset=0.3,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003377199172973633
4 - validation_accuracy: 0.7581533238280647
4 - test_accuracy: 0.460380786978612
finished experiment 7
processing hyper-parameter 8 out of 9
doing run 0 out of 5
fixed rate, multiple epochs values
running experiment 8
run number: 0

parameters:
	epochs=30,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003300189971923828
0 - validation_accuracy: 0.9462807447804227
0 - test_accuracy: 0.8023390144087101
finished experiment 8
processing hyper-parameter 8 out of 9
doing run 1 out of 5
fixed rate, multiple epochs values
running experiment 8
run number: 1

parameters:
	epochs=30,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003201723098754883
1 - validation_accuracy: 0.8995285846324479
1 - test_accuracy: 0.735299954627971
finished experiment 8
processing hyper-parameter 8 out of 9
doing run 2 out of 5
fixed rate, multiple epochs values
running experiment 8
run number: 2

parameters:
	epochs=30,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003557443618774414
2 - validation_accuracy: 0.8576829403464957
2 - test_accuracy: 0.7773070012242608
finished experiment 8
processing hyper-parameter 8 out of 9
doing run 3 out of 5
fixed rate, multiple epochs values
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 30 epochs
epoch 0: accuracy: 0.32999999999999996
epoch 1: accuracy: 0.36
epoch 2: accuracy: 0.39
epoch 3: accuracy: 0.42000000000000004
epoch 4: accuracy: 0.45000000000000007
epoch 5: accuracy: 0.4800000000000001
epoch 6: accuracy: 0.5100000000000001
epoch 7: accuracy: 0.5400000000000001
epoch 8: accuracy: 0.5700000000000002
epoch 9: accuracy: 0.6000000000000002
epoch 10: accuracy: 0.6300000000000002
epoch 11: accuracy: 0.6600000000000003
epoch 12: accuracy: 0.6900000000000003
epoch 13: accuracy: 0.7200000000000003
epoch 14: accuracy: 0.7500000000000003
epoch 15: accuracy: 0.7800000000000004
epoch 16: accuracy: 0.8100000000000004
epoch 17: accuracy: 0.8400000000000004
epoch 18: accuracy: 0.8700000000000004
epoch 19: accuracy: 0.9000000000000005
epoch 20: accuracy: 0.8700000000000004
epoch 21: accuracy: 0.8400000000000004
epoch 22: accuracy: 0.8100000000000004
epoch 23: accuracy: 0.7800000000000004
epoch 24: accuracy: 0.7500000000000003
epoch 25: accuracy: 0.7200000000000003
epoch 26: accuracy: 0.6900000000000003
epoch 27: accuracy: 0.6600000000000003
epoch 28: accuracy: 0.6300000000000002
epoch 29: accuracy: 0.6000000000000002
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
epoch 15: accuracy: 1.0800000000000003
epoch 16: accuracy: 1.1100000000000003
epoch 17: accuracy: 1.1400000000000003
epoch 18: accuracy: 1.1700000000000004
epoch 19: accuracy: 1.2000000000000004
epoch 20: accuracy: 1.1700000000000004
epoch 21: accuracy: 1.1400000000000003
epoch 22: accuracy: 1.1100000000000003
epoch 23: accuracy: 1.0800000000000003
epoch 24: accuracy: 1.0500000000000003
epoch 25: accuracy: 1.0200000000000002
epoch 26: accuracy: 0.9900000000000002
epoch 27: accuracy: 0.9600000000000002
epoch 28: accuracy: 0.9300000000000002
epoch 29: accuracy: 0.9000000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
epoch 15: accuracy: 1.0800000000000003
epoch 16: accuracy: 1.1100000000000003
epoch 17: accuracy: 1.1400000000000003
epoch 18: accuracy: 1.1700000000000004
epoch 19: accuracy: 1.2000000000000004
epoch 20: accuracy: 1.1700000000000004
epoch 21: accuracy: 1.1400000000000003
epoch 22: accuracy: 1.1100000000000003
epoch 23: accuracy: 1.0800000000000003
epoch 24: accuracy: 1.0500000000000003
epoch 25: accuracy: 1.0200000000000002
epoch 26: accuracy: 0.9900000000000002
epoch 27: accuracy: 0.9600000000000002
epoch 28: accuracy: 0.9300000000000002
epoch 29: accuracy: 0.9000000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
epoch 15: accuracy: 1.0800000000000003
epoch 16: accuracy: 1.1100000000000003
epoch 17: accuracy: 1.1400000000000003
epoch 18: accuracy: 1.1700000000000004
epoch 19: accuracy: 1.2000000000000004
epoch 20: accuracy: 1.1700000000000004
epoch 21: accuracy: 1.1400000000000003
epoch 22: accuracy: 1.1100000000000003
epoch 23: accuracy: 1.0800000000000003
epoch 24: accuracy: 1.0500000000000003
epoch 25: accuracy: 1.0200000000000002
epoch 26: accuracy: 0.9900000000000002
epoch 27: accuracy: 0.9600000000000002
epoch 28: accuracy: 0.9300000000000002
epoch 29: accuracy: 0.9000000000000001
current path: /mnt/athena/hpsearch/nbs/utils
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>running experiment 8
run number: 3

parameters:
	epochs=30,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.0033392906188964844
3 - validation_accuracy: 0.8484903385387791
3 - test_accuracy: 0.7103962847313978
finished experiment 8
processing hyper-parameter 8 out of 9
doing run 4 out of 5
fixed rate, multiple epochs values
running experiment 8
run number: 4

parameters:
	epochs=30,
	noise=0.1,
	offset=0.6,
	rate=0.03

script: /mnt/athena/hpsearch/hpsearch/examples/dummy_experiment_manager.py, line number: 201
time spent on this experiment: 0.003292083740234375
4 - validation_accuracy: 0.7977704861745482
4 - test_accuracy: 0.9997575149738822
finished experiment 8
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fitting model with 30 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
epoch 15: accuracy: 1.0800000000000003
epoch 16: accuracy: 1.1100000000000003
epoch 17: accuracy: 1.1400000000000003
epoch 18: accuracy: 1.1700000000000004
epoch 19: accuracy: 1.2000000000000004
epoch 20: accuracy: 1.1700000000000004
epoch 21: accuracy: 1.1400000000000003
epoch 22: accuracy: 1.1100000000000003
epoch 23: accuracy: 1.0800000000000003
epoch 24: accuracy: 1.0500000000000003
epoch 25: accuracy: 1.0200000000000002
epoch 26: accuracy: 0.9900000000000002
epoch 27: accuracy: 0.9600000000000002
epoch 28: accuracy: 0.9300000000000002
epoch 29: accuracy: 0.9000000000000001
current path: /mnt/athena/hpsearch/nbs/utils
fitting model with 30 epochs
epoch 0: accuracy: 0.63
epoch 1: accuracy: 0.66
epoch 2: accuracy: 0.6900000000000001
epoch 3: accuracy: 0.7200000000000001
epoch 4: accuracy: 0.7500000000000001
epoch 5: accuracy: 0.7800000000000001
epoch 6: accuracy: 0.8100000000000002
epoch 7: accuracy: 0.8400000000000002
epoch 8: accuracy: 0.8700000000000002
epoch 9: accuracy: 0.9000000000000002
epoch 10: accuracy: 0.9300000000000003
epoch 11: accuracy: 0.9600000000000003
epoch 12: accuracy: 0.9900000000000003
epoch 13: accuracy: 1.0200000000000002
epoch 14: accuracy: 1.0500000000000003
epoch 15: accuracy: 1.0800000000000003
epoch 16: accuracy: 1.1100000000000003
epoch 17: accuracy: 1.1400000000000003
epoch 18: accuracy: 1.1700000000000004
epoch 19: accuracy: 1.2000000000000004
epoch 20: accuracy: 1.1700000000000004
epoch 21: accuracy: 1.1400000000000003
epoch 22: accuracy: 1.1100000000000003
epoch 23: accuracy: 1.0800000000000003
epoch 24: accuracy: 1.0500000000000003
epoch 25: accuracy: 1.0200000000000002
epoch 26: accuracy: 0.9900000000000002
epoch 27: accuracy: 0.9600000000000002
epoch 28: accuracy: 0.9300000000000002
epoch 29: accuracy: 0.9000000000000001
</pre>
</div>
</div>

</div>
</div>

    </details>
</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">hpsearch.config.hpconfig</span> <span class="kn">import</span> <span class="n">get_path_experiments</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">path_experiments</span> <span class="o">=</span> <span class="n">get_path_experiments</span> <span class="p">()</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;path_experiments: </span><span class="si">{</span><span class="n">path_experiments</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;experiments content: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_experiments</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;experiments inside: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path_experiments</span><span class="si">}</span><span class="s2">/experiments&quot;</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">experiments_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">path_experiments</span><span class="si">}</span><span class="s1">/experiments_data.pk&#39;</span><span class="p">)</span>
<span class="n">old_experiments_data</span> <span class="o">=</span> <span class="n">experiments_data</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;csv data index </span><span class="si">{</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">index</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;csv content:&#39;</span><span class="p">)</span>
<span class="n">experiments_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>path_experiments: /mnt/athena/hpsearch/hpsearch/../results

experiments content: [&#39;experiments_data.pk&#39;, &#39;current_experiment_number.pkl&#39;, &#39;summary.txt&#39;, &#39;experiments&#39;, &#39;git_hash.json&#39;, &#39;experiments_data.csv&#39;, &#39;logs.txt&#39;, &#39;parameters.pk&#39;, &#39;other_parameters.csv&#39;, &#39;parameters.txt&#39;]

experiments inside: [&#39;00000&#39;, &#39;00008&#39;, &#39;00005&#39;, &#39;00006&#39;, &#39;00002&#39;, &#39;00004&#39;, &#39;00001&#39;, &#39;00007&#39;, &#39;00003&#39;]

csv data index RangeIndex(start=0, stop=9, step=1)

csv content:
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>noise</th>
      <th>offset</th>
      <th>rate</th>
      <th>0_validation_accuracy</th>
      <th>0_test_accuracy</th>
      <th>time_0</th>
      <th>date</th>
      <th>0_finished</th>
      <th>1_validation_accuracy</th>
      <th>...</th>
      <th>time_2</th>
      <th>2_finished</th>
      <th>3_validation_accuracy</th>
      <th>3_test_accuracy</th>
      <th>time_3</th>
      <th>3_finished</th>
      <th>4_validation_accuracy</th>
      <th>4_test_accuracy</th>
      <th>time_4</th>
      <th>4_finished</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.398190</td>
      <td>0.503005</td>
      <td>0.001472</td>
      <td>15:43:50.843200</td>
      <td>True</td>
      <td>0.237532</td>
      <td>...</td>
      <td>0.001378</td>
      <td>True</td>
      <td>0.288024</td>
      <td>0.324241</td>
      <td>0.001403</td>
      <td>True</td>
      <td>0.123719</td>
      <td>0.341125</td>
      <td>0.001447</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.379232</td>
      <td>0.654667</td>
      <td>0.001369</td>
      <td>15:43:51.064255</td>
      <td>True</td>
      <td>0.745192</td>
      <td>...</td>
      <td>0.001507</td>
      <td>True</td>
      <td>0.426478</td>
      <td>0.558034</td>
      <td>0.001398</td>
      <td>True</td>
      <td>0.478542</td>
      <td>0.541459</td>
      <td>0.001453</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.717795</td>
      <td>0.816707</td>
      <td>0.001388</td>
      <td>15:43:51.283737</td>
      <td>True</td>
      <td>0.697048</td>
      <td>...</td>
      <td>0.001457</td>
      <td>True</td>
      <td>0.597638</td>
      <td>0.839794</td>
      <td>0.001464</td>
      <td>True</td>
      <td>0.835126</td>
      <td>0.664219</td>
      <td>0.001474</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.795840</td>
      <td>0.383417</td>
      <td>0.002422</td>
      <td>15:43:51.515454</td>
      <td>True</td>
      <td>0.684275</td>
      <td>...</td>
      <td>0.002560</td>
      <td>True</td>
      <td>0.397632</td>
      <td>0.402169</td>
      <td>0.002899</td>
      <td>True</td>
      <td>0.552610</td>
      <td>0.457519</td>
      <td>0.002405</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.738689</td>
      <td>0.709655</td>
      <td>0.002459</td>
      <td>15:43:51.759312</td>
      <td>True</td>
      <td>0.632554</td>
      <td>...</td>
      <td>0.002354</td>
      <td>True</td>
      <td>0.854771</td>
      <td>0.830298</td>
      <td>0.002466</td>
      <td>True</td>
      <td>0.661954</td>
      <td>0.550794</td>
      <td>0.002438</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.896727</td>
      <td>0.912238</td>
      <td>0.002409</td>
      <td>15:43:52.010218</td>
      <td>True</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.002463</td>
      <td>True</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.002443</td>
      <td>True</td>
      <td>0.949093</td>
      <td>1.000000</td>
      <td>0.002416</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.268727</td>
      <td>0.190381</td>
      <td>0.004025</td>
      <td>15:43:52.275762</td>
      <td>True</td>
      <td>0.191534</td>
      <td>...</td>
      <td>0.003689</td>
      <td>True</td>
      <td>0.458991</td>
      <td>0.281427</td>
      <td>0.003723</td>
      <td>True</td>
      <td>0.379079</td>
      <td>0.431044</td>
      <td>0.003976</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.658142</td>
      <td>0.533260</td>
      <td>0.003903</td>
      <td>15:43:52.560892</td>
      <td>True</td>
      <td>0.790248</td>
      <td>...</td>
      <td>0.003795</td>
      <td>True</td>
      <td>0.669601</td>
      <td>0.542452</td>
      <td>0.003951</td>
      <td>True</td>
      <td>0.758153</td>
      <td>0.460381</td>
      <td>0.004018</td>
      <td>True</td>
    </tr>
    <tr>
      <th>8</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.946281</td>
      <td>0.802339</td>
      <td>0.003829</td>
      <td>15:43:52.846902</td>
      <td>True</td>
      <td>0.899529</td>
      <td>...</td>
      <td>0.004088</td>
      <td>True</td>
      <td>0.848490</td>
      <td>0.710396</td>
      <td>0.003877</td>
      <td>True</td>
      <td>0.797770</td>
      <td>0.999758</td>
      <td>0.003820</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Removing-experiments">Removing experiments<a class="anchor-link" href="#Removing-experiments"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">remove_experiments</span> <span class="p">(</span><span class="n">experiments</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">old_experiments_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>noise</th>
      <th>offset</th>
      <th>rate</th>
      <th>0_validation_accuracy</th>
      <th>0_test_accuracy</th>
      <th>time_0</th>
      <th>date</th>
      <th>0_finished</th>
      <th>1_validation_accuracy</th>
      <th>...</th>
      <th>time_2</th>
      <th>2_finished</th>
      <th>3_validation_accuracy</th>
      <th>3_test_accuracy</th>
      <th>time_3</th>
      <th>3_finished</th>
      <th>4_validation_accuracy</th>
      <th>4_test_accuracy</th>
      <th>time_4</th>
      <th>4_finished</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.398190</td>
      <td>0.503005</td>
      <td>0.001472</td>
      <td>15:43:50.843200</td>
      <td>True</td>
      <td>0.237532</td>
      <td>...</td>
      <td>0.001378</td>
      <td>True</td>
      <td>0.288024</td>
      <td>0.324241</td>
      <td>0.001403</td>
      <td>True</td>
      <td>0.123719</td>
      <td>0.341125</td>
      <td>0.001447</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.379232</td>
      <td>0.654667</td>
      <td>0.001369</td>
      <td>15:43:51.064255</td>
      <td>True</td>
      <td>0.745192</td>
      <td>...</td>
      <td>0.001507</td>
      <td>True</td>
      <td>0.426478</td>
      <td>0.558034</td>
      <td>0.001398</td>
      <td>True</td>
      <td>0.478542</td>
      <td>0.541459</td>
      <td>0.001453</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.717795</td>
      <td>0.816707</td>
      <td>0.001388</td>
      <td>15:43:51.283737</td>
      <td>True</td>
      <td>0.697048</td>
      <td>...</td>
      <td>0.001457</td>
      <td>True</td>
      <td>0.597638</td>
      <td>0.839794</td>
      <td>0.001464</td>
      <td>True</td>
      <td>0.835126</td>
      <td>0.664219</td>
      <td>0.001474</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.795840</td>
      <td>0.383417</td>
      <td>0.002422</td>
      <td>15:43:51.515454</td>
      <td>True</td>
      <td>0.684275</td>
      <td>...</td>
      <td>0.002560</td>
      <td>True</td>
      <td>0.397632</td>
      <td>0.402169</td>
      <td>0.002899</td>
      <td>True</td>
      <td>0.552610</td>
      <td>0.457519</td>
      <td>0.002405</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.738689</td>
      <td>0.709655</td>
      <td>0.002459</td>
      <td>15:43:51.759312</td>
      <td>True</td>
      <td>0.632554</td>
      <td>...</td>
      <td>0.002354</td>
      <td>True</td>
      <td>0.854771</td>
      <td>0.830298</td>
      <td>0.002466</td>
      <td>True</td>
      <td>0.661954</td>
      <td>0.550794</td>
      <td>0.002438</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.896727</td>
      <td>0.912238</td>
      <td>0.002409</td>
      <td>15:43:52.010218</td>
      <td>True</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.002463</td>
      <td>True</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.002443</td>
      <td>True</td>
      <td>0.949093</td>
      <td>1.000000</td>
      <td>0.002416</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.268727</td>
      <td>0.190381</td>
      <td>0.004025</td>
      <td>15:43:52.275762</td>
      <td>True</td>
      <td>0.191534</td>
      <td>...</td>
      <td>0.003689</td>
      <td>True</td>
      <td>0.458991</td>
      <td>0.281427</td>
      <td>0.003723</td>
      <td>True</td>
      <td>0.379079</td>
      <td>0.431044</td>
      <td>0.003976</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.658142</td>
      <td>0.533260</td>
      <td>0.003903</td>
      <td>15:43:52.560892</td>
      <td>True</td>
      <td>0.790248</td>
      <td>...</td>
      <td>0.003795</td>
      <td>True</td>
      <td>0.669601</td>
      <td>0.542452</td>
      <td>0.003951</td>
      <td>True</td>
      <td>0.758153</td>
      <td>0.460381</td>
      <td>0.004018</td>
      <td>True</td>
    </tr>
    <tr>
      <th>8</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.946281</td>
      <td>0.802339</td>
      <td>0.003829</td>
      <td>15:43:52.846902</td>
      <td>True</td>
      <td>0.899529</td>
      <td>...</td>
      <td>0.004088</td>
      <td>True</td>
      <td>0.848490</td>
      <td>0.710396</td>
      <td>0.003877</td>
      <td>True</td>
      <td>0.797770</td>
      <td>0.999758</td>
      <td>0.003820</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>9 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiments_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>noise</th>
      <th>offset</th>
      <th>rate</th>
      <th>0_validation_accuracy</th>
      <th>0_test_accuracy</th>
      <th>time_0</th>
      <th>date</th>
      <th>0_finished</th>
      <th>1_validation_accuracy</th>
      <th>...</th>
      <th>time_2</th>
      <th>2_finished</th>
      <th>3_validation_accuracy</th>
      <th>3_test_accuracy</th>
      <th>time_3</th>
      <th>3_finished</th>
      <th>4_validation_accuracy</th>
      <th>4_test_accuracy</th>
      <th>time_4</th>
      <th>4_finished</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.398190</td>
      <td>0.503005</td>
      <td>0.001472</td>
      <td>15:43:50.843200</td>
      <td>True</td>
      <td>0.237532</td>
      <td>...</td>
      <td>0.001378</td>
      <td>True</td>
      <td>0.288024</td>
      <td>0.324241</td>
      <td>0.001403</td>
      <td>True</td>
      <td>0.123719</td>
      <td>0.341125</td>
      <td>0.001447</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.379232</td>
      <td>0.654667</td>
      <td>0.001369</td>
      <td>15:43:51.064255</td>
      <td>True</td>
      <td>0.745192</td>
      <td>...</td>
      <td>0.001507</td>
      <td>True</td>
      <td>0.426478</td>
      <td>0.558034</td>
      <td>0.001398</td>
      <td>True</td>
      <td>0.478542</td>
      <td>0.541459</td>
      <td>0.001453</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.717795</td>
      <td>0.816707</td>
      <td>0.001388</td>
      <td>15:43:51.283737</td>
      <td>True</td>
      <td>0.697048</td>
      <td>...</td>
      <td>0.001457</td>
      <td>True</td>
      <td>0.597638</td>
      <td>0.839794</td>
      <td>0.001464</td>
      <td>True</td>
      <td>0.835126</td>
      <td>0.664219</td>
      <td>0.001474</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.738689</td>
      <td>0.709655</td>
      <td>0.002459</td>
      <td>15:43:51.759312</td>
      <td>True</td>
      <td>0.632554</td>
      <td>...</td>
      <td>0.002354</td>
      <td>True</td>
      <td>0.854771</td>
      <td>0.830298</td>
      <td>0.002466</td>
      <td>True</td>
      <td>0.661954</td>
      <td>0.550794</td>
      <td>0.002438</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.896727</td>
      <td>0.912238</td>
      <td>0.002409</td>
      <td>15:43:52.010218</td>
      <td>True</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.002463</td>
      <td>True</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.002443</td>
      <td>True</td>
      <td>0.949093</td>
      <td>1.000000</td>
      <td>0.002416</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.268727</td>
      <td>0.190381</td>
      <td>0.004025</td>
      <td>15:43:52.275762</td>
      <td>True</td>
      <td>0.191534</td>
      <td>...</td>
      <td>0.003689</td>
      <td>True</td>
      <td>0.458991</td>
      <td>0.281427</td>
      <td>0.003723</td>
      <td>True</td>
      <td>0.379079</td>
      <td>0.431044</td>
      <td>0.003976</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.946281</td>
      <td>0.802339</td>
      <td>0.003829</td>
      <td>15:43:52.846902</td>
      <td>True</td>
      <td>0.899529</td>
      <td>...</td>
      <td>0.004088</td>
      <td>True</td>
      <td>0.848490</td>
      <td>0.710396</td>
      <td>0.003877</td>
      <td>True</td>
      <td>0.797770</td>
      <td>0.999758</td>
      <td>0.003820</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="n">old_experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment_folders</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path_experiments</span><span class="si">}</span><span class="s2">/experiments&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;experiment folders after removal: </span><span class="si">{</span><span class="n">experiment_folders</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">experiment_folders</span><span class="p">)</span><span class="o">==</span><span class="mi">7</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;00007&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">experiment_folders</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;00008&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">experiment_folders</span><span class="p">)</span>

<span class="c1"># we check that neither 3 nor 7 are in the new dataframe index</span>
<span class="n">experiments_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">path_experiments</span><span class="si">}</span><span class="s1">/experiments_data.pk&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;csv data index after removal: </span><span class="si">{</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">index</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">index</span><span class="o">==</span><span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="k">assert</span> <span class="p">(</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="n">old_experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="o">==</span> <span class="n">old_experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">==</span> <span class="n">old_experiments_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;csv content:&#39;</span><span class="p">)</span>
<span class="n">experiments_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>experiment folders after removal: [&#39;00000&#39;, &#39;00005&#39;, &#39;00006&#39;, &#39;00002&#39;, &#39;00004&#39;, &#39;00001&#39;, &#39;00003&#39;]

csv data index after removal: RangeIndex(start=0, stop=7, step=1)

csv content:
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>epochs</th>
      <th>noise</th>
      <th>offset</th>
      <th>rate</th>
      <th>0_validation_accuracy</th>
      <th>0_test_accuracy</th>
      <th>time_0</th>
      <th>date</th>
      <th>0_finished</th>
      <th>1_validation_accuracy</th>
      <th>...</th>
      <th>time_2</th>
      <th>2_finished</th>
      <th>3_validation_accuracy</th>
      <th>3_test_accuracy</th>
      <th>time_3</th>
      <th>3_finished</th>
      <th>4_validation_accuracy</th>
      <th>4_test_accuracy</th>
      <th>time_4</th>
      <th>4_finished</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.398190</td>
      <td>0.503005</td>
      <td>0.001472</td>
      <td>15:43:50.843200</td>
      <td>True</td>
      <td>0.237532</td>
      <td>...</td>
      <td>0.001378</td>
      <td>True</td>
      <td>0.288024</td>
      <td>0.324241</td>
      <td>0.001403</td>
      <td>True</td>
      <td>0.123719</td>
      <td>0.341125</td>
      <td>0.001447</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.379232</td>
      <td>0.654667</td>
      <td>0.001369</td>
      <td>15:43:51.064255</td>
      <td>True</td>
      <td>0.745192</td>
      <td>...</td>
      <td>0.001507</td>
      <td>True</td>
      <td>0.426478</td>
      <td>0.558034</td>
      <td>0.001398</td>
      <td>True</td>
      <td>0.478542</td>
      <td>0.541459</td>
      <td>0.001453</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.717795</td>
      <td>0.816707</td>
      <td>0.001388</td>
      <td>15:43:51.283737</td>
      <td>True</td>
      <td>0.697048</td>
      <td>...</td>
      <td>0.001457</td>
      <td>True</td>
      <td>0.597638</td>
      <td>0.839794</td>
      <td>0.001464</td>
      <td>True</td>
      <td>0.835126</td>
      <td>0.664219</td>
      <td>0.001474</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.03</td>
      <td>0.738689</td>
      <td>0.709655</td>
      <td>0.002459</td>
      <td>15:43:51.759312</td>
      <td>True</td>
      <td>0.632554</td>
      <td>...</td>
      <td>0.002354</td>
      <td>True</td>
      <td>0.854771</td>
      <td>0.830298</td>
      <td>0.002466</td>
      <td>True</td>
      <td>0.661954</td>
      <td>0.550794</td>
      <td>0.002438</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.896727</td>
      <td>0.912238</td>
      <td>0.002409</td>
      <td>15:43:52.010218</td>
      <td>True</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.002463</td>
      <td>True</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.002443</td>
      <td>True</td>
      <td>0.949093</td>
      <td>1.000000</td>
      <td>0.002416</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.03</td>
      <td>0.268727</td>
      <td>0.190381</td>
      <td>0.004025</td>
      <td>15:43:52.275762</td>
      <td>True</td>
      <td>0.191534</td>
      <td>...</td>
      <td>0.003689</td>
      <td>True</td>
      <td>0.458991</td>
      <td>0.281427</td>
      <td>0.003723</td>
      <td>True</td>
      <td>0.379079</td>
      <td>0.431044</td>
      <td>0.003976</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>30.0</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.03</td>
      <td>0.946281</td>
      <td>0.802339</td>
      <td>0.003829</td>
      <td>15:43:52.846902</td>
      <td>True</td>
      <td>0.899529</td>
      <td>...</td>
      <td>0.004088</td>
      <td>True</td>
      <td>0.848490</td>
      <td>0.710396</td>
      <td>0.003877</td>
      <td>True</td>
      <td>0.797770</td>
      <td>0.999758</td>
      <td>0.003820</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
<p>7 rows × 25 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

